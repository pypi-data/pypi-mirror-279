import pyperclip as pc
    
def imports():
    s = '''import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
from scipy.stats import *
    '''
    return pc.copy(s)
    
def zarembki():
    s = '''Y_gmean = gmean(Y)
print(Y_gmean)
Y_ = Y / Y_gmean

X_with_c = sm.add_constant(X)
model = sm.OLS(Y_, X_with_c)
result = model.fit()
result.summary()

ESS1 = sum(result.resid**2)
print(ESS1)

X_with_c = sm.add_constant(X)
model = sm.OLS(np.log(Y_), X_with_c)
result = model.fit()
result.summary()

ESS2 = sum(result.resid**2)
print(ESS2)

Z = np.abs(len(X)/2 * np.log(ESS1/ESS2))
print(Z)
print(chi2(1).isf(0.05))
    '''
    return pc.copy(s)
    
def bokskoks():
    s = '''l = {}
for lam in range(1, 1001):
    lambd = lam/1000
    Y_ = Y/gmean(Y)
    Y_bc = Y_**lambd / lambd
    X_bc = X**lambd / lambd

    X_with_c = sm.add_constant(X_bc)
    model = sm.OLS(Y_bc, X_with_c)

    result = model.fit()
    l[result.ssr] = lambd
    print(l[min(l.keys())])
#–ø–∞—Ä–∞–º–µ—Ç—Ä Œª‚Üí0, —Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –≤–∏–¥ F=lny –í—ã–±–∏—Ä–∞–µ–º –ø–æ–ª—É–ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫—É—é –º–æ–¥–µ–ª—å
    '''
    return pc.copy(s)

def shwarz():
    s = '''X_with_c = sm.add_constant(X)
model = sm.OLS(Y, X_with_c)
result = model.fit()
ESS = result.ssr
BIC = np.log(ESS/len(X)) + np.log(len(X))/len(X) + 1 + np.log(2*np.pi)
print(BIC)

X_with_c = sm.add_constant(X)
model = sm.OLS(np.log(Y), X_with_c)
result = model.fit()
ESS = result.ssr
BIC = np.log(ESS/len(X)) + np.log(len(X))/len(X) + 1 + np.log(2*np.pi)
print(BIC)
#—á–µ–º –º–µ–Ω—å—à–µ –ø–æ –º–æ–¥—É–ª—é —á–∏—Å–ª–æ, —Ç–µ–º –ª—É—á—à–µ
    '''
    return pc.copy(s)
    
def akaike():
    s = '''X_with_c = sm.add_constant(X)
model = sm.OLS(Y, X_with_c)
result = model.fit()
ESS = result.ssr
AIC = np.log(ESS/len(X)) + 2/len(X) + 1 + np.log(2*np.pi)
print(AIC)

X_with_c = sm.add_constant(X)
model = sm.OLS(np.log(Y), X_with_c)
result = model.fit()
ESS = result.ssr
AIC = np.log(ESS/len(X)) + 2/len(X) + 1 + np.log(2*np.pi)
print(AIC)
#—á–µ–º –º–µ–Ω—å—à–µ –ø–æ –º–æ–¥—É–ª—é —á–∏—Å–ª–æ, —Ç–µ–º –ª—É—á—à–µ
    '''
    return pc.copy(s)
    
def mkwhitedavidson():
    s = '''X_with_c = sm.add_constant(X)
model = sm.OLS(Y, X_with_c)
result = model.fit()
Y_pred = result.predict(X_with_c)

X_with_c = sm.add_constant(X)
model = sm.OLS(np.log(Y), X_with_c)
result = model.fit()
LNY_pred = result.predict(X_with_c)

X_with_c = sm.add_constant(np.array(list(zip(X, (Y_pred-np.e**LNY_pred)))))
model = sm.OLS(np.log(Y), X_with_c)
result = model.fit()
result.summary()

X_with_c = sm.add_constant(np.array(list(zip(X, (LNY_pred - np.log(Y_pred))))))
model = sm.OLS(Y, X_with_c)
result = model.fit()
result.summary()

#–ï—Å–ª–∏ theta1 = 0 –Ω–µ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è, –∞ theta2 = 0 –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è, –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –ø–æ–ª—É–ª–æ–≥–∞—Ä –º–æ–¥–µ–ª—å
#–ï—Å–ª–∏ theta2 = 0 –Ω–µ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è, –∞ theta1 = 0 –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è, –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –ª–∏–Ω–µ–π–Ω–∞—è –º–æ–¥–µ–ª—å
    '''
    return pc.copy(s)

def logit_probit():
    s = '''X0 = sm.add_constant(X)
log_reg0 = sm.Logit(Y, X0)
result = log_reg0.fit()
result.summary()

prob = sm.Probit(Y, X0)
result_prob = prob.fit()
result_prob.summary() 

Y_pred = result.predict(X0)
Y_pred[Y_pred > 0.5] = 1
Y_pred[Y_pred < 0.5] = 0
accuracy_score(Y, Y_pred)
f1_score(Y, Y_pred)
    '''
    return pc.copy(s)

def tobit_heckit():
    s = '''install.packages('AER')
data <- read.csv("tobit.csv", header = TRUE, stringsAsFactors = TRUE, sep=';')
``
require(ggplot2)
f <- function(x, var, bw = 20) {
  dnorm(x, mean = mean(var), sd(var)) * length(var)  * bw
}
p <- ggplot(data, aes(x = apt))
p + stat_bin(binwidth=10) + stat_function(fun = f, size = 1, args = list(var = data$apt))

train <- data[0:160, ]
test <- data[161:200, ]

library(AER)
model = tobit(apt ~ read + math +prog, data = train, right=800, left=200)

summary(model)

y_pred <- test['read'] * 2.54207 + test['math'] * 5.85932 + test['prog'] * 24.46143 + 152.52400

MSE <- sum((y_pred - test['apt'])**2)/40
MSE

R2 <- with(test, cor(y_pred, apt))
R2

plot <-plot(test$apt, col = "green", ylim = c(0, max(test$apt, y_pred$read)), xlab = "–ù–∞–±–ª—é–¥–µ–Ω–∏—è", ylab = "–ó–Ω–∞—á–µ–Ω–∏—è")
points(y_pred, col = "black")
legend("topright", legend = c("–†–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è", "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è"), col = c("green", "black"), pch = 1)

if (!require("sampleSelection")) {
  install.packages("sampleSelection")
  library("sampleSelection")
}

heckit <- heckit(data=data, selection = d ~ read + math + prog, outcome = apt ~ read + math +prog)
summary(heckit)

y_pred1 = 175.82327354 + 2.61170331*test['read'] + 5.25718171*test['math'] + 24.42492773 * test['prog']
MSE <- sum((y_pred1 - test['apt'])**2)/40
MSE

R2 <- with(test, cor(y_pred1, apt))
R2

plot <-plot(test$apt, col = "green", ylim = c(0, max(test$apt, y_pred1$read)), xlab = "–ù–∞–±–ª—é–¥–µ–Ω–∏—è", ylab = "–ó–Ω–∞—á–µ–Ω–∏—è")
points(y_pred1, col = "black")
legend("topright", legend = c("–†–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è", "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è"), col = c("green", "black"), pch = 1)

#–ú–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥,
#—á—Ç–æ –¥–ª—è –Ω–∞—à–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –ª—É—á—à–µ –ø–æ–¥–æ–π–¥–µ—Ç Tobit –º–æ–¥–µ–ª—å, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∞ –∏–º–µ–µ—Ç –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π R^2
#–ò –∑–Ω–∞—á–µ–Ω–∏–µ MSE –º–µ–Ω—å—à–µ, —á–µ–º —É heckit –º–æ–¥–µ–ª–∏.
#–ù–æ —Ç–∞–∫ –∫–∞–∫ —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è—Ö –º–∏–Ω–∏–º–∞–ª—å–Ω–∞, –º–æ–∂–Ω–æ —Å–∫–∞–∑–∞—Ç—å, —á—Ç–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ heckit —è–≤–ª—è–µ—Ç—Å—è –æ—á–µ–Ω—å —Å—Ö–æ–∂–µ–π —Å –º–æ–¥–µ–ª—å—é Tobit.
#–ù—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å–Ω–µ–π—à–µ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏ —Å—Ç—Ä–æ–∏—Ç—å –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏.
    '''
    return pc.copy(s)

def kriteriy_seriy_median():
    s = '''
def func_me(x):
    if x > Me:
        return 1
    elif x < Me:
        return -1
    else:
        return 0

Y_t = df['EX_NON-CIS_Y'].copy().sort_values()
Me = np.median(Y_t)
Y_t_signs = Y_t.apply(func_me).sort_index()
Y_t_signs

i = 0
current = 2
max_lenght = 0
count_serias = 0
current_cnt = 0
while i < len(Y_t_signs):
    # print(Y_t_signs.iloc[i], current, max_lenght)
    if Y_t_signs.iloc[i] == current:
        current_cnt += 1
    else:
        current = Y_t_signs.iloc[i]
        count_serias += 1
        max_lenght = max(current_cnt, max_lenght)
        current_cnt = 1
    i += 1

print(max_lenght, count_serias)

max_lenght < 3.3 * (np.log(n) + 1) and count_serias > 0.5 * (n + 1 - 1.96*(n-1)**0.5)
#False => —É—Å–ª–æ–≤–∏–µ –æ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏ —Ä—è–¥–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è => –º–æ–∂–Ω–æ –≥–æ–≤–æ—Ä–∏—Ç—å –æ –Ω–∞–ª–∏—á–∏–∏ —Ç—Ä–µ–Ω–¥–∞
    '''
    return pc.copy(s)
    
def anomalii_student():
    s = '''data1 = data.copy()
ind = np.argmax(abs(data1['UNEMPL_Y_SH'] - data1['UNEMPL_Y_SH'].mean()))
y_m = data1.iloc[ind][1]
tau = abs(y_m - data1['UNEMPL_Y_SH'].mean()) / data1['UNEMPL_Y_SH'].std(ddof=0)
print(tau)

alpha = 0.05
n = len(data1)
tau_an = t.ppf(1 - alpha/2, n-2) * (n - 1)**0.5 / (n - 2 + t.ppf(1 - alpha/2, n-2)**2)**0.5
print(tau_an)

alpha = 0.001
n = len(data1)
tau_an = t.ppf(1 - alpha/2, n-2) * (n - 1)**0.5 / (n - 2 + t.ppf(1 - alpha/2, n-2)**2)**0.5
print(tau_an)
#–ï—Å–ª–∏ –Ω–∞—à–µ tau –º–µ–Ω—å—à–µ –æ–±–æ–∏—Ö, —Ç–æ –Ω–µ –≤—ã–±—Ä–æ—Å
#–ï—Å–ª–∏ –º–µ–∂–¥—É, —Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ –ø—Ä–∏–∑–Ω–∞–Ω–Ω–æ –∞–Ω–æ–º–∞–ª–∏–µ–π, —Ç–∞–∫ –∫–∞–∫ –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≥–æ–≤–æ—Ä–∏—Ç –æ–± –∞–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö.
#–ï—Å–ª–∏ –±–æ–ª—å—à–µ –æ–±–æ–∏—Ö, —Ç–æ –≤—ã–±—Ä–æ—Å
    '''
    return pc.copy(s)
    
def ber_makaler():
    s = '''X_with_c = sm.add_constant(X)
model = sm.OLS(Y, X_with_c)
result = model.fit()
Y_pred = result.predict(X_with_c)

X_with_c = sm.add_constant(X)
model = sm.OLS(np.log(Y), X_with_c)
result = model.fit()
LNY_pred = result.predict(X_with_c)
#


X_with_c = sm.add_constant(X)
model = sm.OLS(np.e**LNY_pred, X_with_c)
result = model.fit()
v1 = result.resid
#

X_with_c = sm.add_constant(X)
model = sm.OLS(np.log(Y_pred), X_with_c)
result = model.fit()
v2 = result.resid
#

X_with_c = sm.add_constant(np.array(list(zip(X, v1))))
model = sm.OLS(np.log(Y), X_with_c)
result = model.fit()
result.summary()
#

X_with_c = sm.add_constant(np.array(list(zip(X, v2))))
model = sm.OLS(Y, X_with_c)
result = model.fit()
result.summary()
#
#–ï—Å–ª–∏ $\theta_1 = 0$ –Ω–µ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è, –∞ $\theta_2 = 0$ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –ø–æ–ª—É–ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å.
#–ï—Å–ª–∏ $\theta_2 = 0$ –Ω–µ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è, –∞ $\theta_1 = 0$ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è, –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –ª–∏–Ω–µ–π–Ω–∞—è –º–æ–¥–µ–ª—å.
#–í–æ–∑–Ω–∏–∫–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º–∞ –µ—Å–ª–∏ –æ–±–µ –≥–∏–ø–æ—Ç–µ–∑—ã –æ—Ç–≤–µ—Ä–≥–∞—é—Ç—Å—è –∏–ª–∏ –Ω–µ –æ—Ç–≤–µ—Ä–≥–∞—é—Ç—Å—è.
    '''
    return pc.copy(s)
    
def foster_stuart():
    s = '''plt.plot(data['Date'], data['Close'])
plt.grid()
plt.scatter(data['Date'], data['Is Outlier'] * 300, color='r')# 300 - —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞—à–∏—Ö –∏–∫—Å–æ–≤ 
#

data4 = data.copy()
#

Kt = [1]
Lt = [1]
arr = data4.Close.values
for i in range(1, len(arr)):
    if arr[i] >= max(arr[:i]):
        Kt.append(1)
    else:
        Kt.append(0)
        
        
    if arr[i] <= min(arr[:i]):
        Lt.append(1)
    else:
        Lt.append(0)

#
data4['Kt'] = Kt
data4['Lt'] = Lt
#
sigma1 = (2*np.log(len(arr)) - 3.4253)**0.5
sigma2 = (2*np.log(len(arr)) - 0.8456)**0.5
#
mu = (1.693872*np.log(len(arr)) - 0.299015) / (1-0.035092 * np.log(len(arr)) + 0.002705*np.log(len(arr))**2)
#
t_s = np.abs(s - mu) / sigma1
t_d = np.abs(d - 0)/sigma2
t_s, t_d
#
t_kr = t.ppf(1-0.05/2, len(arr) - 2)
t_kr
#
t_s > t_kr # –µ—Å–ª–∏ —Ç—Ä—É, —Ç–æ –¥–µ–ª–∞–µ–º –≤—ã–≤–æ–¥ –æ –Ω–∞–ª–∏—á–∏–∏ —Ç—Ä–µ–Ω–¥–∞ —Ä—è–¥–∞
t_d > t_kr #  –µ—Å–ª–∏ —Ç—Ä—É, —Ç–æ –¥–µ–ª–∞–µ–º –≤—ã–≤–æ–¥ –æ –Ω–∞–ª–∏—á–∏–∏ —Ç—Ä–µ–Ω–¥–∞ –¥–∏—Å–ø–µ—Ä—Å–∏–∏
    '''
    return pc.copy(s)

def ARMA():
    s = '''adfuller(Y)# —Ä—è–¥ –Ω–µ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π
from statsmodels.tsa.seasonal import seasonal_decompose
result = seasonal_decompose(Y, period=12)
Y_stac = result.resid.dropna()
plt.plot(result.resid)
adfuller(Y_stac) # —Ä—è–¥ —Å—Ç–∞–ª —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–º

fig = plt.figure(figsize=(12,8))
ax1 = fig.add_subplot(211)
fig = sm.graphics.tsa.plot_acf(Y_stac.diff().dropna().values.squeeze(), lags=25, ax=ax1)
ax2 = fig.add_subplot(212)
fig = sm.graphics.tsa.plot_pacf(Y_stac.diff().dropna(), lags=25, ax=ax2)

from statsmodels.tsa.arima.model import ARIMA

import warnings
warnings.filterwarnings("ignore")
best_model = None
best_params = [0, 0]
best_metrics = [1e9, 1e9]
for p in range(1, 5):
    for q in range(1, 5):
        model = ARIMA(Y_stac, order=(p, 0, q))
        results = model.fit()
        print(f'p={p}, q={q}, AIC={results.aic}, BIC={results.bic}')
        if (results.aic + results.bic)/2 < sum(best_metrics)/2:
            best_metrics = results.aic, results.bic
            best_model = model
            best_params = [p, q]

print(f'\n\n\nBEST MODEL\n')
print(f'p={best_params[0]}, q={best_params[1]}, AIC={best_metrics[0]}, BIC={best_metrics[1]}')

model = ARIMA(Y_stac, order=(best_params[0], 0, best_params[1]))

results = model.fit()
Y_pred = results.predict(len(X), len(X)+10)

plt.figure(figsize=(15, 6))
plt.plot(Y_stac.index, Y_stac)
plt.plot(Y_pred.index, Y_pred, 'r')
    '''
    return pc.copy(s)
    
def panel_data():
    s = '''from linearmodels.panel import RandomEffects, PooledOLS, PanelOLS
data.set_index(['Reg', 'Year'], inplace=True)
data

exog_vars = ["X1", "X2", "X3", "X4", "X5", "X6", "t"]
exog = sm.add_constant(data[exog_vars])

mod = PooledOLS(data.Y, exog)
pooled_res = mod.fit()
pooled_res

mod = PanelOLS(data.Y, exog, entity_effects=True)
fe_res = mod.fit()
fe_res

mod = RandomEffects(data.Y, exog)
re_res = mod.fit()
re_res

#F-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
F_test = ((pooled_res.resid_ss - fe_res.resid_ss)/(len(data)-1)) / (fe_res.resid_ss / (len(data)*3-len(data)-7))
F_test
–¢–∞–∫ –∫–∞–∫ F_test=51.485 > F_–∫—Ä–∏—Ç => –¥–µ–ª–∞–µ–º –≤—ã–±–æ—Ä –≤ –ø–æ–ª—å–∑—É –º–æ–¥–µ–ª–∏ FixedEffect


#–¢–µ—Å—Ç –•–∞—É—Å–º–∞–Ω–∞
def hausman_test(fixed, random):
    b = fixed.params
    B = random.params
    v_b = fixed.cov
    v_B = random.cov
    df = b[np.abs(b) < 1e8].size
    chi2 = np.dot((b - B).T, la.inv(v_b - v_B).dot(b - B))
    pval = stats.chi2.sf(chi2, df)
    return chi2, df, pval

hausman_results = hausman_test(fe_res, re_res)
print(f'Chi^2: {str(hausman_results[0])}')
print(f'–°—Ç–µ–ø–µ–Ω–∏ —Å–≤–æ–±–æ–¥—ã: {str(hausman_results[1])}')
print(f'p-value: {str(hausman_results[2])}')
# –¢–∞–∫ –∫–∞–∫ p-value < 0.05 => –¥–µ–ª–∞–µ–º –≤—ã–±–æ—Ä –≤ –ø–æ–ª—å–∑—É –º–æ–¥–µ–ª–∏ FixedEffect


#–¢–µ—Å—Ç –ë—Ä–µ—É—à–∞-–ü–∞–≥–∞–Ω–∞
# –û—Å—Ç–∞—Ç–∫–∏ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –º–æ–¥–µ–ª–∏ Pooled
pooled_residuals = pooled_res.resids
pooled_fitted = pooled_res.fitted_values
pooled_residuals; pooled_fitted

sigma2_u = re_res.variance_decomposition[1]; sigma2_u
exog = sm.add_constant(pooled_fitted)
exog = np.column_stack((exog, pooled_fitted**2))

from statsmodels.stats.diagnostic import het_breuschpagan
bp_test = het_breuschpagan(pooled_residuals, exog); bp_test
#–¢–∞–∫ –∫–∞–∫ p-value < 0.05 => –¥–µ–ª–∞–µ–º –≤—ã–±–æ—Ä –≤ –ø–æ–ª—å–∑—É –º–æ–¥–µ–ª–∏ RandomEffect
    '''
    return pc.copy(s)
    
def topolog_regr():
    s = '''from sklearn.cluster import KMeans
y = data['data'][:, 0]
X = data['data'][:, 1:]
kmeans = KMeans(n_clusters=2, random_state=42, n_init="auto").fit(X)
kl_pred = kmeans.predict(X)
filtered_label0 = data['data'][kl_pred == 0]
plt.scatter(filtered_label0[:,1] , filtered_label0[:,0], color='red', marker='.')
filtered_label1 = data['data'][kl_pred == 1]
plt.scatter(filtered_label1[:, 1] , filtered_label1[:, 0], color='blue', marker='.')
plt.show()

y_0 = filtered_label0[:, 0]
X_0 = filtered_label0[:, 1:]

y_1 = filtered_label1[:, 0]
X_1 = filtered_label1[:, 1:]
X_0_c = sm.add_constant(X_0)
model_0 = sm.OLS(y_0, X_0_c).fit()
model_0.summary()
X_1_c = sm.add_constant(X_1)
model_1 = sm.OLS(y_1, X_1_c).fit()
model_1.summary()#–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∑–Ω–∞—á–∏–º—ã–º–∏ –∫–æ—ç—Ñ—Ñ—ã
def Topolog_Regr(X, kmean_fit=kmeans, models=[]):
    classter_pred = kmean_fit.predict(X)
    if classter_pred[classter_pred == 0].shape[0] > classter_pred[classter_pred == 1].shape[0]:
        claster = 0
    else:
        claster = 1
        X = X[:, :-1]
        
    if X.shape[0] > 1:
        X_with_c = sm.add_constant(X)
        y_pred = models[claster].predict(X_with_c)
    else:
        X = pd.DataFrame(X)
        X['c']=1
        y_pred = models[claster].predict(X)
        
    result_model = {"R^2": round(models[claster].rsquared, 3),
                   "F": round(models[claster].fvalue, 3),
                   "t-–∑–Ω–∞—á–µ–Ω–∏—è": models[claster].tvalues}
    
    return claster, y_pred, result_model
Topolog_Regr(np.array([[2,10,0]]), kmean_fit=kmeans, models=[model_0, model_1])

y_pred0 = Topolog_Regr(X_0, kmean_fit=kmeans, models=[model_0, model_1])[1]
plt.plot(y_0)
plt.plot(y_pred0, color='r')
plt.legend(['data', 'predict'])
y_pred1 = Topolog_Regr(X_1, kmean_fit=kmeans, models=[model_0, model_1])[1]
plt.plot(y_1)
plt.plot(y_pred1, color='r')
plt.legend(['data', 'predict'])
    '''
    return pc.copy(s)
   
    
def logit_probit_full():
    s = '''import pandas as pd
import statsmodels.api as sm
from sklearn.metrics import accuracy_score, f1_score
from sklearn.model_selection import train_test_split
import seaborn as sns
#—Å–ø–µ—Ü–∏—Ñ –ª–æ–≥–∏—Ç $p(x)=\frac{1}{1+e^{-(\beta_0+\beta_1x}}$
#—Å–ø–µ—Ü–∏—Ñ –ø—Ä–æ–±–∏—Ç $P(y_i = 1) = \Phi(z_i) = \Phi(\beta_1 + \beta_2x_i^{(2)} + ... + \beta_kx_i^{(k)})$
df = ...
X = ...
Y = ...
X_train, X_test, y_train, y_test = train_test_split(X, Y)
sns.heatmap(df.corr(), annot = True) #–≤—ã–±—Ä–∞—Ç—å –≤—Å–µ, —É –∫–æ—Ç–æ—Ä—ã—Ö –≤—ã—Å–æ–∫–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è c Y
#–µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ VIF-test

X0 = sm.add_constant(X_train)
log_reg0 = sm.Logit(y_train, X0)
result = log_reg0.fit()
result.summary()

prob = sm.Probit(Y, X0)
result_prob = prob.fit()
result_prob.summary() 

Y_pred = result.predict(sm.add_constant(X_test)) #–¥–ª—è –ø—Ä–æ–±–∏—Ç–∞ —Ç–æ–∂–µ —Å–¥–µ–ª–∞—Ç—å
Y_pred[Y_pred > 0.5] = 1
Y_pred[Y_pred < 0.5] = 0
#–ø—Ä–æ–≥–Ω–æ–∑–Ω–∞—è –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å
accuracy_score(y_test, Y_pred)

result.get_margeff().summary() #–¥–æ–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–∫—Ç–æ—Ä–∞ –≤ –º–æ–¥–µ–ª–∏
#dy/dx - –Ω–∞—Å–∫–æ–ª—å–∫–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –∫ –∫–ª–∞—Å—Å—É –ø—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ –æ–¥–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –Ω–∞ –µ–¥–∏–Ω–∏—Ü—É
    '''
    return pc.copy(s)
    
def irvin():
    s = '''result = pd.DataFrame()  
y = df['EX_NON-CIS_Y']
n = len(y)
result['EX_NON-CIS_Y'] = y

# –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
S_y = np.sqrt(sum([(y[i] - y.mean()) ** 2 for i in range(n)]) / (n - 1))

# –í—ã—á–∏—Å–ª—è–µ–º –≤–µ–ª–∏—á–∏–Ω—É l_t –¥–ª—è –Ω–∞–±–ª—é–¥–µ–Ω–∏–π
l_t = [0] + [abs(y[i] - y[i - 1]) / S_y for i in range(1, n)]
result['lambda'] = l_t

# –ï—Å–ª–∏ –≤–µ–ª–∏—á–∏–Ω–∞ l_t –ø—Ä–µ–≤—ã—à–∞–µ—Ç —Ç–∞–±–ª–∏—á–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å, —Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ y_t —Å—á–∏—Ç–∞–µ—Ç—Å—è –∞–Ω–æ–º–∞–ª—å–Ω—ã–º
difference = df['EX_NON-CIS_Y'].diff()
lamb = np.abs(difference)/S_y
l_kririch = 1.478*(n/10)**(-0.1767)

result_normal = result[result['lambda'] <= l_kririch]  # –£–±–∏—Ä–∞–µ–º –∞–Ω–æ–º–∞–ª–∏–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã

# –ü—Ä–æ–≤–æ–¥–∏–º –∞–Ω–∞–ª–∏–∑ –ø–æ –º–µ—Ç–æ–¥—É –ò—Ä–≤–∏–Ω–∞
anomalies = result[result['lambda'] > l_kririch]
num_anomalies = len(anomalies)

if num_anomalies == 0:
    print("–ê–Ω–æ–º–∞–ª–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.")
else:
    print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {num_anomalies} –∞–Ω–æ–º–∞–ª–∏–π:")
    print(anomalies)

# –û—Ç–æ–±—Ä–∞–∑–∏–º —Ç–∞–±–ª–∏—Ü—É –±–µ–∑ –∞–Ω–æ–º–∞–ª–∏–π
print("\n–¢–∞–±–ª–∏—Ü–∞ –±–µ–∑ –∞–Ω–æ–º–∞–ª–∏–π:")
print(result_normal)

#–ò—Å–ø–æ–ª—å–∑—É—è –º–µ—Ç–æ–¥ –ò—Ä–≤–∏–Ω–∞ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∏ –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è. –¢–∞–∫–∏—Ö –Ω–µ –æ–∫–∞–∑–∞–ª–æ—Å—å => –î–∞—Ç–∞—Å–µ—Ç –æ—Å—Ç–∞–≤–ª—è–µ–º –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
    '''
    return pc.copy(s)
    
def mov_average():
    s = '''def mov_average(data, k = 5, a = 0.5, T = 12):
    #–ü—Ä–∏–Ω–∏–º–∞–µ—Ç –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–π –º–∞—Å—Å–∏–≤ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
    #–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 3 –º–∞—Å—Å–∏–≤–∞ –æ–±—ã—á–Ω–æ–≥–æ, —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü, —Å—Ä–µ–¥–Ω–µ—Ö—Ä–æ–Ω–æ–ª–æ–≥ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è

    # —Å—Ä–µ–¥–Ω–µ–∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–∞—è —Å–∫–æ–ª—å–∑—è—â–∞—è —Å—Ä–µ–¥–Ω—è—è –ø–æ k —Ç–æ—á–∫–∞–º
    SMA = data.rolling(window=k).mean() 
    # —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü. —Å—Ä–µ–¥–Ω–µ–µ —Å a –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
    EMA = data.ewm(alpha=a).mean()

    # —Å—Ä–µ–¥–Ω–µ—Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Å –ø–µ—Ä–∏–æ–¥–æ–º T = 12 (–≥–æ–¥)
    sr_hronolog = np.array([0]*len(data))
    i = 0
    i_i = T//2
    while i_i <= len(data):
    try:
      sr_hronolog[i_i] = np.sum(np.sum(data.values[i+1:i+T]) + data.values[i]/2 + data.values[i+T+1]/2) / T
    except:
      pass
    i += 1
    i_i += 1
    return SMA, EMA, sr_hronolog
    '''
    return pc.copy(s)
    
def analiz_vrem_ryada():
    s = '''import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import *
df = ...
plt.plot(df['T'], df['EX_NON-CIS_Y'])
#1. –ú—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–∏–≤–Ω–∞—è/–∞–¥–¥–∏—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å (–∞–¥–¥–∏—Ç–∏–≤–Ω–∞—è —Ä–∞–∑–±—Ä–æ—Å –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è (—Ä–∞–∑–±—Ä–æ—Å –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤–æ –∏–¥–µ—Ç), –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–∏–≤–Ω–∞—è —Ä–∞–∑–±—Ä–æ—Å –º–µ–Ω—è–µ—Ç—Å—è)
#2. –¢—Ä–µ–Ω–¥ –≤–æ—Å—Ö–æ–¥—è—â–∏–π/—É–±—ã–≤–∞—é—â–∏–π/–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥)
#3. –ù–µ—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π/—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π (—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π - —Ö–∞–æ—Ç–∏—á–Ω—ã–µ –¥–≤–∏–∂–µ–Ω–∏—è –≤ –æ–∫—Ä–µ—Å–Ω–æ—Å—Ç–∏ –Ω—É–ª—è, –∏–Ω–∞—á–µ –Ω–µ—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π / –±—É–¥–µ—Ç –Ω–µ—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π 99%)

#–∞–Ω–æ–º–∞–ª–∏–∏ —Å—Ç—å—é–¥–µ–Ω—Ç - –≤—ã–∑–≤–∞—Ç—å anomalii_student() / –ª–∏–±–æ –∏—Ä–≤–∏–Ω irvin()

#–Ω–∞–ª–∏—á–∏–µ —Ç—Ä–µ–Ω–¥–∞ - –∫—Ä–∏—Ç–µ—Ä–∏–π –º–µ–¥–∏–∞–Ω kriteriy_seriy_median()

#—Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏–º –∏–ª–∏ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º - mov_average()
#–ø–æ—Å—Ç—Ä–æ–∏—Ç—å 2 –≥—Ä–∞—Ñ–∏–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–∏–¥–∞ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
#–í—ã–≤–æ–¥: —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –ª—É—á—à–µ —É–ª–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–ª–µ–±–∞–Ω–∏—è, –∞ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ —Å–≥–ª–∞–∂–∏–≤–∞–µ—Ç –≤—Å–µ –∫–æ–ª–µ–±–∞–Ω–∏—è —Ä—è–¥–∞
    '''
    return pc.copy(s)
    
def kriv_rosta():
    s = '''import numpy as np
import pandas as pd
import statsmodels.api as sm
import matplotlib.pyplot as plt
import sklearn.metrics as m
import seaborn as sns
df = ...
plt.plot(df['Y'])
#–î–ª—è –≤—ã–±–æ—Ä–∞ –∫—Ä–∏–≤–æ–π —Ä–æ—Å—Ç–∞
plt.plot(np.array(Y_new[1:]) - np.array(Y_new[:-1]))
#–ø–æ—Å—Ç–æ—è–Ω–Ω–∞ => –ª–∏–Ω–µ–π–Ω–∞—è
#–ª–∏–Ω–µ–π–Ω–∞ => –ø–æ–ª–∏–Ω–æ–º 2 –ø–æ—Ä—è–¥–∫–∞

temp = np.array(Y_new[1:]) - np.array(Y_new[:-1])
plt.plot(temp[1:] - temp[:-1])
#–ø–æ—Å—Ç–æ—è–Ω–Ω–∞ => –ª–∏–Ω–µ–π–Ω–∞—è
#–ª–∏–Ω–µ–π–Ω–∞ => –ø–æ–ª–∏–Ω–æ–º 3 –ø–æ—Ä—è–¥–∫–∞

plt.plot((np.array(Y_new[1:]) - np.array(Y_new[:-1]))/np.array(Y_new[1:]))
#–ø–æ—Å—Ç–æ—è–Ω–Ω–∞ => —ç–∫—Å–ø–æ–Ω–µ–Ω—Ç–∞
#–î–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–Ω–∏–π
X = list(range(1, len(df) + 1))
X0 = sm.add_constant(X)

model = sm.OLS(df['CNSTR_C_M'], X0).fit()
model.summary()

#–õ–∏–Ω–µ–π–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
for i in range(1, 5):
  print(f'–ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {i} –¥–æ–ø –ø–µ—Ä–∏–æ–¥: {a0 + (len(df) + i) * a1:.2f}')
  
def calculate_U_k(n, k, t_alpha, t_bar, epsilon, m):
    S_y_hat = np.sqrt(np.sum(epsilon**2) / (n - m - 1))
    
    sum_term = np.sum((np.arange(1, n + 1) - t_bar)**2)
    
    U_k = S_y_hat * t_alpha * np.sqrt(1 + 1/n + (n + k - t_bar)**2 / sum_term)
    return U_k
    
U_k = calculate_U_k(len(df), 4, 0.05, np.mean(X), model.resid, 1) #4 –∫–æ–ª-–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞, 1 - –∫–æ–ª-–≤–æ –∏–∫—Å–æ–≤
print("U(k):", U_k)  
 
for i in range(1, 5):
  print(f'–ò–Ω—Ç–µ—Ä–≤–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {i} –¥–æ–ø –ø–µ—Ä–∏–æ–¥: {(a0 + (len(df) + i) * a1) - U_k:.2f}, {(a0 + (len(df) + i) * a1) + U_k:.2f}')
    '''
    return pc.copy(s)
    
def braun():
    s = '''first8 = sm.OLS(df['Y'][:8], X0[:8]).fit()
first8.summary()

#–û–¢–ú–ï–¢–ö–ê
model_params = [list(first8.params)] * 8
beta = 0.5 #random
df['t'] = list(range(1, len(df) + 1))
df['y'] = df['Y']

for i in range(8, len(df)):
    y_pred = model_params[-1][0] + model_params[-1][1] * df.iloc[i].t
    error = df.iloc[i].y - y_pred
    temp = [0, 0]
    temp[0] = model_params[-1][0] + model_params[-1][1] + (1 - beta) ** 2 * error
    temp[1] = model_params[-1][1] + (1 - beta) ** 2 * error
    model_params.append(temp)
    
model_params = np.array(model_params)
y_pred = model_params[:, 0] + model_params[:, 1] * df.t
plt.xlabel('t, –ø–µ—Ä–∏–æ–¥ –≤—Ä–µ–º–µ–Ω–∏')
plt.ylabel('y')
plt.plot(df.t, y_pred)
plt.plot(df.t, df.y)
#–ö–û–ù–ï–¶ –û–¢–ú–ï–¢–ö–ò

#–ü–û–î–ë–û–† –ë–ï–¢–ê
res = []
first8 = sm.OLS(df[:8].y, sm.add_constant(df[:8].t)).fit()
for beta in np.linspace(0, 1, 1000):
    model_params = [list(first8.params)] * 8
    for i in range(8, len(df)):
        y_pred = model_params[-1][0] + model_params[-1][1] * df.iloc[i].t
        error = df.iloc[i].y - y_pred
        temp = [0, 0]
        temp[0] = model_params[-1][0] + model_params[-1][1] + (1 - beta) ** 2 * error
        temp[1] = model_params[-1][1] + (1 - beta) ** 2 * error
        model_params.append(temp)
    model_params = np.array(model_params)
    y_pred = model_params[:, 0] + model_params[:, 1] * df.t
    res.append(np.sum((df.y - y_pred) ** 2))
print(np.argmin(res) / 1000, min(res)) #–ø–æ–¥–æ–±—Ä–∞–ª–∏ –±–µ—Ç–∞
#–ø—Ä–æ–¥–µ–ª—ã–≤–∞–µ–º —Ç–æ –∂–µ —Å–∞–º–æ–µ –æ—Ç –æ—Ç–º–µ—Ç–∫–∏, –º–µ–Ω—è—è –±–µ—Ç–∞ –Ω–∞ –ø–æ–¥–æ–±—Ä–∞–Ω–Ω—É—é
    '''
    return pc.copy(s)

def chetverikov_func():
    s = '''
def Chetverikov(t, y, L):
    y_reshaped = np.array(y).reshape(-1, L)
    chrono_mean = (0.5 * y_reshaped[:, 0] + np.sum(y_reshaped[:, 1:-1], axis=1) + 0.5 * y_reshaped[:, -1]) / L
    l1 = y_reshaped - chrono_mean[[[i]*L for i in range(len(chrono_mean))]]
    l1_2 = l1 ** 2
    sigma1 = np.sqrt((np.sum(l1_2, axis=1) - np.sum(l1, axis=1) ** 2 / L) / (L - 1))
    l1_norm = l1 / sigma1[[[i]*L for i in range(len(chrono_mean))]]
    s1 = np.mean(l1_norm, axis=0)

    f1 = y_reshaped - s1[[list(range(0, L)) for i in range(len(y_reshaped))]] * sigma1[[[i]*L for i in range(len(chrono_mean))]]
    f2 = [np.nan] * (int(0.5 * L) - 1)

    for i in range(int(0.5 * L), len(f1.reshape(-1)) + 1):
        f2.append(np.mean(f1.reshape(-1)[i - int(0.5 * L): i]))
    for i in range(int(0.5 * L) - 1):
        f2[i] = f1[i, 0]
    
    f2 = np.array(f2).reshape(-1, L)

    l2 = y_reshaped - f2

    l2_2 = l2 ** 2

    sigma2 = np.sqrt((np.sum(l2_2, axis=1) - np.sum(l2, axis=1) ** 2 / L) / (L - 1))
    l2_norm = l2 / sigma2[[[i]*L for i in range(len(chrono_mean))]]

    s2 = np.mean(l2_norm, axis=0)

    eps = l2 - s2[[list(range(0, L)) for i in range(len(y_reshaped))]] * sigma2[[[i]*L for i in range(len(chrono_mean))]]

    k = np.sum(l2_2 * eps, axis=1) / np.sum(eps ** 2, axis=1)

    return {'chrono_mean': chrono_mean[[[i]*L for i in range(len(chrono_mean))]].reshape(-1),  
            'f1': f1.reshape(-1), 
            'f2': f2.reshape(-1), 
            's1': s1, 
            's2': s2, 
            'eps': eps.reshape(-1)}
    '''
    return pc.copy(s)
    
def chetverikov():
    s = '''#—Å–Ω–∞—á–∞–ª–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º chetverikov_func()
res = Chetverikov(df.t, df.y, 12) #–µ—Å–ª–∏ –∫–≤–∞—Ä—Ç–∞–ª—ã —Ç–æ 4, –º–µ—Å—è—Ü—ã - 12
plt.figure(figsize=(8, 8))
plt.suptitle('–î–∏–∞–≥—Ä–∞–º–º—ã —Ç—Ä–µ–Ω–¥–∞')
plt.subplots_adjust(hspace=0.5)
titles = ['–ò—Å—Ö–æ–¥–Ω—ã–π —Ä—è–¥', '–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç—Ä–µ–Ω–¥–∞', '–ü–µ—Ä–≤–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç—Ä–µ–Ω–¥–∞', '–í—Ç–æ—Ä–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç—Ä–µ–Ω–¥–∞']
for i, col in enumerate([df.y, res['chrono_mean'], res['f1'], res['f2']]):
    plt.subplot(4, 1, i + 1)
    plt.title(titles[i])
    if i == 3:
        plt.xlabel('t, –ø–µ—Ä–∏–æ–¥ –≤—Ä–µ–º–µ–Ω–∏')
    plt.grid(alpha=0.5, linestyle='--')
    plt.plot(df.t, col, c=('orange' if i else 'blue'))
    
plt.figure(figsize=(10, 7))
plt.suptitle('–î–∏–∞–≥—Ä–∞–º–º—ã —Å–µ–∑–æ–Ω–Ω–æ–π –≤–æ–ª–Ω—ã')
plt.subplots_adjust(hspace=0.5)
titles = ['–ü–µ—Ä–≤–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏', '–í—Ç–æ—Ä–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏']
for i, col in enumerate([res['s1'], res['s2']]):
    plt.subplot(3, 1, i + 1)
    if i < 2:
        plt.plot(np.arange(1, 13), col, c=('red' if i else 'lightgreen'), linewidth=1) #–µ—Å–ª–∏ –∫–≤–∞—Ä—Ç–∞–ª—ã —Ç–æ –≤–º–µ—Å—Ç–æ 13 —Å—Ç–∞–≤–∏–º 5
    else:
        plt.plot(np.arange(1, 13), col[0], c='red', linewidth=1)
        plt.plot(np.arange(1, 13), col[1], c='lightgreen', linewidth=1)
        
plt.figure(figsize=(10, 5))
plt.title('–û—Å—Ç–∞—Ç–æ—á–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞')
plt.grid()
plt.plot(df.t, res['eps'], c='g')
    '''
    return pc.copy(s)
    
def holt_w():
    s = '''import sklearn.metrics as m
def HolterWinter(y, alpha, beta, gamma, L, data_offset=None):
    a = [y[0]]
    b = [0]
    F = [1] * L

    for i in range(1, L):
        a_temp = alpha * (y[i] / 1) + (1 - alpha) * (a[i - 1] + b[i - 1])
        b_temp = beta * (a_temp - a[i - 1]) + (1 - beta) * b[i - 1]

        a.append(a_temp)
        b.append(b_temp)
    
    for i in range(L, len(y[:data_offset])):
        a_temp = alpha * (y[i] / F[i - L]) + (1 - alpha) * (a[i - 1] + b[i - 1])
        b_temp = beta * (a_temp - a[i - 1]) + (1 - beta) * b[i - 1]
        F_temp = gamma * (y[i] / a_temp) + (1 - gamma) * F[i - L]

        a.append(a_temp)
        b.append(b_temp)
        F.append(F_temp)

    return map(np.array, [a, b, F])

alpha, beta, gamma = 0.5, 0.5, 0.5 #–æ—Ç –ø–∏–∑–¥—ã
a, b, F = HolterWinter(df.y, alpha, beta, gamma, 4)

y_pred = (a + b) * F
y_pred, len(y_pred)

plt.figure(figsize=(10, 5))
plt.title(f'–ú–æ–¥–µ–ª—å –•–æ–ª—Ç–µ—Ä–∞-–£–∏–Ω—Ç–æ—Ä—Å–∞ ({alpha=}, {beta=}, {gamma=})')
plt.xlabel('t, –ø–µ—Ä–∏–æ–¥ –≤—Ä–µ–º–µ–Ω–∏')
plt.ylabel('y')
plt.plot(df.t, y_pred, c='orange')
plt.plot(df.t, df.y, c='blue')

m.r2_score(y_pred, df.y) #—Ö–æ—Ä–æ—à–∏–π r^2
    '''
    return pc.copy(s)
    
def ARIMA():
    s = '''from statsmodels.tsa.stattools import adfuller
print(adfuller(data)) # –Ω–µ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π, pvalue –±–æ–ª—å—à–æ–µ

# –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å 
data2 = (data[1:].values - data[:-1].values)/data[:-1].values
print(adfuller(data2)) # —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π, pvalue –º–∞–ª–µ–Ω—å–∫–æ–µ
 
fig = plt.figure(figsize=(15, 10))
ig = plt.figure(figsize=(12,8))
ax1 = fig.add_subplot(211)
# –≥—Ä–∞—Ñ–∏–∫ –∞–≤—Ç–æ–∫–æ—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
fig = sm.graphics.tsa.plot_acf(data2, lags=25, ax=ax1) 
ax2 = fig.add_subplot(212)
# –≥—Ä–∞—Ñ–∏–∫ —á–∞—Å—Ç–Ω–æ–π –∞–≤—Ç–æ–∫–æ—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
fig = sm.graphics.tsa.plot_pacf(data2, lags=25, ax=ax2)
plt.show()

def autocovariance(x, lag):
    n = len(x)
    mean = np.mean(x)
    cov = np.sum((x[:n-lag] - mean) * (x[lag:] - mean)) / n
    return cov

lags = np.arange(20)  # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∞–≤—Ç–æ–∫–æ–≤–∞—Ä–∏–∞—Ü–∏–∏ –¥–ª—è 20 –ª–∞–≥–æ–≤
autocovariances = [autocovariance(data2, lag) for lag in lags]
plt.figure(figsize=(10, 5))
plt.stem(lags, autocovariances, use_line_collection=True)
plt.show()

# —Ä–∞—Å—á—ë—Ç AR(1), AR(2), ARMA(1, 1)
from statsmodels.tsa.arima.model import ARIMA
arma1 = ARIMA(data2, order = (1, 0, 0)).fit()
arma2 = ARIMA(data2, order = (2, 0, 0)).fit()
arma3 = ARIMA(data2, order = (1, 0, 1)).fit()
arma1.bic, arma2.bic, arma3.bic
arma1.aic, arma2.aic, arma3.aic
# –í—ã–±–∏—Ä–∞–µ—Ç—Å—è —Ç–∞, –≥–¥–µ –º–µ–Ω—å—à–µ aic –∏ bic –ø–æ –º–æ–¥—É–ª—é

# –ø–µ—Ä–µ–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ARMA –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –ª—É—á—à–µ–π
best_params = (0, 0)
best_aic_bic = 10000

for p in range(1, 5):
  for q in range(1, 5):
    arma = ARIMA(data2, order = (p, 0, q))
    arma = arma.fit()
    if (arma.aic + arma.bic) / 2 <  best_aic_bic:
      best_params = (p, q)
      best_aic_bic = (arma.aic + arma.bic) / 2

    '''
    return pc.copy(s)
    
def check_rank():
    s = '''
def check(mat, endog=2):
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∞—Ç—Ä–∏—Ü—ã –Ω–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ–º–æ—Å—Ç

    Args:
        mat (–º–∞—Ç—Ä–∏—Ü–∞): –ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—ç—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤
        endog (int, optional): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ Y. Defaults to 2.

    Returns:
        bool: –Ø–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ–º–æ–π
    """    
    for i in range(mat.shape[0]):
        pos0 = np.where(np.array(mat[i, :])[0] == 0)[0]
        v = list(range(mat.shape[0]))
        v.remove(i)
        submat = mat[v, list(pos0)]
        print(submat, f"rang = {submat.shape[0]}")
        if submat.shape[0] < endog - 1:
            return False
    return True
check(mat, 2)
    '''
    return pc.copy(s)
    
def pravilo_poryadka():
    s = '''$ùê¥ùê∑ùêºùê∑ùê¥ùëÜ=ùëé_0+ùëé_1 ùë°+ ùëé_2 ùë°^2+ùëé_3 ùëÉùëàùëÄùê¥+ùë¢_1$
#k - –∫–æ–ª-–≤–æ –≤—Å–µ—Ö –∏–∫—Å–æ–≤ –≤–æ –≤—Å–µ—Ö —É—Ä–∞–≤–Ω–µ–Ω–∏—è—Ö (–≤ —Ç–æ–º —á–∏—Å–ª–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞)
#p - –∫–æ–ª-–≤–æ Y –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –≤ —ç—Ç–æ–º —É—Ä–∞–≤–Ω–µ–Ω–∏–∏
#q - –∫–æ–ª-–≤–æ –∏–∫—Å–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –≤ —ç—Ç–æ–º —É—Ä–∞–≤–Ω–µ–Ω–∏–∏ –∏–∑ –≤—Å–µ—Ö –∏–∫—Å–æ–≤     
ùëò = 4, ùëù = 2, ùëû = 3    
ùëò‚àí ùëù ‚â• ùëû ‚àí 1     
4 ‚àí 2 ‚â• 3 ‚àí 1 (–∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ–º–æ –µ—Å–ª–∏ =, –µ—Å–ª–∏ > —Ç–æ —Å–≤–µ—Ä—Ö–∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ–º–æ)
    '''
    return pc.copy(s)
 
def pravilo_ranga():
    s = '''a0, a1, a2, a3,  b0, b1, b2, b3, c0, c1, c2, c3, u1, u2, u3 = symbols('a0 a1 a2 a3 b0 b1 b2 b3 c0 c1 c2 c3 u1 u2 u3')
A = Matrix([[1, 0, -a3], [-b2, 1, 0], [-c2, -c3, 1]])
B = Matrix([[-a0, -a1, 0, -a2], [-b0, -b1, 0, 0], [-c0, 0, -c1, 0]])
AB = Matrix.hstack(A, B)
AB

R1 = Matrix([[0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0]])
R2 = Matrix([[0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1]])

AB * R2.T

m = 3 #–∫–æ–ª-–≤–æ –≤—Å–µ—Ö Y

print((AB*R1.T).rank(), (AB*R2.T).rank(), m - 1) #–µ—Å–ª–∏ –≤—Å–µ —Ä–∞–≤–Ω—ã —Ç–æ –Ω–æ—Ä–º
    '''
    return pc.copy(s)
    
def gretl():
    s = '''
system
    equation Apple const SP500 Microsoft t
    equation Nvidia const  SP500 t
    equation Microsoft const Apple Microsoft t
    equation SP500 const Apple Nvidia Microsoft t
end system
    '''
    return pc.copy(s)