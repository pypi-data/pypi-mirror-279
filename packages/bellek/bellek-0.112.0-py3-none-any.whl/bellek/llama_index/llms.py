# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/llama_index.llms.ipynb.

# %% auto 0
__all__ = ['log', 'HuggingFaceTextGenInferenceLLM']

# %% ../../nbs/llama_index.llms.ipynb 3
from typing import Optional

from fastcore.meta import delegates
from langchain.llms.huggingface_text_gen_inference import HuggingFaceTextGenInference
from llama_index.callbacks import CallbackManager
from llama_index.llms import LangChainLLM
from llama_index.llms.llm import LLM

from ..logging import get_logger

log = get_logger(__name__)

# %% ../../nbs/llama_index.llms.ipynb 4
@delegates(HuggingFaceTextGenInference.__init__)
def HuggingFaceTextGenInferenceLLM(
    *,
    callback_manager: Optional[CallbackManager] = None,
    **kwargs,
) -> LLM:
    llm = HuggingFaceTextGenInference(**kwargs)
    return LangChainLLM(llm=llm, callback_manager=callback_manager)
