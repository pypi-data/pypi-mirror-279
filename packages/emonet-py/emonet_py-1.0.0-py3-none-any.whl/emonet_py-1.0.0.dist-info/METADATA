Metadata-Version: 2.1
Name: emonet-py
Version: 1.0.0
Summary: A PyTorch port of the MatLab EmoNet network by Kragel et al., 2019.
Author-email: Laurent Mertens <laurent.mertens@kuleuven.be>
License: Copyright (c) 2024 Laurent Mertens
        
        Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
        
Project-URL: Homepage, https://gitlab.com/EAVISE/lme/emonet
Keywords: ANN,PyTorch,Neural Networks,Emotion Recognition
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE.md
Requires-Dist: Pillow >=9
Requires-Dist: torch >=2
Requires-Dist: torchvision >=0.15

# EmoNet: A PyTorch port
This package contains a PyTorch port of the EmoNet network originally developed in MatLab described in the paper "Emotion schemas are
embedded in the human visual system" by Krager et al., 2019.

The original model and corresponding paper can be found at:
[https://sites.google.com/colorado.edu/emonet/](https://sites.google.com/colorado.edu/emonet/)

The ```data``` folder contains:
- The original model parameters, as exported from MatLab (```*.bz2``` files).
- The original mean pixel values used to preprocess images (```img_mean.txt```).
- Two demo images to verify the integrity of the port, i.e., that the outputs generated by the PyTorch model closely match the original
MatLab model outputs (```demo_*.jpg```).
- A PyTorch ```state_dict``` object containing the PyTorch translation of the original weights, to be used in conjunction
with an AlexNetBig instance to obtain the EmoNet model (```emonet.pth```).

The package ```emonet_py``` contains the following scripts:
- ```alexnet_big.py```: defines the original AlexNet model, compared to the updated version that comes with
```torchvision.models```.
- ```convert_emonet_matlab_weights.py```: this script can be used to translate the MatLab model parameters to PyTorch. See its internal
documentation for details on this process.
- A demonstration script showing how to use the model (```demo.py```).
- ```emonet.py```: the script defining the EmoNet model, as well as a class, EmoNetPreProcess, to load and preprocess images
using the same image normalization used by the original MatLab model.
- ```emonet_arousal.py```: an arousal prediction model, consisting of an extra linear layer following the EmoNet output layer (see paper).
- ```emonet_valence.py```: a valence prediction model, consisting of an extra linear layer following the EmoNet output layer (see paper).
- ```test_integrity.py```: a UnitTest to check the integrity of the ported model.
Note that the arousal and valence models are also ports of the original models.

To load and use EmoNet, simply do (see ```emonet.py/demo.py```):
```
import os
from emonet_py.emonet import EmoNet, EmoNetPreProcess
from emonet_py.emonet_arousal import EmoNetArousal
from emonet_py.emonet_valence import EmoNetValence

if __name__ == '__main__':
    emonet = EmoNet(b_eval=True)
    emonet_pp = EmoNetPreProcess()
    img_big = os.path.join('..', 'data', 'demo_big.jpg')
    img_loaded = emonet_pp(img_big)
    pred = emonet.emonet(img_loaded.unsqueeze(0))
    emonet.prettyprint(pred, b_pc=True)

    emo_aro = EmoNetArousal()
    print(f"Arousal: {emo_aro(img_loaded.unsqueeze(0))}")

    emo_val = EmoNetValence()
    print(f"Valence: {emo_val(img_loaded.unsqueeze(0))}")
```

## Licensing
This repository is made available under an MIT license (see [LICENSE.md](./LICENSE.md)).

Author: Laurent Mertens\
Mail: [laurent.mertens@kuleuven.be](laurent.mertens@kuleuven.be)
