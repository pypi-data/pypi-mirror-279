import pandas as pd
from collections import defaultdict
from faker import Faker
from pathlib import Path
from types import FunctionType, ModuleType

from .schema import get_schema_objects, get_tables, determine_dependencies
from .sorting import topological_sort
from .fake import get_column_provider


def generate_data(
    schema_objects: ModuleType,
    quantities: dict[str, int] = {},
    fallback_quantity: int = 10,
    custom_providers: dict[str, FunctionType] = {},
    data_dir: str | Path | None = None,
) -> tuple[None | dict[str, pd.DataFrame], list[str]]:
    """Generate data in topological order for a sqlalchemy schema. The data is generated using the faker library and/or user provided data generator functions.

    ```py
    # basic usage
    data, order = generate_data(schema)
    ```

    The models in the schema are expected to have a `__tablename__` attribute that specifies the name of the table in the database. An optional info attribute can be used on the columns to specify a data generator function, for example:

    ```py
    # schema.py
    class User(Base):
        __tablename__ = "User"
        id = Column(String, primary_key=True, info={"provider": "uuid4"})
    ```

    The value of the provider can be the name of a faker method or a custom data generator function. The custom data generator function should take no arguments and return a value.

    Enumerations can be generated by passing enum: followed by a list of values, for example:

    ```py
    # schema.py
    class User(Base):
        __tablename__ = "User"
        id = Column(String, primary_key=True, info={"provider": "uuid4"})
        status = Column(Enum("active", "inactive"), info={"provider": "enum:active,inactive"})
    ```

    Args:
        schema_objects (ModuleType): A module containing sqlalchemy schema objects.
        quantities (dict[str, int], optional): A dictionary where the key is the table name and the value is the quantity of data to generate for the given table. Defaults to {}.
        fallback_quantity (int, optional): The quantity of data to generate for tables not specified in the quantities dictionary. Defaults to 10.
        custom_providers (dict[str, FunctionType], optional): A dictionary where the key is the name of the custom data generator function and the value is the function itself. Defaults to {}.
        data_dir (str | Path | None, optional): The directory where the generated data will be stored. Defaults to None. If None, the generated data will be returned as a dictionary with table names as keys and pandas DataFrames as values.

    Returns:
        tuple[None | dict[str, pd.DataFrame], list[str]]: A tuple where the first element is a dictionary with table names as keys and pandas DataFrames as values if data_dir is None, otherwise None. The second element is a list of table names in the order in which the data was generated.
    """
    # instantiate faker
    faker = Faker()

    # get all classes listed in __all__ as a list of classes
    models = get_schema_objects(schema_objects)
    tables = get_tables(models)

    # determine the dependencies between tables
    deps = determine_dependencies(tables)

    # determine the order in which the tables should be created
    order = topological_sort(deps)

    # Store primary keys for each table
    primary_keys = defaultdict(list)

    all_data: dict[str, pd.DataFrame] | None = None
    # Generate data for each table in the correct order
    for _, table_name in enumerate(order):
        table = next(table for table in tables if table.__tablename__ == table_name)

        data = {}
        for column in table.__table__.columns:
            generator = get_column_provider(column, faker, custom_providers)

            rows_to_generate = quantities.get(table.__tablename__, fallback_quantity)

            if column.primary_key:
                # Store primary keys separately
                primary_keys[table.__tablename__] = [
                    generator() for _ in range(rows_to_generate)
                ]
                data[column.name] = primary_keys[table.__tablename__]
            elif column.foreign_keys:
                # Populate foreign keys with random primary keys from the referenced table
                fk_column = list(column.foreign_keys)[0].column.table.name
                data[column.name] = [
                    faker.random_element(primary_keys[fk_column])
                    for _ in range(rows_to_generate)
                ]
            else:
                data[column.name] = [generator() for _ in range(rows_to_generate)]

        df = pd.DataFrame(data)

        if data_dir:
            output_dir = Path(data_dir)
            # check if output_dir exists
            if not output_dir.exists():
                output_dir.mkdir(parents=True)

            df.to_csv(output_dir / f"{table.__tablename__}.csv", index=False)
        else:
            if all_data is None:
                all_data = {}

            all_data[table.__tablename__] = df

    return all_data, order
