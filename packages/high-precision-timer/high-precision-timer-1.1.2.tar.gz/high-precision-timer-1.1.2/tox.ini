# This file provides configurations for various project-building tasks. In a way, Tox is used as a build system for
# this project. Note, all tasks listed in this file should be executed successfully prior to merging ANY changes into
# the main branch.

# Configures the 'general' runtime commands. This allows specifying the list of commands to be executed when 'tox'
# command is used without any environment specification. In turn, this configuration allows using plain 'tox' call to
# carry out all project checkout tasks with a single call.
[tox]
envlist =
    lint
    {py310, py311, py312}-test
    combine-test-reports
    doxygen
    docs

# This forces tox to create a 'sterile' environment into which the project with all dependencies is installed prior to
# running the requested tasks, isolating the process from the rest of the system. This is almost always the desired
# runtime mode.
isolated_build = True

# Linter task. This task uses Ruff and MyPy to statically lint the code. This allows standardizing most formatting,
# code style and typing requirements across the project. Successful (zero-error) result of running this task is
# REQUIRED before submitting a merge request.
[testenv: lint]
description = Runs static code formatting, style and typing checkers.
# This should be set either to the 'oldest' supported version or to the 'primary' target version, whichever is more
# applicable for the project. This determines the specific ruleset used by ruff and mypy to determine the appropriate
# code formatting, styling and type-hinting requirements.
basepython = py310
extras = lint
allowlist_externals =
    ruff
    mypy
commands =
# Checks formatting and style. Behaves like Black does both in terms of resultant output and in terms of behavior
# regarding fixing 'safe' errors on the spot.
    ruff check --select I --fix
    ruff format
# Checks type hinting. While not strictly required for most project, this is generally considered a good practice.
    mypy . --install-types

# Main testing task. This task builds and installs the package and then runs the contents of the 'tests' folder using
# pytest framework on the installed package. This ensures the package works as intended for the target python versions.
# Note, you can specify the particular python version to use during runtime, if you only need to test one of them at a
# time. This task requires the target Python to be installed on the host system and, by far, the easiest solution is to
# install the standalone python version(s) you need for testing.
[testenv: {py310, py311, py312}-test]
description = Runs unit and integration tests using parallel workers and generates coverage reports.
package = wheel
extras = test
allowlist_externals = pytest
# Sets environment parameters, which includes the coverage_report parameters.
setenv =
    COVERAGE_FILE = reports{/}.coverage.{envname}
deps =
    scikit-build-core
    nanobind
    pytest
commands =
    # Builds and installs the package and runs pytest-cov. The coverage reports are aggregated into the unified
    # html file to be reviewed by the developers at the end of the testing runtime. To optimize testing speed, the tests
    # run in parallel via pytest-xdist plugin. The '-n auto' allows the plugin to automatically determine the number of
    # workers, but it an also be configured to a specific number.
    python -m pip install .
    pytest \
        --import-mode=append \
        --cov=high_precision_timer.precision_timer \
        --cov-config=pyproject.toml \
        --cov-report=xml \
        --junitxml=reports/pytest.xml.{envname} \
        -n auto

# A sub-task executed for each '-test' call. This task aggregates the coverage reports for different python versions
# into an .html file to be reviewed by the developers. To view the report, navigate to reports/coverage_html/index.html.
[testenv:combine-test-reports]
description = Combines test and coverage data from multiple test runs into a file.
skip_install = true
setenv = COVERAGE_FILE = reports/.coverage
depends = {py310, py311, py312}-test
deps =
    junitparser
    coverage[toml]
commands =
    # Uses junitparser to read the pytest .xml reports and convert them to a unified html summary file
    junitparser merge --glob reports/pytest.xml.* reports/pytest.xml
    coverage combine --keep
    coverage xml
    coverage html

# This task is only required for project that use C / C++ extensions. To unify the documentation for the project, this
# task uses doxygen to generate the API documentation using doxygen-formatted docstrings and outputs it as an .xml,
# which is then used by 'breathe' to generate sphinx-compatible files. This step is necessary to generate the original
# C / C++ source documentation. Note, since doxygen is not pip-installable, it has to be installed and made available
# system-wide for this task to succeed. Consult https://www.doxygen.nl/manual/install.html for guidance.
[testenv:doxygen]
description = Generates Doxygen documentation.
allowlist_externals = doxygen
commands =
# Instructs doxygen to use the local Doxyfile instance to parse C++ docstrings
    doxygen Doxyfile

# Builds the read-the-docs formatted APi documentation html page via sphinx. Sphinx is configured to build the Python
# documentation using Google-style docstrings and to build C++ documentation via breathe linker (from doxygen .xml).
# This task works in-tandem with onf.py and the .rst files inside the docs/source directory.
[testenv:docs]
description = Builds the API documentation using Sphinx (integrates with C++ documentation via Breathe).
extras = docs
deps =
    click
    tqdm
    importlib_metadata
    breathe
    sphinx-click
    sphinx-rtd-theme
allowlist_externals =
    sphinx-build
commands =
# Instructs the sphinx to build the html documentation using local configuration files. uses '-j auto' to parallelize
# the build process and '-v' to make it verbose.
    sphinx-build -b html -d docs/build/doctrees docs/source docs/build/html -j auto -v

# Another C++ / C extension exclusive task. This task assembles the project wheels, which includes compiling the
# OS- and platform-specific version of the C++ extension. This task should be used on all supported systems (virtual or
# physical) to generate the wheels to be used for end-user distribution. Note, this task is not part of the 'default'
# tox command and has to be called manually, as building the wheels is an intensive process that is only required for
# the release versions of the project (unlike other development steps that, ideally, should be run before any change is
# pushed back to GitHub). The wheels need to be manually uploaded to pip via 'twine' and to conda via the
# greyskull-assisted process.
[testenv:build]
description = Build the package.
extras = build
allowlist_externals =
    docker
    python
deps =
    scikit-build-core
    nanobind
    cibuildwheel
    build
commands =
    # Builds the source distribution in addition to wheels.
    python -m build . --sdist

    # To build linux wheels in addition to native OS on non-native systems, uncomment the line below. Note, this
    # requires dockers. THe docker command is used to quickly catch when the docker is not present.
    cibuildwheel --output-dir dist --platform auto
    docker --version
    cibuildwheel --output-dir dist --platform linux