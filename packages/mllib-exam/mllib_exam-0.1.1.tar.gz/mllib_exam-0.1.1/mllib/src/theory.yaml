- text: |-
      ## 1. **Понятие машинного обучения. Отличие машинного обучения от других областей программирования.**

      Машинное обучение - это численная оптимизация параметрических моделей для описания определенного набора данных.

      Машинное обучение — это область знаний, дающая компьютерам возможность учиться без явного программирования.

      ML позволяет машине решать различные задачи, которые трудно решить алгоритмически. Например, это может быть распознавание лица или голоса вашим телефоном, вождение автомобиля (Google Self-Driving Car), диагностика заболеваний по симптомам (Watson), рекомендация продуктов, книг (Amazon), фильмов (Netflix), музыки (Spotify).

      1. Машинное обучение является частью более широкого понятия - искусственного интеллекта.
      2. Сейчас ученые и инженеры говорят только о “слабом искусственном интеллекте” - способном решать конкретные задачи.
      3. Интеллектуальные технологии позволяют написать программу без явного алгоритма решения задач.
      4. Машинное обучение позволяет решать такие задачи, которые считались невозможными в классическом программировании.
      5. Сейчас машинное обучение используется практически во всех областях человеческой деятельности.
      6. Машинное обучение тесно связано с обработкой больших массивов данных.
      7. Частью машинного обучения является глубокое обучение - оно имеет дело с созданием многослойных искусственных нейронных сетей.

      **Различия:**

      1. Подход к решению задач:
      Традиционное программирование: программист пишет явные правила или инструкции, которым должен следовать компьютер. Эти правила определяют, как именно компьютер должен обрабатывать входные данные для получения желаемого результата.
      Машинное обучение: вместо написания явных правил программист обучает модель, используя большой набор данных. Модель извлекает из данных закономерности и взаимосвязи, что позволяет ей делать прогнозы или принимать решения без явного программирования для каждой возможности.
      2. Зависимость от данных:
      Традиционное программирование в меньшей степени опирается на данные. Качество выходных данных в основном зависит от логики, заданной программистом.
      Машинное обучение в значительной степени зависит от данных. Качество и количество обучающих данных существенно влияют на производительность и точность модели.
      3. Гибкость и адаптируемость:
      Традиционное программирование: обладает ограниченной гибкостью. Изменения в проблемной области требуют ручного обновления кода.
      Машинное обучение: обеспечивает более высокую адаптивность к новым сценариям, особенно если модель переобучается с использованием обновленных данных.
      4. Предсказуемость результатов:
      Традиционное программирование: результат в высшей степени предсказуем, если известны входные данные и логика.
      Машинное обучение: Прогнозы или решения, принимаемые с помощью модели машинного обучения, иногда могут быть менее интерпретируемыми, особенно при использовании сложных моделей, таких как глубокие нейронные сети
- text: |-
      ## **2. Классификация задач машинного обучения. Примеры задач из различных классов**

      **Обучение с учителем** - это задачи предсказания (моделирования) значения некоторой переменной (целевой), которые решаются путем обучения по набору данных, в которых описаны объекты с известными значениями этой переменной.

      **Обучение без учителя** - это задача поиска и описания внутренней структуры в данных, в которых не выделяется отдельно целевая переменная.

      1. Любое машинное обучение заключается в подборе параметров по данным.
      2. Обучение с учителем применяется, когда в обучающей выборке даны “правильные ответы” - значения целевых переменных.
      3. Обучение с учителем подразделяется на задачи регрессии и классификации.
      4. Обучение без учителя нужно, когда в данных нет правильных ответов и нам нужно обнаружить в них внутреннюю структуру.
      5. К задачам обучения без учителя относят кластеризацию, понижение размерности, обнаружение аномалий и другие.
      6. Обучение с учителем и без учителя решает разные задачи.
      7. Выбирают класс задач исходя из решаемой проблемы и имеющихся данных.
      8. Есть еще обучение с подкреплением, которое применяется, например, при создании игровых алгоритмов.

      ПРИМЕР: С учителем – различать собачек от печенек. Без учителя – рекомендательная система Яндекс музыки

      ---
- text: |-
      ## 3. Основные понятия машинного обучения: набора данных, объекты, признаки, атрибуты, модели, параметры

      **Набор данных (Dataset)**: Это коллекция данных, используемых для обучения и оценки модели машинного обучения. Набор данных обычно делится на обучающую выборку (training set) и тестовую выборку (test set). Обучающая выборка используется для создания модели, а тестовая — для её оценки.

      **Объекты (Instances, Samples)**: Объекты представляют собой отдельные элементы или примеры в наборе данных. Например, в наборе данных о погоде каждый объект может представлять собой данные о погоде в конкретный день.

      **Признаки (Features)**: Признаки — это отдельные характеристики или свойства объектов в наборе данных. Например, в наборе данных о погоде такими признаками могут быть температура, влажность, скорость ветра и т.д. Признаки используются для описания объектов и для построения модели.

      **Атрибуты (Attributes)**: Атрибуты часто используются как синонимы признаков. Однако иногда атрибуты могут включать дополнительные метаданные о признаках, такие как их тип (например, числовой или категориальный) и допустимые значения.

      **Модели (Models)**: Модель в машинном обучении — это математическое представление зависимости между входными признаками и целевой переменной (output). Модель создается на основе обучающих данных и используется для предсказания значений целевой переменной для новых данных. Примеры моделей включают линейную регрессию, деревья решений, нейронные сети и т.д.

      **Параметры (Parameters)**: Параметры — это внутренние настройки модели, которые определяются в процессе её обучения. Например, в линейной регрессии параметры включают коэффициенты, которые умножаются на признаки для получения предсказания. В нейронной сети параметры включают веса и смещения (biases) для каждого нейрона.
- text: |-
      ## 4. Структура и представление данных для машинного обучения

      **Табличные данные:**

      - **Строки (Rows)**: Каждая строка представляет собой отдельный объект (пример, образец) в наборе данных.
      - **Столбцы (Columns)**: Каждый столбец соответствует признаку (атрибуту) объекта.
      - **Заголовки столбцов (Column Headers)**: Обычно первый ряд таблицы содержит названия признаков, что позволяет легко идентифицировать каждый признак.

      **Форматы файлов:**

      - **CSV (Comma-Separated Values)**: Один из самых распространённых форматов для табличных данных. Строки данных разделяются запятыми.
      - **Excel (XLS, XLSX)**: Используется для хранения и работы с табличными данными в программах типа Microsoft Excel.
      - **SQL базы данных**: Таблицы в реляционных базах данных, которые могут быть экспортированы в табличные форматы.

      **Матричные данные:**

      - Используются для представления данных в виде матриц, особенно в задачах, связанных с изображениями или текстом.

      Пример: Изображения могут быть представлены в виде трехмерных матриц (высота, ширина, цветовые каналы).

      **Векторные данные (Vector Data)**:

      - Данные представляются в виде векторов признаков. Это часто используется в задачах классификации и регрессии.

      Пример: [5.1, 3.5, 1] — вектор признаков для одного объекта.

      **Типы данных:**

      **Числовые данные**

      - Непрерывные: данные, которые могут принимать любое значение в определенном диапазоне (например, вес, рост).
      - Дискретные: данные, принимающие конечное число значений (например, количество детей в семье).

      **Категориальные данные**

      - Номинативные: данные, представляющие категории без естественного порядка (например, цвета, страны).
      - Порядковые: категории, имеющие естественный порядок (например, уровни образования, оценки).

      **Текстовые данные** : например, отзывы клиентов, статьи, комментарии.

      Временные ряды: данные, упорядоченные по времени (например, цены акций, погодные условия).
- text: |-
      ## 5. Инструментальные средства машинного обучения

      **Языки программирования**

      - **Python**: Наиболее популярный язык программирования для машинного обучения благодаря своему простому синтаксису и обширной экосистеме библиотек.
      - **R**: Часто используется для статистического анализа и визуализации данных.

      **Библиотеки и фреймворки для Python**

      - **NumPy**: Библиотека для работы с многомерными массивами и матрицами, обеспечивающая высокоэффективные математические операции.
      - **Pandas**: Библиотека для манипуляции и анализа данных, предоставляющая удобные структуры данных, такие как DataFrame.
      - **Scikit-learn**: Одна из самых популярных библиотек для машинного обучения, включающая множество алгоритмов для классификации, регрессии, кластеризации и уменьшения размерности.
      - **Matplotlib и Seaborn**: Библиотеки для визуализации данных. Matplotlib предоставляет низкоуровневые инструменты для создания графиков, тогда как Seaborn строит на основе Matplotlib более удобные и информативные графики.

      **Платформы и облачные сервисы**

      - **Google Colab**: Облачная платформа для выполнения Python-кода, предоставляющая доступ к GPU и TPU для ускорения вычислений.
- text: |-
      ## 6. Задача регрессии: постановка, математическая формализация

      Регрессия - это задача машинного обучения с учителем, которая заключается в предсказании некоторой непрерывной величины.

      Примеры регрессионных задач - предсказание цены акции, оценка объекта недвижимости.

      Задача регрессии является одной из фундаментальных задач в машинном обучении и статистике. Она заключается в предсказании числового значения целевой переменной на основе набора входных признаков. Рассмотрим постановку задачи и её математическую формализацию.

      **Постановка задачи регрессии**

      Цель задачи регрессии — научиться предсказывать значение непрерывной целевой переменной yyy на основе вектора входных признаков $\mathbf{x} = (x_1, x_2, \ldots, x_n)$. Примеры задач регрессии включают предсказание цены недвижимости на основе её характеристик, предсказание спроса на продукт, прогнозирование погоды и т.д.

      **Математическая формализация**

      Пусть у нас есть обучающая выборка $(X^{(i)}, y^{(i)})_{i=1}^m$, где:

      - $X^{(i)} = (x_1^{(i)}, x_2^{(i)}, \ldots, x_n^{(i)})$ — вектор признаков для i-го объекта.
      - $y^{(i)}$ — целевая переменная для i-го объекта.
      - m — количество объектов в обучающей выборке.

      Мы предполагаем, что существует некоторая функция f, которая описывает зависимость целевой переменной y от признаков x:

      $$
      y = f(x) + \varepsilon
      $$

      где $\varepsilon$ - случайная ошибка (шум), которая учитывает все факторы, не включённые в X.

      Цель состоит в том, чтобы найти такую оценочную функцию $\hat{f}$, которая минимизирует расхождение между предсказанными значениями $\hat{y} = \hat{f}(x)$ и истинными значениями y.

      В регрессии обычно используется функция потерь для оценки качества предсказаний модели. Одной из наиболее распространённых функций потерь является среднеквадратичная ошибка (MSE):

      $$
      MSE = \frac {1}{m} \sum_{i=1}^{m}(y^{(i)} - \hat f(x^{(i)}))^2
      $$

      Обучение модели заключается в нахождении параметров функции $\hat f$ путём минимизации выбранной функции потерь. В случае линейной регрессии функция $\hat f$ имеет вид:

      $$
      \hat f(x) = w^T \cdot x + b
      $$

      где   w — вектор весов, b — смещение (bias).
- text: |-
      ## 7. Метод градиентного спуска для парной линейной регрессии

      1. Метод градиентного спуска нужен, чтобы найти минимум функции, если мы не можем ее вычислить аналитически.
      2. Это численный итеративный алгоритм локальной оптимизации.
      3. Для запуска градиентного спуска нужно знать частную производную функции ошибки.
      4. Для начала мы берем произвольные значения параметров, затем обновляем их по данной формуле.
      5. Доказано, что этот метод сходится к локальному минимуму.
      6. Если функция ошибки достаточно сложная, то разные начальные точки дадут разный результат.
      7. Метод градиентного спуска имеет свой параметр - скорость обучения. Обычно его подстаивают автоматически.
      8. Метод градиентного спуска повторяют много раз до тех пор, пока функция ошибки не перестанет значимо изменяться.

      Алгоритм градиентного спуска для парной линейной регрессии:
      повторяйте до сходимости:

      $b_0 := b_0 - \alpha \cdot \frac {1}{m} \cdot \sum_{i=1}^{m}(h_b(x_i) - y_i)$

      $b_1 := b_1 - \alpha \cdot \frac {1}{m} \cdot \sum_{i=1}^{m}((h_b(x_i) - y_i) \cdot x_i)$
- text: |-
      ## 8. Понятие функции ошибки: требования, использование, примеры

      1. Функция ошибки нужна для того, чтобы отличать хорошие модели от плохих.
      2. Функция ошибки показывает численно, насколько модель хорошо описывает данные.
      3. Аргументами функции ошибки являются параметры модели, ошибка зависит от них.
      4. Само значение функции ошибки не несет никакого смысла, оно используется только в сравнении.
      5. Цель алгоритма машинного обучения - минимизировать функцию ошибки, то есть найти такой набор параметров модели, при которых ошибка минимальна.
      6. Чаще всего используется так называемая L2-ошибка - средний квадрат отклонений теоретических значений от эмпирических (метрика MSE).
- text: |-
      ## 9. Множественная и нелинейная регрессии

      **Множественная регрессия**

      Множественная регрессия расширяет идею простой линейной регрессии на случай, когда у нас есть несколько входных признаков. Цель заключается в предсказании значения целевой переменной на основе нескольких входных переменных.

      **Модель множественной линейной регрессии**

      Модель множественной линейной регрессии выражается как:

      $h_b (x)=b_0 x_0+b_1 x_1+b_2 x_2+⋯+b_n x_n+e$

      **Метод градиентного спуска:**

      $b_0≔b_0-α \frac{1}{m} ∑_{i=1}^m(h_b (x_i )-y_i )$

      $b_1≔b_1-α \frac{1}{m} ∑_{i=1}^m((h_b (x_i )-y_i )\cdot x_1i )$

      $b_j≔b_j-α \frac{1}{m} ∑_{i=1}^m((h_b (x_i )-y_i )*x_ji )$

      1. Множественная регрессия очень похожа на парную, но с большим количеством признаков.
      2. Для удобства и однообразия, почти всегда обозначают x0=1.
      3. Признаки образуют матрицу, поэтому уравнения множественной регрессии часто приводят в матричной форме, так короче.
      4. Алгоритм градиентного спуска для множественной регрессии точно такой же, как и для парной.

      **Нелинейная регрессия:**

      **Полиномиальная регрессия:**

      $y=b_0+b_1 x+b_2 x^2+b_3 x^3+⋯+e$

      **Гиперболическая регрессия:**

      $y=b_0+ \frac{b_1}{x}  + e$

      $y=\frac{1}{(a+b_1 x_1+b_2 x_2+⋯+b_m x_m+e)}$

      **Логарифмическая регрессия:**

      $y=b_0+b_1 ln(x)+e$

      **Степенная регрессия:**

      $y=b_0*x_1^{b_1}*x_2^{b_2}*x_3^{b_3 }… e$

      **Показательная регрессия:**

      $y=b_0*b_1^x$

      **Экспоненциальная регрессия:**

      $y=e^{a+b_1 x_1+b_2 x_2+⋯+b_m x_m+e}$
- text: |-
      ## 10. Нормализация признаков в задачах регрессии

      $x'=\frac{x-x_{min}}{x_{max}-x_{min}}$

      1. Нормализация нужна для ускорения метода градиентного спуска.
      2. Есть два основных метода нормализации - минимаксная и стандартизация.
      3. Параметры нормализации высчитываются по обучающей выборке.
      4. Нормализация встроена в большинство библиотечных методов.
      5. Некоторые методы более чувствительны к нормализации, чем другие.
      6. Нормализацию лучше сделать, чем не делать.
- text: |-
      ## 11. Задача классификации: постановка, математическая формализация

      - Классификация— задача машинного обучения с учителем, которая выражается в предсказании дискретного значения
      - Если нам неизвестны значения целевой переменной, тогда это задача кластеризации — обучения без учителя.
      - Классификация может быть множественной или бинарной.
      - Примеры: распознавание объектов, подбор тематики текста, идентификация объекта на картинке, распознавание речи (голоса), машинный перевод (подбор слова по контексту), сегментация товаров.
      - Различают одноклассовую и мультиклассовую классификации — объект может принадлежать только одному классу или сразу множеству.

      ---

      ### Мат. формализация

      На вход модели подается вектор признаков $\vec{x}$. Вводится также $a_0 =1$. Функция гипотезы имеет вид: $y=h(x)$.

      Отличие от регрессии в том, что $y$ принимает значение из их конечного числа. $y\in0, 1, ..., k$ ($k$ — кол-во классов)
- text: |-
      ## 12. Метод градиентного спуска для задач классификации

      Метод градиентного спуска (Gradient Descent) — это популярный итеративный метод оптимизации, используемый для нахождения локального минимума функции. Он широко применяется в машинном обучении для минимизации функции потерь, с целью нахождения оптимальных параметров модели. В контексте линейной регрессии метод градиентного спуска используется для нахождения коэффициентов, которые минимизируют ошибку предсказаний.

      ### Основная идея метода градиентного спуска

      Градиентный спуск начинается с начальной точки в пространстве параметров и постепенно движется в направлении наискорейшего убывания функции потерь. Этот процесс повторяется до тех пор, пока не будет достигнут минимум функции.

      ### Основные шаги метода градиентного спуска

      1. **Инициализация**: Задаем начальные значения параметров модели (например, случайным образом или нулями).
      2. **Вычисление градиента**: На каждой итерации вычисляется градиент функции потерь по каждому параметру модели. Градиент — это вектор, указывающий направление наибольшего увеличения функции.
      3. **Обновление параметров**: Параметры модели обновляются в направлении, противоположном градиенту. Шаг обновления определяется с использованием гиперпараметра, называемого шагом обучения (learning rate).
      4. **Повторение**: Процесс вычисления градиента и обновления параметров повторяется до тех пор, пока функция потерь не перестанет существенно уменьшаться или не будет достигнуто заданное количество итераций.
- text: |-
      ## 13. Логистическая регрессия в задачах классификации

      Несмотря на то, что модель называется регрессия, решает она задачу классификации. Название дано по историческим причинам.

      Регрессионные функции, как правило, неограничены. Поэтому необходимо преобразовать функцию гипотезы так, чтобы её значения были ограничены.

      $$
      h_b(x)=g(z)=\frac{1}{1+e^{-z}}
      $$

      Для неё свойственно: $g(z)\in [0, 1]$

      - $\lim_{z \rightarrow -\infty}g(z)=0$
      - $\lim_{z \rightarrow \infty}g(z)=1$

      Функция называется логистической (сигмоидой)

      ![Так выглядит логистическая функция](%D0%A2%D0%B5%D0%BE%D1%80%D0%B8%D1%8F%20%D0%B4%D0%BB%D1%8F%20%D1%8D%D0%BA%D0%B7%D0%B0%D0%BC%D0%B5%D0%BD%D0%B0%204a089ea6dcec4929931f24fdfd488a5a/Untitled.png)

      Так выглядит логистическая функция

      Граница области принятия решений — это линия, которая разделяет область, где $y=1$ и $y=0$. Эта граница создается функцией гипотезы. Так как мы используем линейную функцию внутри логистической, то граница будет линией (или гиперплоскостью).

      Граница области принятия решений существует в любых моделях классификации. Конкретное положение границы определяется в ходе подбора параметров модели.

      Логистическая регрессия покажет хорошие результаты тогда, когда результаты могут быть разделены гиперплоскостью. Такое **свойство данных** называется линейной разделимостью.
- text: |-
      ## 14. Множественная и многоклассовая классификация. Алгоритм “один против всех”

      ### Многоклассовая классификация

      В многоклассовой классификации (multi-class classification) имеется более двух классов, и каждая запись принадлежит только одному классу. Например, распознавание цифр от 0 до 9 является задачей многоклассовой классификации.

      ### Множественная классификация

      В множественной классификации (multi-label classification) каждый экземпляр может принадлежать сразу нескольким классам. Например, классификация жанров фильмов, где один фильм может быть одновременно и комедией, и драмой.

      Алгоритм “один против всех” заключается в рассчете вероятности отнесения наблюдения к каждому классу и выбору максимально вероятного класса для этого наблюдения.

      В случае множественной классификации значение целевой переменной $y=\{0, 1,...,n\}$.

      Алгоритм следующий:

      - Последовательно берётся каждый класс
      - Выбранный класс определяется как положительный. Все остальные отмечаются отрицательными.
      - Обучается модель, которая отделяет данный класс от остальных.
      - В результате получаем множество моделей (столько же, сколько всего классов), которые определяют вероятность отнесения наблюдения к конкретному классу.

      Другими словами, модели выдают вектор вероятности:

      $$
      h_b^{(0)}=P(y=0|x, \vec{b}) \\
      h_b^{(1)}=P(y=1|x, \vec{b}) \\ ...\\
      h_b^{(n)}=P(y=n|x, \vec{b})
      $$

      Выбирается тот класс, чья модель дала наивысший результат.
- text: |-
      ## 15. Метод опорных векторов в задачах классификации

      Метод опорных векторов заключается в поиске такой гиперплоскости, которая имеет максимальный зазор. То есть при выборе гиперплоскости мы руководствуемся не только наименьшей ошибкой, но и максимальным зазором.

      Зазор — это расстояние между границей принятия решения и крайними точками выборки (разных классов). То есть на зазор не влияют точки в глубине класса, а только крайние между классами

      ![Untitled](%D0%A2%D0%B5%D0%BE%D1%80%D0%B8%D1%8F%20%D0%B4%D0%BB%D1%8F%20%D1%8D%D0%BA%D0%B7%D0%B0%D0%BC%D0%B5%D0%BD%D0%B0%204a089ea6dcec4929931f24fdfd488a5a/Untitled%201.png)

      Для этого нужно модифицировать функцию ошибки в модели классификации:

      $$
      y = 1 \Rightarrow X\cdot \vec{b}\ge 1 \\
      y = 0 \Rightarrow X \cdot \vec{b} \le -1
      $$

      То есть хотим, чтобы между границами был зазор. Функция ошибки не будет штрафовать модель за предсказание $\notin [-1, 1]$.
- text: |-
      ## 16. Понятие ядра и виды ядер в методе опорных векторов

      Ядро — это функция (настройка алгоритма), которая определяет форму границы принятия решений.

      ### Виды ядер

      1. Линейное ядро. Часто встречается в задачах с разделимыми данными. Если данные линейно неразделимы, то используется классификация с мягким зазором.

      ![https://github.com/koroteevmv/ML_course/raw/main/ML3.2%20svm/img/ml32-8.png?raw=true](https://github.com/koroteevmv/ML_course/raw/main/ML3.2%20svm/img/ml32-8.png?raw=true)

      1. Радиальное ядро. Может разделять данные, не являющиеся линейно разделимыми.  Создает границу принятия решений в виде радиально-симметричного колокола.

      ![https://github.com/koroteevmv/ML_course/raw/main/ML3.2 svm/img/ml32-11.png?raw=true](<https://github.com/koroteevmv/ML_course/raw/main/ML3.2> svm/img/ml32-11.png?raw=true)

      1. Ядро с полиномиальной функцией. Вводит полиномиальную функцию в пространство признаков для разделения данных.

      ![https://github.com/koroteevmv/ML_course/raw/main/ML3.2 svm/img/ml32-13.png?raw=true](<https://github.com/koroteevmv/ML_course/raw/main/ML3.2> svm/img/ml32-13.png?raw=true)

      Есть и другие ядра.

      В случае, если зазора между данными нет, используется метод опорных векторов с мягким зазором. Для этого уменьшается параметр регуляризации $C$
- text: |-
      ## 17. Метод решающих деревьев в задачах классификации

      Метод решающих деревьев похож на логику рассуждения человека, если бы ему дали порассуждать над какими-то данными. Её можно представить в виде блок схемы — легко интерпретируемый метод.

      1. Во время обучения модели выбирается фактор и его граница разделения классов так, чтобы добиться максимальной однородности выборок после разделения. Причем деление необязательно должно быть равномерным
      2. Выбор границы принятия решения определяется минимизацией информационной энтропии или минимизацией коэффициента Джини.
      3. В случае, если в результате деления у нас получилось выделить выборку, состоящую из 1 класса, то эту ветку можно дальше не продолжать. То есть в этой ветке рост дерева остановится
      4. Мы можем продолжить рост дерева (рассматривая каждую половину дерева отдельно) или прекратить деление.

      При достаточно высоком количестве уровней дерево решений опишет обучающую выборку без ошибок. Поэтому, тем сложнее модель, тем больше она подвержена переобучению.
- text: |-
      ## 18. Метод k ближайших соседей в задачах классификации

      Метод k-ближайших соседей — это метод, который относит объект к классу на основании классов $k$ ближайших объектов. То есть для каждого объекта находится ближайшая точка обучающей выборки и определяется, к какому классу она относится. Метод опирается на гипотезу компактности:

      **Гипотеза компактности —** объекты с похожими характеристиками скорее будут относиться к одинаковому классу или будут иметь похожие значения целевой переменной, чем разные

      С увеличением $k$ граница будет проще, проще будет модель. Если гиперпараметр $k$ будет равен $n$=объему выборки, то модель всегда будет предсказывать самый популярный класс. Стартовое значение выбирают как $k=\sqrt{n}$ (эмпирическое правило).

      Коллизии — это момент, когда среди $k$ ближайших соседей во множественной регрессии у нас получается ничья. Это решается, например, рангом. То есть ближайшие соседи имеют бóльший вес.
- text: |-
      ## 19. Однослойный перцептрон в задачах классификации

      - Перцептрон — простейший случай частной работы нейронной сети. Нейронные сети — самый популярный метод обучения с учителем. Они позволяют построить сложные и масштабируемые модели.
      - Плюс нейронных сетей — распараллеливание обучения и применения. Их работу можно ускорить с помощью графических ядер
      - Минус — сложная интерпретация.
      - Главный параметр — количество слоёв. Если их больше 1, то нейросеть называется глубокой.
      - Они очень естественно решают задачу множественной и мультиклассовой классификации

      Нейронные сети пытаются смоделировать работу нейрона и мозга  

      ---

      В перцептроне работает следующая схема работы:

      - Входные параметры $x_1, ..., x_n$ (а также $x_0$ называемый bias=1) умножаются на веса (веса — это параметры модели, которые в ходе обучения будут изменяться) $w_0, w_1, ..., w_n$
      - Считается взвешенная сумма входных значений
      - Она проходит через функцию активации $h(x)$: сигмоидальная, арктангенс, ReLU, Leaky ReLU и другие.

      Веса показывают, насколько чувствителен нейрон к появлению конкретного сигнала

      Нейроны могут соединяться друг с другом (то есть на вход одного нейрона подставить выход другого). Таким образом образуются три слоя:

      1. Входной слой: $x_1, ..., x_n$
      2. Скрытый слой: $A_1, ..., A_n$. В случае с перцептроном всё значения предыдущего слоя подаются на следующий слой каждому нейрону (то есть каждый $x_i$ к $A_1$, потом $x_i$ к $A_2$ и т.д.)
      3. Выходной слой $h(x)$ → Вывод

      Схема соединения нейронов называется архитектура нейронной сети.

      Так как (см. пункт №2 в слоях) Перцептрон называют полносвязной нейронной сетью прямого распространения.

      **Полносвязный** = все связи предыдущего и следующего слоя есть. И нет никаких обратных, зацикленных, через слой быть не может.
- text: |-
      ## 20. Метрики эффективности и функции ошибки: назначение, примеры, различия

      Метрики эффективности и функции ошибки - это два важных понятия в машинном обучении, которые играют ключевую роль в оценке качества модели и оптимизации ее обучения. Хотя они тесно связаны, их назначение и использование имеют некоторые различия.

      Метрики эффективности

      - Назначение: Метрики эффективности используются для оценки производительности обученной модели на новых данных, которые не были использованы в процессе обучения. Они позволяют сравнивать разные модели и выбирать лучшую для конкретной задачи.
      - Примеры:
        - Точность (Accuracy): Доля правильно классифицированных образцов.
        - Точность (Precision): Доля правильно классифицированных положительных образцов среди всех предсказанных как положительные.
        - Полнота (Recall): Доля правильно классифицированных положительных образцов среди всех фактических положительных образцов.
        - F1-мера (F1-score): Гармоническое среднее между точностью и полнотой.
        - AUC-ROC (Area Under the Receiver Operating Characteristic Curve): Площадь под кривой ROC, которая показывает, насколько хорошо модель может различать положительные и отрицательные образцы.
        - Среднеквадратичная ошибка (MSE): Среднее квадратов ошибок предсказаний модели.
        - Средняя абсолютная ошибка (MAE): Среднее абсолютных значений ошибок предсказаний модели.
      - Применение: Метрики эффективности используются для:
        - Оценки качества обученной модели.
        - Сравнения разных моделей.
        - Выбора лучшей модели для конкретной задачи.
        - Настройки гиперпараметров модели.

      Функции ошибки

      - Назначение: Функции ошибки используются во время обучения модели для измерения отклонения предсказаний модели от реальных значений. Эта информация используется алгоритмом оптимизации для обновления весов модели и уменьшения ошибки.
      - Примеры:
        - Среднеквадратичная ошибка (MSE): Часто используется для регрессии, где мы хотим минимизировать разницу между предсказанными и реальными значениями.
        - Кросс-энтропия (Cross-entropy): Часто используется для классификации, где мы хотим максимизировать вероятность правильной классификации.
        - Hinge loss: Используется в методах машинного обучения с максимальным запасом (SVM).
      - Применение: Функции ошибки используются для:
        - Оптимизации весов модели во время обучения.
        - Уменьшения ошибки предсказаний модели.
        - Настройки гиперпараметров модели.

      Различия между метриками эффективности и функциями ошибки:

      - Применение: Метрики эффективности используются после обучения модели, чтобы оценить ее качество, а функции ошибки используются во время обучения модели для ее оптимизации.
      - Цель: Метрики эффективности предназначены для оценки качества модели, а функции ошибки для уменьшения ошибки предсказаний.
      - Использование: Метрики эффективности могут быть разными для разных задач, но функции ошибки обычно выбираются в зависимости от используемого алгоритма обучения.

      Пример:

      Представьте, что вы обучили модель для классификации изображений кошек и собак.

      - Функция ошибки может быть кросс-энтропией, которая измеряет, насколько хорошо модель предсказывает правильный класс для каждого изображения.
      - Метрика эффективности может быть точностью, которая измеряет, какая доля изображений была правильно классифицирована.

      Таким образом, функция ошибки используется во время обучения модели для ее оптимизации, а метрика эффективности используется после обучения модели для оценки ее качества.
- text: |-
      ## 21. **Понятие набора данных (датасета) в машинном обучении. Требования, представление. Признаки и объекты.**

      Набор данных (датасет) — это структурированная коллекция данных, используемая для обучения и тестирования моделей машинного обучения. Он состоит из множества объектов (также называемых примерами или строками) и признаков (также называемых атрибутами или столбцами).

      Требования к набору данных:

      - Репрезентативность: Датасет должен отражать реальные условия, для которых будет использоваться модель.
      - Качество: Данные должны быть точными, полными и последовательными.
      - Объем: Достаточное количество данных для обучения модели.
      - Разнообразие: Датасет должен содержать разнообразные данные, чтобы модель могла обучиться обобщению на новые данные.
      - Релевантность: Данные должны быть релевантными к решаемой задаче.

      Представление набора данных:

      - Табличная форма: Данные представлены в виде таблицы, где строки соответствуют объектам, а столбцы - признакам.
      - Матричная форма: Данные представлены в виде матрицы, где каждая строка представляет объект, а каждый столбец - признак.
      - Графическая форма: Данные могут быть представлены в виде графиков, диаграмм и других визуализаций.

      Признаки (атрибуты):

      - Независимые переменные: Признаки, которые используются для прогнозирования целевой переменной.
      - Зависимые переменные: Признаки, которые предсказываются моделью.
      - Количественные: Признаки, которые представляют числовые значения (например, возраст, температура).
      - Категориальные: Признаки, которые представляют категориальные значения (например, пол, цвет).

      Объекты (примеры):

      - Строки в табличном представлении: Каждый объект представляет собой отдельную запись в наборе данных.
      - Векторы в матричном представлении: Каждый объект представлен вектором, где каждый элемент вектора соответствует значению определенного признака.

      Пример:

      Рассмотрим набор данных для прогнозирования цен на жилье.

      - Объекты: Отдельные дома.
      - Признаки: Площадь, количество комнат, район, возраст дома, цена (целевая переменная).

      Важно:  Выбор правильного датасета,  подготовка данных и  использование  соответствующих  методов  предобработки   являются  ключевыми  факторами  для  достижения  высокой  точности  и  надежности  модели  машинного  обучения.

      Метрики эффективности и функции ошибки - это два важных понятия в машинном обучении, которые играют ключевую роль в оценке качества модели и оптимизации ее обучения. Хотя они тесно связаны, их назначение и использование имеют некоторые различия.

      Метрики эффективности

      - Назначение: Метрики эффективности используются для оценки производительности обученной модели на новых данных, которые не были использованы в процессе обучения. Они позволяют сравнивать разные модели и выбирать лучшую для конкретной задачи.
      - Примеры:
        - Точность (Accuracy): Доля правильно классифицированных образцов.
        - Точность (Precision): Доля правильно классифицированных положительных образцов среди всех предсказанных как положительные.
        - Полнота (Recall): Доля правильно классифицированных положительных образцов среди всех фактических положительных образцов.
        - F1-мера (F1-score): Гармоническое среднее между точностью и полнотой.
        - AUC-ROC (Area Under the Receiver Operating Characteristic Curve): Площадь под кривой ROC, которая показывает, насколько хорошо модель может различать положительные и отрицательные образцы.
        - Среднеквадратичная ошибка (MSE): Среднее квадратов ошибок предсказаний модели.
        - Средняя абсолютная ошибка (MAE): Среднее абсолютных значений ошибок предсказаний модели.
      - Применение: Метрики эффективности используются для:
        - Оценки качества обученной модели.
        - Сравнения разных моделей.
        - Выбора лучшей модели для конкретной задачи.
        - Настройки гиперпараметров модели.

      Функции ошибки

      - Назначение: Функции ошибки используются во время обучения модели для измерения отклонения предсказаний модели от реальных значений. Эта информация используется алгоритмом оптимизации для обновления весов модели и уменьшения ошибки.
      - Примеры:
        - Среднеквадратичная ошибка (MSE): Часто используется для регрессии, где мы хотим минимизировать разницу между предсказанными и реальными значениями.
        - Кросс-энтропия (Cross-entropy): Часто используется для классификации, где мы хотим максимизировать вероятность правильной классификации.
        - Hinge loss: Используется в методах машинного обучения с максимальным запасом (SVM).
      - Применение: Функции ошибки используются для:
        - Оптимизации весов модели во время обучения.
        - Уменьшения ошибки предсказаний модели.
        - Настройки гиперпараметров модели.

      Различия между метриками эффективности и функциями ошибки:

      - Применение: Метрики эффективности используются после обучения модели, чтобы оценить ее качество, а функции ошибки используются во время обучения модели для ее оптимизации.
      - Цель: Метрики эффективности предназначены для оценки качества модели, а функции ошибки для уменьшения ошибки предсказаний.
      - Использование: Метрики эффективности могут быть разными для разных задач, но функции ошибки обычно выбираются в зависимости от используемого алгоритма обучения.

      Пример:

      Представьте, что вы обучили модель для классификации изображений кошек и собак.

      - Функция ошибки может быть кросс-энтропией, которая измеряет, насколько хорошо модель предсказывает правильный класс для каждого изображения.
      - Метрика эффективности может быть точностью, которая измеряет, какая доля изображений была правильно классифицирована.

      Таким образом, функция ошибки используется во время обучения модели для ее оптимизации, а метрика эффективности используется после обучения модели для оценки ее качества.
- text: |-
      ## 22. **Шкалы измерения признаков. Виды шкал, их характеристика**

      Шкала измерения признака определяет, как мы можем интерпретировать и сравнивать значения этого признака. Разные типы шкал имеют разные свойства и ограничения, которые влияют на выбор алгоритмов машинного обучения и способ интерпретации результатов.

      Основные типы шкал:

      1. Номинальная шкала:
          - Используется для категориальных признаков, где значения не могут быть упорядочены.
          - Пример: цвет, пол, марка автомобиля.
          - Операции: равенство, неравенство.
      2. Порядковая шкала:
          - Используется для категориальных признаков, где значения могут быть упорядочены, но расстояние между значениями не имеет смысла.
          - Пример: образование (начальное, среднее, высшее), уровень удовлетворенности (низкий, средний, высокий).
          - Операции: равенство, неравенство, сравнение порядка (больше, меньше).
      3. Интервальная шкала:
          - Используется для количественных признаков, где значения могут быть упорядочены, а расстояние между значениями имеет смысл.
          - Пример: температура по Цельсию, время.
          - Операции: все операции с порядковой шкалой + сложение, вычитание, нахождение среднего.
          - Особенность: нет абсолютного нуля (0 градусов по Цельсию не означает отсутствие температуры).
      4. Отношение шкала:
          - Используется для количественных признаков, где значения могут быть упорядочены, расстояние между значениями имеет смысл, и есть абсолютный ноль.
          - Пример: рост, вес, возраст, количество.
          - Операции: все операции с интервальной шкалой + деление, умножение, нахождение отношения.

      Примеры применения различных шкал в машинном обучении:

      - Номинальная шкала:
        - Классификация: предсказание типа документа, типа товара.
        - Кластеризация: группировка пользователей по интересам, сегментация клиентов.
      - Порядковая шкала:
        - Классификация: предсказание уровня риска кредита.
        - Регрессия: предсказание рейтинга фильма.
      - Интервальная шкала:
        - Регрессия: предсказание температуры.
        - Кластеризация: группировка пользователей по активности.
      - Отношение шкала:
        - Регрессия: предсказание стоимости недвижимости.
        - Кластеризация: группировка пользователей по уровню дохода.

      Выбор подходящей шкалы:

      - Тип признака: определяет, какая шкала подходит для него.
      - Задача машинного обучения: требования к данным зависят от задачи.
      - Алгоритмы машинного обучения: некоторые алгоритмы работают только с определенными типами шкал.

      Преобразование шкал:

      - One-hot encoding: преобразование номинальных и порядковых признаков в набор бинарных признаков.
      - Ordinal encoding: преобразование порядковых признаков в числовые значения.
      - Standardization: масштабирование количественных признаков к единому диапазону.

      Важно:  правильный выбор и преобразование шкал играет важную роль в качестве моделей машинного обучения.
- text: |-
      ## 23. Понятие чистых данных. Определение, очистка данных

      Чистые данные в машинном обучении - это данные, которые свободны от ошибок, несоответствий, дубликатов и пропусков. Они представляют собой достоверную, полную и согласованную информацию, готовую к использованию в алгоритмах машинного обучения.

      Почему чистые данные важны?

      - Повышение точности моделей: Некорректные данные приводят к ошибкам в обучении модели и, как следствие, к неверным прогнозам.
      - Сокращение времени разработки: Очистка данных позволяет сэкономить время, которое было бы потрачено на исправление ошибок в уже обученной модели.
      - Улучшение интерпретации результатов: Чистые данные позволяют получить более точные и достоверные результаты модели.
      - Снижение рисков: Неправильные данные могут привести к принятию ошибочных решений, что может иметь серьезные последствия.

      Очистка данных - это процесс удаления ошибок, несоответствий, дубликатов и пропусков из данных. Это важный этап подготовки данных к машинному обучению.

      Основные методы очистки данных:

      - Удаление дубликатов: Удаление повторяющихся записей в данных.
      - Заполнение пропусков: Замена пропущенных значений на основе имеющихся данных (например, средним значением, медианой, методом ближайшего соседа).
      - Исправление ошибок: Исправление некорректных значений в данных.
      - Нормализация данных: Преобразование данных к единому масштабу для улучшения производительности модели.
      - Трансформация данных: Преобразование данных в другой формат (например, категориальные данные в числовые).

      Примеры проблем с данными:

      - Некорректные значения: Опечатки, неправильный формат данных.
      - Пропущенные значения: Отсутствие данных в некоторых полях.
      - Дубликаты: Повторяющиеся записи.
      - Несоответствия: Несовместимые данные в разных источниках.

      Важно отметить:

      - Очистка данных - это итеративный процесс, который может потребовать нескольких шагов.
      - Выбор методов очистки данных зависит от типа данных и целей машинного обучения.
      - Необходимо тщательно проверить очищенные данные перед использованием их в модели.
- text: |-
      ## **24. Основные этапы проекта по машинному обучению.**

      1. Определение типа задачи машинного обучения
      2. Подготовка данных
          1. Сбор / поиск датасета
          2. Очистка данных от nan и выбросов
          3. Избавление от регрессии
          4. Нормализация значений
          5. Преобразование категориальных признаков
          6. Балансирование классов
      3. Выбор модели
          1. Обучение различных моделей
          2. Выбор лучшей модели
      4. Улучшение модели
          1. Подбор гиперпараметров
          2. Выбор значащих признаков
          3. Исправление недо / переобучения
      5. Оценка модели на валидационной выборке
- text: |-
      ## **25. Предварительный анализ данных: задачи, методы, цели.**

      Предварительный анализ данных (EDA - Exploratory Data Analysis) - это ключевой этап в машинном обучении, который позволяет получить глубокое понимание данных и подготовить их для дальнейшей обработки. Он включает в себя ряд задач, использующих различные методы и направлен на достижение определенных целей.

      Задачи предварительного анализа данных:

      - Понимание данных:
        - Определение типов данных (категориальные, числовые, текстовые), их структуры, формата и источников.
        - Выявление наличия пропущенных значений, дубликатов и несоответствий.
        - Поиск аномалий и выбросов.
        - Изучение распределения данных, выявление закономерностей и зависимостей.
      - Предобработка данных:
        - Очистка данных: удаление дубликатов, заполнение пропусков, исправление ошибок.
        - Трансформация данных: преобразование данных в более удобный формат, например, стандартизация или нормализация.
        - Снижение размерности: удаление нерелевантных признаков, использование методов dimensionality reduction (PCA, t-SNE).
        - Обработка категориальных данных: преобразование в числовой формат (One-Hot Encoding, Label Encoding).
      - Визуализация данных:
        - Создание различных графиков и диаграмм для визуального анализа распределения данных, выявления закономерностей и аномалий.
        - Использование интерактивных инструментов для удобной работы с данными.

      Методы предварительного анализа данных:

      - Статистические методы:
        - Описательная статистика: среднее, медиана, мода, дисперсия, стандартное отклонение.
        - Корреляционный анализ: определение взаимосвязей между переменными.
        - Гистограммы, box plots, scatter plots.
      - Визуализация данных:
        - Гистограммы, box plots, scatter plots.
        - Heatmaps, dendrograms, parallel coordinates.
      - Методы машинного обучения:
        - Кластеризация: группировка данных по схожим признакам.
        - Редукция размерности: PCA, t-SNE.

      Цели предварительного анализа данных:

      - Повышение качества модели машинного обучения:
        - Устранение ошибок в данных и улучшение их качества.
        - Преобразование данных в формат, подходящий для алгоритма машинного обучения.
        - Определение наиболее важных признаков и снижение размерности данных.
      - Глубокое понимание данных:
        - Выявление закономерностей и зависимостей в данных.
        - Поиск аномалий и выбросов.
        - Построение гипотез о природе данных.
      - Оптимизация процесса разработки модели:
        - Выбор подходящего алгоритма машинного обучения.
        - Определение параметров модели.
        - Проверка качества модели на тестовых данных.

      Примеры применения предварительного анализа данных:

      - Анализ медицинских данных: выявление факторов риска развития заболеваний, оптимизация диагностики и лечения.
      - Анализ данных электронной коммерции: прогнозирование продаж, выявление покупательских предпочтений, персонализация рекомендаций.
      - Анализ данных в финансах: выявление мошеннических транзакций, прогнозирование рыночной активности, оптимизация инвестиционного портфеля.

      Важно:

      - Предварительный анализ данных - это итеративный процесс, который может потребовать много времени и усилий.
      - Важно использовать различные методы и подходы для получения полного и комплексного представления о данных.
      - Необходимо быть внимательным к выбору методов и интерпретации результатов анализа.
- text: |-
      ## 26. Проблема отсутствующих данных: причины, исследование, пути решения

      Проблема отсутствующих данных является распространенной в области анализа данных и машинного обучения. Она возникает, когда часть данных отсутствует в исходном наборе данных. Рассмотрим подробнее причины, методы исследования и стратегии решения этой проблемы.

      ### Причины отсутствия данных

      1. **Несбалансированность сбора данных:**
          - Некоторые данные могут быть не собраны в исходном процессе, из-за чего они отсутствуют в наборе данных.
      2. **Проблемы при передаче данных:**
          - В процессе передачи данных могут возникнуть ошибки, которые приводят к их частичной потере.
      3. **Ошибки в процессе сбора данных:**
          - Некорректно настроенное оборудование или программное обеспечение может привести к потере части данных.
      4. **Необязательные поля:**
          - В некоторых случаях пользователь может пропустить заполнение полей, если они необязательные.
      5. **Естественная недоступность данных:**
          - Например, при мониторинге определенных параметров, данные могут быть недоступны в определенные моменты времени.

      ### Исследование отсутствующих данных

      Для эффективного решения проблемы отсутствующих данных важно провести детальное исследование, чтобы понять, где и почему данные отсутствуют.

      1. **Анализ пропусков:**
          - Исследование структуры данных для определения количества и распределения отсутствующих значений.
      2. **Проверка на случайные пропуски:**
          - Определение, случайны ли пропуски, или они имеют какие-то закономерности.
      3. **Корреляция с другими переменными:**
          - Анализ взаимосвязи между пропущенными данными и другими переменными может помочь выявить причины отсутствия данных.
      4. **Исследование влияния на анализ:**
          - Оценка влияния отсутствующих данных на результаты анализа и моделирования.

      ### Пути решения проблемы отсутствующих данных

      После проведения исследования необходимо принять меры для обработки отсутствующих данных:

      1. **Удаление пропущенных значений:**
          - Если пропусков немного и они случайны, можно удалить строки или столбцы с отсутствующими данными.
      2. **Заполнение пропусков:**
          - Заполнение отсутствующих данных средними или медианными значениями для числовых переменных.
          - Использование моды для категориальных переменных.
          - Использование методов машинного обучения для предсказания пропущенных значений на основе остальных данных.
      3. **Использование специальных моделей:**
          - Использование специальных моделей, способных работать с отсутствующими данными (например, модели, учитывающие веса данных).
      4. **Улучшение процесса сбора данных:**
          - Оптимизация процесса сбора данных, чтобы минимизировать возможные ошибки и пропуски.
      5. **Информирование о пропусках:**
          - При анализе данных важно документировать пропуски и принятые методы их обработки для повышения прозрачности и повторяемости исследования.
- text: |-
      ## 27. Проблема несбалансированных классов: исследование, пути решения

      Проблема несбалансированных классов в задачах машинного обучения возникает, когда количество образцов одного класса значительно превышает количество образцов другого класса. Это может привести к нежелательным последствиям при обучении моделей, таким как смещение в сторону часто встречающегося класса и недообучение на редко встречающемся классе. Рассмотрим подробнее исследование проблемы и возможные пути ее решения.

      ### Исследование проблемы несбалансированных классов

      1. **Анализ распределения классов:**
          - Подсчет количества образцов каждого класса в обучающем наборе данных.
          - Визуализация распределения классов (например, с помощью диаграммы или гистограммы).
      2. **Оценка влияния на модель:**
          - Изучение влияния несбалансированных классов на производительность модели.
          - Анализ ошибок модели в контексте несбалансированных классов.
      3. **Идентификация причин несбалансированности:**
          - Понимание, почему определенные классы являются редкими или частыми в данных.
          - Рассмотрение внешних факторов или специфики задачи, влияющих на распределение классов.

      ### Пути решения проблемы несбалансированных классов

      1. **Использование взвешивания классов:**
          - Веса классов можно настроить таким образом, чтобы модель учитывала баланс классов в процессе обучения.
          - Это часто реализуется через параметр `class_weight` в алгоритмах машинного обучения.
      2. **Использование алгоритмов с учетом несбалансированных классов:**
          - Некоторые алгоритмы машинного обучения (например, RandomForest, XGBoost) имеют встроенную поддержку для работы с несбалансированными классами.
          - Использование алгоритмов, специально разработанных для работы с несбалансированными данными, таких как алгоритмы адаптации границы решения (Boundary-Sensitive Learning).

      В задачах классификации может быть сильный дисбаланс целевых классов, что может плохо влиять на обучение. Увидеть это проще всего построив гистограмму. Решением может являться удаление экземпляров мажоритарного класса или добавление экземпляров миноритарного класса (например за счет дублирования)
- text: |-
      ## 28. Понятие параметров и гиперпараметров модели. Обучение параметров и гиперпараметров. Поиск по сетке

      ### Понятие параметров и гиперпараметров модели

      **Параметры модели** — это внутренние параметры модели, которые обучаются во время процесса обучения. Они напрямую влияют на прогнозы модели и обновляются в ходе обучения. Примеры параметров:

      - Коэффициенты в линейной регрессии.
      - Веса и смещения (bias) в нейронных сетях.

      **Гиперпараметры модели** — это параметры, которые задаются до начала обучения и не изменяются в процессе обучения модели. Они определяют, как именно модель будет обучаться. Примеры гиперпараметров:

      - Скорость обучения (learning rate).
      - Количество слоев и количество нейронов в каждом слое нейронной сети.
      - Количество деревьев в случайном лесе.
      - Параметры регуляризации (например, коэффициент L2-регуляризации).

      **Обучение параметров** происходит следующим образом:

      1. **Инициализация параметров:** Обычно случайными значениями.
      2. **Прямой проход (forward pass):** Вычисление прогнозов модели на основе текущих параметров.
      3. **Вычисление функции потерь:** Определение разницы между прогнозами модели и истинными значениями.
      4. **Обратный проход (backward pass):** Вычисление градиентов функции потерь по отношению к параметрам модели.
      5. **Обновление параметров:** С использованием метода оптимизации (например, градиентный спуск).

      **Настройка гиперпараметров** включает в себя:

      1. **Выбор сетки гиперпараметров:** Определение возможных значений гиперпараметров, которые нужно протестировать.
      2. **Обучение модели для каждой комбинации гиперпараметров:** На тренировочном наборе данных.
      3. **Оценка качества моделей:** Использование метрики на валидационном наборе данных для оценки производительности каждой комбинации гиперпараметров.
      4. **Выбор наилучшей комбинации гиперпараметров:** Комбинация, которая дает наилучший результат на валидационном наборе данных.

      **Поиск по сетке (Grid Search)** — это метод автоматического подбора гиперпараметров модели путем исчерпывающего перебора всех возможных комбинаций заданного набора гиперпараметров.

      Основные шаги поиска по сетке:

      1. **Определение гиперпараметров и их возможных значений:** Например, для случайного леса можно задать количество деревьев (10, 50, 100) и глубину деревьев (5, 10, 15).
      2. **Создание сетки:** Формирование всех возможных комбинаций значений гиперпараметров.
      3. **Обучение моделей:** Для каждой комбинации гиперпараметров обучается отдельная модель.
      4. **Оценка производительности:** Для каждой модели вычисляется значение метрики на валидационном наборе данных.
      5. **Выбор наилучших гиперпараметров:** Комбинация гиперпараметров, которая показала наилучшее значение метрики, считается оптимальной.
- text: |-
      ## 29. Понятие недо- и переобучения. Определение, пути решения

      **Недообучение (underfitting)** — это ситуация, когда модель недостаточно хорошо обучается на тренировочных данных, и, следовательно, не улавливает основные закономерности в данных. Такая модель показывает низкую точность как на тренировочных, так и на тестовых данных.

      **Переобучение (overfitting)** — это ситуация, когда модель слишком хорошо подстраивается под тренировочные данные, включая шум и выбросы, что приводит к снижению её обобщающей способности. Модель показывает высокую точность на тренировочных данных, но низкую точность на тестовых данных.

      ### Определение недообучения и переобучения

      **Недообучение:**

      - Низкая точность на тренировочных данных.
      - Низкая точность на тестовых данных.
      - Модель слишком проста для данных.

      **Переобучение:**

      - Высокая точность на тренировочных данных.
      - Низкая точность на тестовых данных.
      - Модель слишком сложная и подстраивается под каждую деталь тренировочных данных.

      **Пути решения недообучения:**

      1. **Усложнение модели:** Использование более сложных моделей (например, увеличение количества слоев и нейронов в нейронной сети).
      2. **Добавление новых признаков:** Включение дополнительных характеристик в модель, которые могут содержать полезную информацию.
      3. **Увеличение времени обучения:** Использование большего числа эпох или итераций для улучшения обучения модели.
      4. **Использование более сложных алгоритмов:** Например, переход от линейной регрессии к полиномиальной регрессии.

      **Пути решения переобучения:**

      1. **Регуляризация:** Использование методов регуляризации, таких как L1, L2 или Dropout, которые ограничивают сложность модели.
      2. **Сбор большего количества данных:** Увеличение объема тренировочных данных, чтобы модель могла лучше обобщать.
      3. **Применение кросс-валидации:** Использование методов кросс-валидации для оценки модели и предотвращения переобучения.
      4. **Уменьшение сложности модели:** Использование более простых моделей, чтобы избежать подстройки под шум.
      5. **Добавление шума в данные:** Искусственное добавление шума в тренировочные данные для улучшения обобщающей способности модели.
- text: |-
      ## 30. Диагностика модели машинного обучения. Методы, цели

      Диагностика модели машинного обучения — это процесс оценки и анализа модели для определения её качества, выявления проблем и поиска путей для их устранения. Основные цели диагностики включают:

      1. **Оценка производительности модели:**
          - Определение точности модели на различных наборах данных (тренировочном, валидационном, тестовом).
          - Сравнение производительности с базовыми моделями или предыдущими версиями моделей.
      2. **Выявление проблем:**
          - Обнаружение недообучения или переобучения.
          - Идентификация смещений и разброса (bias-variance tradeoff).
          - Обнаружение проблем с данными, таких как выбросы, пропуски данных или неправильная разметка.
      3. **Оптимизация и улучшение модели:**
          - Подбор гиперпараметров.
          - Выбор оптимальных признаков и методов их обработки.
          - Улучшение обобщающей способности модели.

      ### Методы диагностики модели

      1. **Разделение данных:**
          - **Тренировочный набор данных (Training set):** Для обучения модели.
          - **Валидационный набор данных (Validation set):** Для подбора гиперпараметров и оценки производительности модели в процессе обучения.
          - **Тестовый набор данных (Test set):** Для окончательной оценки производительности модели.
      2. **Кросс-валидация (Cross-validation):**
          - **K-fold кросс-валидация:** Разделение данных на K частей и проведение K экспериментов, где каждая часть по очереди используется как тестовый набор, а остальные как тренировочные.
          - **Stratified k-fold:** Кросс-валидация с сохранением пропорций классов.
      3. **Метрики оценки:**
          - **Классификация:** Accuracy, Precision, Recall, F1-score, ROC-AUC.
          - **Регрессия:** Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), R².
      4. **Learning curves (Кривые обучения):**
          - Графики, показывающие зависимость ошибки на тренировочных и валидационных данных от числа обучающих примеров.
          - Помогают определить, страдает ли модель от недообучения или переобучения.
      5. **Validation curves (Кривые валидации):**
          - Графики, показывающие зависимость ошибки на тренировочных и валидационных данных от значений гиперпараметра.
          - Помогают в подборе оптимальных гиперпараметров.
      6. **Confusion matrix (Матрица ошибок):**
          - Таблица, показывающая распределение предсказанных и истинных классов.
- text: |-
      ## 31. Проблема выбора модели машинного обучения. Сравнение моделей

      Выбор модели машинного обучения — это критический шаг, который значительно влияет на производительность и эффективность системы. Основные аспекты, которые следует учитывать при выборе модели, включают:

      1. **Сложность модели:**
          - Простой модели может не хватать мощности для захвата всех сложностей данных (недообучение).
          - Сложная модель может слишком подстроиться под тренировочные данные, включая шум (переобучение).
      2. **Характеристики данных:**
          - Размер данных: Большие данные требуют моделей, которые могут масштабироваться.
          - Тип данных: Время, текст, изображения, числовые данные и т.д.
          - Присутствие пропусков, выбросов и дисбаланс классов.
      3. **Цель задачи:**
          - Регрессия или классификация.
          - Одноклассовая или многоклассовая классификация.
      4. **Производительность:**
          - Время обучения и предсказания.
          - Потребление памяти и вычислительных ресурсов.
      5. **Интерпретируемость:**
          - Некоторые модели, такие как линейная регрессия и решающие деревья, легко интерпретируемы.
          - Другие, такие как нейронные сети, являются "черными ящиками".

      Для выбора наилучшей модели необходимо провести сравнение нескольких моделей по ряду критериев. Основные этапы сравнения моделей включают:

      1. **Выбор метрик оценки:**
          - Классификация: Accuracy, Precision, Recall, F1-score, ROC-AUC.
          - Регрессия: MAE, MSE, RMSE, R².
      2. **Кросс-валидация:**
          - K-fold кросс-валидация для оценки устойчивости модели.
          - Stratified K-fold кросс-валидация для сохранения пропорций классов в случае несбалансированных данных.
      3. **Сравнение результатов:**
          - Использование выбранных метрик для оценки каждой модели.
          - Построение таблиц и графиков для визуального сравнения.
      4. **Анализ кривых обучения и валидации:**
          - Построение и анализ кривых обучения для выявления недообучения или переобучения.
          - Построение и анализ кривых валидации для подбора оптимальных гиперпараметров.
- text: |-
      ## 32. Измерение эффективности работы моделей машинного обучения. Метрики эффективности

      Измерение эффективности работы моделей машинного обучения осуществляется с помощью различных метрик оценки. Выбор метрики зависит от задачи, которую решает модель (классификация, регрессия, кластеризация и т.д.). Ниже рассмотрены основные метрики для классификационных и регрессионных задач.

      ### Метрики эффективности для классификационных задач

      1. **Accuracy (Точность)**
          - Доля правильно предсказанных экземпляров к общему числу экземпляров.
          - $\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}$, TP — True Positive, FN — False Negative, TN, FP — соответственно.
          - Подходит для задач с равномерным распределением классов.
      2. **Precision (Точность)**
          - Доля правильно предсказанных положительных экземпляров к общему числу предсказанных положительных экземпляров.
          - $\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}$
          - Важна, когда стоимость ложных срабатываний (FP) высока.
      3. **Recall (Полнота)**
          - Доля правильно предсказанных положительных экземпляров к общему числу истинных положительных экземпляров.
          - $\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}$
          - Важна, когда стоимость пропущенных положительных случаев (FN) высока.
      4. **F1-score**
          - Гармоническое среднее Precision и Recall.
          - $\text{F1-score} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}$
          - Используется, когда важен баланс между Precision и Recall.
      5. **ROC-AUC (Area Under the Receiver Operating Characteristic Curve)**
          - Площадь под ROC-кривой, которая строится по точкам (FPR, TPR) при изменении порога классификации.
          - Отражает способность модели различать положительные и отрицательные классы.
      6. **Confusion Matrix (Матрица ошибок)**
          - Таблица, показывающая количество истинных положительных (TP), истинных отрицательных (TN), ложных положительных (FP) и ложных отрицательных (FN) предсказаний.
          - Полезна для детального анализа производительности модели.

      ### Метрики эффективности для регрессионных задач

      1. **Mean Absolute Error (MAE)**
          - Среднее абсолютное отклонение предсказаний от истинных значений.
          - $\text{MAE} = \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y}_i|$
          - Показывает среднее значение ошибок предсказаний.
      2. **Mean Squared Error (MSE)**
          - Среднее квадратов отклонений предсказаний от истинных значений.
          - $\text{MSE} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2$
          - Уделяет большее внимание большим ошибкам за счет квадратичного увеличения.
      3. **Root Mean Squared Error (RMSE)**
          - Квадратный корень из MSE.
          - $\text{RMSE} = \sqrt{\text{MSE}}$
          - Интерпретируется в тех же единицах измерения, что и исходные данные.
      4. **R-squared (R², Коэффициент детерминации)**
          - Доля дисперсии зависимой переменной, объясненная моделью.
          - $R^2 = 1 - \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{\sum_{i=1}^n (y_i - \bar{y})^2}$
          - Значение в пределах от 0 до 1, где 1 означает идеальное предсказание.
      5. **Adjusted R-squared (Скорректированный коэффициент детерминации)**
          - Вариант R², который корректируется с учетом числа предикторов в модели.
          - Полезен для сравнения моделей с разным количеством признаков.
- text: |-
      ## 33. Метрики эффективности моделей классификации. Виды, характеристика, выбор

      **Метрики эффективности** - это способ показать, насколько точно модель отражает реальный мир. Обычно они вычисляются из двух векторов: **предсказанных** значений целевой переменной и **эмпирических** значений.

      **Основные метрики:**

      1) Accuracy (Точность)

      **Формула**: (TP + TN) / (TP + TN + FP + FN)

      **Характеристика**: Доля правильно классифицированных экземпляров от общего числа экземпляров.

      **Использование**: Применяется, когда классы сбалансированы (т.е., каждый класс представлен примерно равным числом экземпляров).

      2) Precision (Точность класса)

      **Формула**: TP / (TP + FP)

      **Характеристика**: Доля правильно предсказанных положительных экземпляров от всех экземпляров, предсказанных как положительные.

      **Использование**: Важна, когда важно минимизировать количество ложных срабатываний (FP).

      3) Recall (Полнота, чувствительность)

      **Формула**: TP / (TP + FN)

      **Характеристика**: Доля правильно предсказанных положительных экземпляров от всех фактических положительных экземпляров.

      **Использование**: Применяется, когда важно минимизировать пропуск положительных случаев (FN).

      4) F1-Score (F1-мера)

      **Формула**: 2 *(Precision* Recall) / (Precision + Recall)

      **Характеристика**: Средняя гармоническая величина точности и полноты. Это компромисс между точностью и полнотой.

      **Использование**: Применяется, когда необходимо учитывать оба аспекта одновременно, особенно в случае несбалансированных классов.

      5) ROC-AUC (Площадь под ROC-кривой)

      **Формула**: Интегральное значение под ROC-кривой (вероятность того, что модель правильно различит случайные положительный и отрицательный примеры).

      **Характеристика**: Оценка способности модели различать положительные и отрицательные примеры при разных порогах.

      **Использование**: Применяется для оценки моделей при разных уровнях порогов вероятности классификации, хорошо работает для несбалансированных классов.

      **Рекомендации по применению:**

      - **Сбалансированные классы**: Accuracy.
      - **Несбалансированные классы**: Precision, Recall, F1-Score, ROC-AUC
      - **Преобладание FP (важность точности)**: Precision.
      - **Преобладание FN (важность полноты)**: Recall.
      - **Компромисс между точностью и полнотой**: F1-Score.
- text: |-
      ## 34. Метрики эффективности моделей регрессии. Виды, характеристика, выбор

      **Метрики эффективности для регрессии** обычно анализируют отклонения предсказанных значений от реальных.

      1) R² (Коэффициент детерминации)

      **Формула**: $1 - \frac{\sum_{i=1}^{n}{(y_i - \hat y_i)^2}}{\sum_{i=1}^{n}{(y_i - \bar y_i)^2}}$, где $\bar y_i$ - среднее значение $y_i$.

      **Характеристика**: Показывает, какую долю дисперсии зависимой переменной объясняет модель. Значения варьируются от 0 до 1, иногда могут быть отрицательными (если модель хуже, чем просто среднее значение).

      **Использование**: Хорошо подходит для оценки общего качества модели. Если $R^2$ близок к 1, модель хорошо объясняет вариативность данных.

      2) Mean Absolute Error (MAE)

      **Формула**: $\frac{1}{n}\sum_{i=0}^{n-1}{|y_i - \hat y_i|}$

      **Характеристика**: Средняя абсолютная ошибка. Легко интерпретируется как среднее абсолютное расхождение предсказанных значений от фактических.

      **Использование**: Хорошо подходит, если важно интерпретировать ошибки в тех же единицах, что и исходные данные. Чувствителен к выбросам.

      3) Mean Squared Error (MSE)

      **Формула**: $\frac{1}{n}\sum_{i=0}^{n-1}{(y_i - \hat y_i)^2}$

      **Характеристика**: Среднеквадратическая ошибка. Наказывает большие ошибки сильнее, чем маленькие, из-за квадрата разницы.

      **Использование**: Применяется в случаях, когда важно сильно наказывать крупные ошибки. Высокая чувствительность к выбросам.

      4) Mean Absolute Percentage Error (MAPE)

      **Формула**: $\frac{1}{n}\sum_{i=0}^{n-1}{\lvert \frac{y_i - \hat y_i}{y_i}\rvert} \cdot 100%$%

      **Характеристика**: Средняя абсолютная процентная ошибка. Показывает ошибку в процентах, что удобно для сравнения ошибок между разными задачами.

      **Использование**: Полезна, когда важна относительная точность модели. Не может использоваться, если есть нулевые значения в yi, так как это приведет к делению на ноль.

      5) Root Mean Squared Error (RMSE)

      **Формула**: $\sqrt{\frac{1}{n}\sum_{i=0}^{n-1}{(y_i - \hat y_i)^2}}$

      **Характеристика**: Корень из среднеквадратической ошибки. Интерпретируется в тех же единицах, что и исходные данные.

      **Использование**: Более понятна для интерпретации, чем MSE, так как находится в той же шкале, что и исходные значения. Чувствительна к выбросам.

      **Рекомендации по применению:**

      - **Чувствительность к выбросам**: MSE, RMSE (для сильно наказываемых крупных ошибок), MAE (для менее чувствительного анализа).
      - **Понятность и интерпретируемость**: MAE, RMSE (в тех же единицах, что и данные).
      - **Процентные ошибки**: MAPE (удобна для задач, где важна относительная ошибка, но избегайте использования при наличии нулевых значений).
      - **Общее качество модели**: R² (показывает общую объясняемую вариативность модели).
- text: |-
      ## 35. Перекрестная проверка (кросс-валидация). Назначение, схема работы

      Разбиение выборки на обучающую и тестовую может внести случайные ошибки. Для избежания этого можно повторить разбиение несколько раз, рассчитать метрики и усреднить их.

      1. **K-Fold Cross-Validation**

      Схема работы:

      - Данные делятся на K равных частей (folds).
      - Модель обучается K раз, на (K-1) фолдах каждый раз и тестируется на оставшемся фолде.
      - Результаты K итераций усредняются для получения оценки модели.

      1. **Stratified K-Fold Cross-Validation**

      Схема работы:

      - Подобна K-Fold кросс-валидации, но сохраняет распределение данных по классам в каждом фолде.
      - Используется для несбалансированных классов, чтобы каждый фолд имел пропорциональное представление классов.

      1. **Leave-One-Out Cross-Validation (LOO-CV)**

      Схема работы:

      - Частный случай K-Fold Cross-Validation, где K равно количеству наблюдений.
      - На каждой итерации одна наблюдаемая запись используется как тестовая выборка, а оставшиеся (n-1) используются для обучения

      1. **Time Series Split**

      Схема работы:

      - Подходит для временных рядов, где порядок данных важен.
      - Создаются обучающие и тестовые наборы, последовательно включая данные из более ранних временных промежутков в обучающие данные и более поздние данные в тестовые.

      **Назначение:**

      - Выбор модели и гиперпараметров: Использования кросс-валидации для сравнения различных моделей и настроек гиперпараметров помогает найти наиболее оптимальный модельный подход.
      - Уверенность в генерализации: Кросс-валидация помогает убедиться, что модель будет работать хорошо на новых данных, предоставляя более достоверную оценку её производительности.
      - Уменьшение дисперсии оценки: Путем многократного разбиения данных и усреднения метрик, кросс-валидация уменьшает дисперсию оценки и делает её более устойчивой.
- text: |-
      ## 36. Конвейеры в библиотеке sklearn. Назначение, использование

      **Конвейеры (pipelines)** в библиотеке sklearn (scikit-learn) предоставляют удобный способ создания и управления последовательностью шагов обработки данных и построения модели. Они позволяют объединить несколько этапов предварительной обработки данных и моделирования в единое целое, что делает код чище, более структурированным и удобным для совместного использования.

      **Назначение:**

      1. **Упрощение кода**: Объединение нескольких шагов обработки данных и обучения модели в одном объекте.
      2. **Устранение повторяемого кода**: Исключение необходимости в многократном обучении и трансформации на различных этапах.
      3. **Совместимость с моделями**: Обеспечение согласованного способа применения одинаковых преобразований для обучения и предсказания.
      4. **Гиперпараметрическая оптимизация**: Легкая интеграция с методами выбора гиперпараметров (например, GridSearchCV, RandomizedSearchCV).
      5. **Совместная обработка тренировочных и тестовых данных**: Автоматическое применение одних и тех же преобразований к тренировочным и тестовым данным.

      **Пример:**

      ```python
      from sklearn.pipeline import Pipeline
      from sklearn.impute import SimpleImputer
      from sklearn.preprocessing import StandardScaler
      from sklearn.ensemble import RandomForestRegressor

      # Определяем шаги конвейера
      steps = [
          ('imputer', SimpleImputer(strategy='mean')),    # Заполнение пропусков средним значением
          ('scaler', StandardScaler()),                   # Масштабирование данных
          ('model', RandomForestRegressor())              # Обучение модели случайного леса
      ]

      # Создание конвейера
      pipeline = Pipeline(steps)

      # Пример данных
      import numpy as np
      X_train = np.array([[1, 2, np.nan], [4, np.nan, 6], [7, 8, 9]])
      y_train = np.array([1, 2, 3])

      # Обучение конвейера на тренировочных данных
      pipeline.fit(X_train, y_train)

      # Предсказание на новых данных
      X_test = np.array([[2, 3, 4], [5, 6, np.nan]])
      predictions = pipeline.predict(X_test)
      print(predictions)

      ```
- text: |-
      ## 37. Использование методов визуализации данных для предварительного анализа

      Визуализация данных является ключевой частью процесса предварительного анализа данных **(EDA, Exploratory Data Analysis).** Она позволяет лучше понять структуру данных, выявить тренды, паттерны, аномалии и потенциальные проблемы, такие как пропущенные значения или выбросы.

      **Основные инструменты:**

      1. **Гистограммы (Histograms)**:
          - **Назначение**: Показывают распределение числовых данных.
          - **Пример использования**:

      ```python
      import pandas as pd
      import matplotlib.pyplot as plt

      data = pd.read_csv('data.csv')
      plt.hist(data['age'], bins=20, edgecolor='k')
      plt.xlabel('Age')
      plt.ylabel('Frequency')
      plt.title('Age Distribution')
      plt.show()
      ```

      1. **Диаграммы рассеяния (Scatter plots)**:
          - **Назначение**: Демонстрируют отношения между двумя числовыми переменными, помогают выявлять корреляции.
          - **Пример использования**:

      ```python
      plt.scatter(data['height'], data['weight'])
      plt.xlabel('Height')
      plt.ylabel('Weight')
      plt.title('Height vs Weight')
      plt.show()
      ```

      1. **“Ящик с усами” (Box plots)**:
          - **Назначение**: Идентифицируют медианы, квартили и выбросы в наборе данных, полезны для сравнения распределений между категориями.
          - **Пример использования**:

      ```python
      import seaborn as sns

      sns.boxplot(x='category', y='value', data=data)
      plt.xlabel('Category')
      plt.ylabel('Value')
      plt.title('Boxplot of Values by Category')
      plt.show()
      ```

      1. **Тепловые карты (Heatmaps)**:
          - **Назначение**: Визуализируют корреляционные матрицы или сводные таблицы, позволяют понять взаимосвязи между числовыми переменными.
          - **Пример использования**:

      ```python
      correlation_matrix = data.corr()
      sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
      plt.title('Correlation Matrix Heatmap')
      plt.show()5**Диаграммы распределения (Distribution plots)**:
      ```

      - **Назначение**: Объединение гистограммы и KDE (Kernel Density Estimation) для детального анализа распределения одной переменной.
      - **Пример использования**:

      ```python
      sns.distplot(data['age'], bins=20, kde=True)
      plt.xlabel('Age')
      plt.title('Age Distribution with KDE')
      plt.show()

      ```

      1. **Диаграммы распределения (Distribution plots)**:
          - **Назначение**: Объединение гистограммы и KDE (Kernel Density Estimation) для детального анализа распределения одной переменной.
          - **Пример использования**:

      ```python
      sns.distplot(data['age'], bins=20, kde=True)
      plt.xlabel('Age')
      plt.title('Age Distribution with KDE')
      plt.show()
      ```

      1. **Линейные графики (Line plots)**:
          - **Назначение**: Подходят для временных рядов, помогают визуализировать тренды и изменения данных во времени.
          - **Пример использования**:

      ```python
      data['date'] = pd.to_datetime(data['date'])
      data.set_index('date', inplace=True)
      plt.plot(data.index, data['value'])
      plt.xlabel('Date')
      plt.ylabel('Value')
      plt.title('Time Series Line Plot')
      plt.show()
      ```
- text: |-
      ## 38. Исследование коррелированности признаков: методы, цели, выводы

      Цель — Изучение коррелированности признаков позволяет понять, какие признаки взаимосвязаны между собой, а также может помочь в исключении лишних или сильно коррелированных признаков для улучшения процесса обучения модели и предотвращения проблемы мультиколлинеарности. Для оценки коррелированности признаков чаще всего используют коэффициент корреляции Пирсона.

      Выводы — Коэффициент **корреляции Пирсона** является мерой линейной связи между двумя переменными *X* и *Y.* Он имеет значение от -1 до 1, где:

      - -1 указывает на совершенно отрицательную линейную корреляцию между двумя переменными
      - 0 указывает на отсутствие линейной корреляции между двумя переменными
      - 1 указывает на совершенно положительную линейную корреляцию между двумя переменными.

      Методы — Существует три распространенных метода измерения корреляции:

      **Корреляция Пирсона:** используется для измерения корреляции между двумя непрерывными переменными. (например, рост и вес)

      Для вычисления корреляции Пирсона (это самая классическая корреляция) между всеми признаками выборки строится корреляционная матрица, в которой каждый элемент матрицы показывает корреляцию между i и j признаком выборки.

      **Корреляция Спирмена:** используется для измерения корреляции между двумя ранжированными переменными. (например, оценка балла учащегося на экзамене по математике и оценка его оценки на экзамене по естественным наукам в классе)

      **Корреляция Кендалла:** используется, когда вы хотите использовать корреляцию Спирмена, но размер выборки мал и имеется много связанных рангов.
- text: |-
      ## 39. Решкалирование данных. Виды, назначение, применение. Нормализация и стандартизация данных

      Решкалирование данных в машинном обучении - это процесс изменения масштаба значений признаков в наборе данных. Основные виды решкалирования данных - нормализация и стандартизация.

      1. Нормализация данных: при нормализации данные приводятся к диапазону от 0 до 1. Это полезно, когда значения признаков имеют разный масштаб и нужно привести их к единому диапазону для более стабильного обучения модели.

      Виды нормализации:

      **Минимаксная нормализация**

      $$
      X^{'} = \frac {X-X_{min}}{X_{max} -X_{min}}
      $$

      2. Стандартизация данных: при стандартизации данные приводятся к виду, где среднее значение каждого признака равно 0, а стандартное отклонение равно 1. Этот метод подходит, когда данные имеют нормальное распределение и помогает модели лучше работать с выбросами.

      $$
      x^{'}_i = \frac{(x_i - \overline X)}{\sigma_x}
      $$

      Оба метода - нормализация и стандартизация - помогают улучшить процесс обучения моделей машинного обучения, делая их более устойчивыми к разным масштабам значений признаков.
- text: |-
      ## 40. Преобразование категориальных признаков в числовые

      Преобразование категориальных признаков в числовые - важный этап предобработки данных в машинном обучении. Вот несколько способов преобразования категориальных признаков в числовые:

      1. One-Hot Encoding (Dummy Encoding): каждая уникальная категория преобразуется в отдельный бинарный признак. Например, если у нас есть категориальный признак "цвет" с возможными значениями "красный", "синий" и "зеленый", то после One-Hot Encoding мы получим три отдельных бинарных признака для каждого цвета.

      P.S. Один из полученных бинарных признаков нужно убрать, чтобы избавиться от мультиколлинеарности.

      2. Label Encoding: каждая уникальная категория преобразуется в числовое значение. Например, "красный" может быть закодировано как 0, "синий" как 1 и "зеленый" как 2. Этот метод подходит, когда категориальный признак имеет внутреннюю упорядоченность.

      3. Target Encoding: каждое значение категориального признака заменяется средним значением целевой переменной для этого значения. Этот метод может быть полезен, когда важна связь категориального признака с целевой переменной.

      Выбор метода зависит от особенностей данных и задачи машинного обучения. Важно учитывать, что правильное преобразование категориальных признаков в числовые поможет модели лучше обучаться и делать более точные прогнозы.
- text: |-
      ## 41. Методы визуализации данных для машинного обучения

      Визуализация данных играет важную роль в машинном обучении, помогая понять структуру данных, выявить взаимосвязи и найти закономерности. Вот несколько методов визуализации данных, которые широко используются в машинном обучении:

      1. Диаграммы рассеяния (Scatter Plots): позволяют визуализировать взаимосвязь между двумя переменными. Этот тип графика особенно полезен при изучении корреляции между признаками.

      2. Гистограммы (Histograms): показывают распределение значений признака. Позволяют оценить форму распределения данных, наличие выбросов и т.д.

      3. Ящики с усами (Box Plots): помогают визуализировать описательные статистики (медиану, квартили, выбросы) для различных категорий или признаков.

      4. Тепловые карты (Heatmaps): отображают данные в виде цветовой карты, позволяя быстро выявить закономерности и корреляции между признаками.

      5. Распределение признаков (Feature Distribution): визуализация распределения отдельных признаков по классам или целевой переменной.

      6. Визуализация работы модели — вывод самой функции регрессии, если это возможно (признаков 2 или меньше). В случае задачи регрессии можно вывести диаграмму рассеяния истинных и предсказанных значений.

      Правильное использование визуализаций может помочь выявить важные закономерности, сделать признаки более интерпретируемыми и улучшить понимание данных перед обучением модели.
- text: |-
      ## 42. Задача выбора модели. Оценка эффективности, валидационный набор

      При выборе модели в машинном обучении важно правильно оценить ее эффективность. Для этого используются валидационные наборы данных и метрики оценки. Вот основные шаги при выборе модели и оценке ее эффективности:

      1. Разделение данных: исходный датасет разделяется на тренировочный набор данных (для обучения модели) и валидационный набор данных (для оценки эффективности модели).

      2. Выбор модели: выбор подходящей модели зависит от задачи машинного обучения (например, классификация или регрессия), объема данных, типа признаков и других факторов.

      3. Обучение модели: модель обучается на тренировочном наборе данных с использованием подходящего алгоритма обучения.

      4. Оценка эффективности: после обучения модели оценивается ее эффективность на валидационном наборе данных с помощью соответствующих метрик качества (например, Accuracy, Precision, Recall, F1-score для классификации; MSE, RMSE, R-squared для регрессии).

      5. Кросс-валидация: для улучшения оценки эффективности модели рекомендуется использовать кросс-валидацию, которая позволяет более устойчиво оценить производительность модели путем разделения данных на несколько подмножеств.

      6. Сравнение моделей: после оценки нескольких моделей на валидационном наборе данных выбирается наилучшая модель с наивысшей эффективностью.

      Использование валидационных наборов данных и правильных метрик оценки позволяет выбрать наилучшую модель в машинном обучении и сделать более точные прогнозы на новых данных.
- text: |-
      ## 43. Кривые обучения для диагностики моделей машинного обучения
      - **Precision** - Точность = $\dfrac{TP}{TP + FP}$ - Какая честь из предсказанных как истинные и правда истинные
      - **Recall** - Полнота - TPR (True Positive Rate) = $\dfrac{TP}{TP + FN}$ - Показывает какую часть истинных значений получилось найти
      ### PR
      1. Кривая precision-recall используется для методов метрической классификации, которые выдают вероятность принадлежности объекта данному классу.
      2. Дискретная классификации производится при помощи порогового значения.
      3. Чем больше порог, тем больше объектов модель будет относить к отрицательному классу.
      4. Повышение порога в среднем увеличивает precision модели, но понижает recall.
      5. PR-кривая используется чтобы выбрать оптимальное значение порога.
      6. PR-кривая нужна для того, чтобы сравнивать и оценивать модели вне зависимости от выбранного уровня порога.
      7. PR-AUC - площадь под PR-кривой, у лучшей модели - 1.0, у тривиальной - 0.5, у худшей - 0.0.

      ### ROC Кривая
      ROC-AUC - ROC кривая строится изменением порога классификации, на осях FPR (x) и TPR (y). Площадь под ней показывает точность модели без учета порога (не очень хорошо справляется с дисбалансом классов)
- text: |-
      ## 44. Регуляризация моделей машинного обучения. Назначение, виды, формализация

      ### L1 и L2 регуляризация: суть и применение

      Регуляризация в машинном обучении - это техника, которая добавляет штраф к функции потерь модели, чтобы предотвратить переобучение. Переобучение происходит, когда модель слишком хорошо запоминает обучающие данные и не может обобщить на новые данные.

      L1 и L2 регуляризация - два популярных вида регуляризации, которые отличаются тем, как они штрафуют коэффициенты модели:

      **L1-регуляризация (Lasso)**

      - **Штраф:** Штраф пропорционален сумме абсолютных значений коэффициентов модели.
      - **Эффект:** L1-регуляризация стремится сделать некоторые коэффициенты равными нулю, что приводит к **отбору признаков**. Это особенно полезно, когда у вас много признаков, и некоторые из них могут быть избыточными или неинформативными.
      - **Применение:** Lasso часто используется для задач сжатия, когда необходимо выбрать подмножество наиболее важных признаков.

      **L2-регуляризация (Ridge)**

      - **Штраф:** Штраф пропорционален сумме квадратов коэффициентов модели.
      - **Эффект:** L2-регуляризация стремится сделать все коэффициенты модели маленькими, но не обязательно равными нулю. Это делает модель более устойчивой к шуму в данных.
      - **Применение:** Ridge часто используется для задач с высокой коллинеарностью признаков.

      **Сравнение L1 и L2 регуляризации:**

      | Свойство | L1-регуляризация (Lasso) | L2-регуляризация (Ridge) |
      | --- | --- | --- |
      | Штраф | Сумма абсолютных значений коэффициентов | Сумма квадратов коэффициентов |
      | Эффект | Сжатие некоторых коэффициентов к нулю | Сжатие всех коэффициентов к нулю |
      | Применение | Отбор признаков | Улучшение устойчивости модели |

      **Пример:**

      Представьте, что вы пытаетесь предсказать цену дома на основе его площади, числа комнат и возраста.

      - **Lasso**: Lasso может обнаружить, что число комнат не сильно влияет на цену и сделать его коэффициент равным нулю, что позволит вам использовать только площадь и возраст для предсказания цены.
      - **Ridge**: Ridge может уменьшить влияние всех трех признаков, делая модель более устойчивой к шуму в данных.

      **Выбор между L1 и L2:**

      - **Lasso:** Используйте, если у вас много признаков и вы хотите выбрать подмножество наиболее важных.
      - **Ridge:** Используйте, если у вас есть высокая коллинеарность признаков и вы хотите улучшить устойчивость модели.

      Надеюсь, это объяснение вам поможет!
- text: |-
      ## 45. Проблема сбора и интеграции данных для машинного обучения
- text: |-
      ## 46. Понятие чистых данных и требования к данным
      Чистые данные - это данные, которые не содержат ошибок, неточностей, дубликатов, пропущенных значений или других проблем, которые могут повлиять на качество модели машинного обучения.

      Основные характеристики чистых данных:

      - Точность: Данные должны быть точными и отражать реальность.
      - Полнота: В данных не должно быть пропущенных значений.
      - Согласованность: Данные должны быть согласованы друг с другом, без противоречий.
      - Единообразие: Данные должны быть представлены в едином формате, без различий в записи.
      - Актуальность: Данные должны быть актуальны и отражать текущее состояние дел.
      - Релевантность: Не содержат лишней информации, которая не связана с задачей машинного обучения.

      **Требования к данным в машинном обучении**

      Качество данных - один из ключевых факторов успеха модели машинного обучения.

      Основные требования к данным:

      - Чистота: Данные должны быть чистыми, без ошибок и неточностей.
      - Объем: Достаточное количество данных необходимо для обучения модели.
      - Разнообразие: Данные должны быть разнообразными, чтобы модель могла научиться обобщать информацию.
      - Репрезентативность: Данные должны представлять реальную ситуацию, для которой модель будет использоваться.
      - Структура: Данные должны иметь структуру, которая позволяет их анализировать и использовать в модели.

      Качество данных напрямую влияет на точность, надежность и эффективность модели машинного обучения. Чистые и качественные данные позволяют:

      - Улучшить точность прогнозов: Модель будет выдавать более точные прогнозы, если данные, на которых она обучена, не содержат ошибок.
      - Снизить риск ошибок: Модель будет работать более стабильно и без ошибок, если данные полные и согласованы.
      - Повысить скорость обучения: Модель будет обучаться быстрее, если данные оптимизированы.
      - Улучшить интерпретацию результатов: Результаты модели будут более легко интерпретировать, если данные структурированы и стандартизированы.
      - text: |-
      ## 47. Основные задачи описательного анализа данных

      1. Загрузка и первичный осмотр данный.
      2. Обработка пропущенных значений (заполнение пропущенных значений, например, средними или медианами значениями).
      3. Анализ распределения переменных (построение для числовых переменных гистограмм и диаграмм рассеяния).
      4. Исследование корреляций между переменными (рассмотрение корреляции между численными признаками, например, с помощью коэффициента корреляции).
      5. Выявление выбросов и аномалий (например, с помощью визуализации (ящик с усами)).
      6. Изучение категориальных признаков.
      7. Визуализация результатов (гистограммы, диаграммы рассеяния, ящик с усами, тепловые карты).

      Описательный анализ данных нужен для обнаружения проблем (артефактов) в данных и для выбора метода их устранения. EDA также может дать информацию о структуре данных, шкалах измерения переменных, которые потом повлияют на методы обработки данных. Также EDA может помочь при выборе признаков, выявлении зависимостей в данных. EDA - это обзорный анализ данных именно при их подготовке к процессу машинного обучения. При необходимости, можно провести более глубокий статистический анализ данных. Анализ и обработку данных обычно производят параллельно, это не изолированные процессы.
- text: |-
      ## 48. Полиномиальные модели машинного обучения

      1. Полиномиальная регрессия

      Для регрессии с одним признаком:

      $\hat{y} = h_b(x) = b_0 +b_1*x +b_2*x^2$ (полином степени 2)

      $\hat{y} = h_b(x) = b_0 +b_1*x +b_2*x^2 + b_3*x^3$ (полином степени 3)

      Для регрессии с двумя признаками:

      $\hat{y} = h_b(x) = b_0 +b_1*x_1 +b_2*x_2$ - линейная модель (полином степени 1)

      $\hat{y} = h_b(x) = b_0 +b_1*x_1 +b_2*x_2 + b_3*x_1^2 + b_4*x_2^2 + b_5*x_1*x_2$ - квадратная модель (полином степени 2)

      $\hat{y} = h_b(x) = b_0 +b_1*x_1 +b_2*x_2 + b_3*x_1^2 + b_4*x_2^2 + b_5*x_1*x_2 + b_6*x_1^3 + b_7*x_2^3 + b_7*x_1^2*x_2 + b_8*x_1*x_2^2$ - кубическая модель (полином степени 3)

      Данные в датасете не всегда располагаются так, что их хорошо может описывать линейная функция. Для описания нелинейных зависимостей нужна более сложная, нелинейная модель. Чтобы не изобретать алгоритм обучения заново, можно просто ввести в модель суррогатные признаки. Суррогатный признак - это новый признак, который считается из существующих атрибутов. Чаще всего используют полиномиальную регрессию - это когда в модель вводят полиномиальные признаки - степени существующих атрибутов. Обычно берут все комбинации факторов до какой-то определенной степени полинома. Полиномиальная регрессия может аппроксимировать любую функцию, нужно только подобрать степень полинома. Чем больше степень полиномиальной регрессии, тем она сложнее и универсальнее, но вычислительно сложнее (экспоненциально).

      1. Полиномиальная классификация

      $h_b(x) = g(b_0 +b_1*x_1 +b_2*x_2)$

      $h_b(x) = g(b_0 +b_1*x_1 +b_2*x_2 + b_3*x_1^2 + b_4*x_2^2)$

      Добавление полиномиальных признаков возможно как к регрессионным, так и к классификационным моделям. Полиномиальная регрессия позволяет охватывать нелинейные зависимости атрибутов и целевой переменной. Полиномиальная классификация позволяет очерчивать нелинейные границы принятия решений. Здесь и далее: атрибуты - характеристики объектов, данные в датасете; признаки - компоненты вектора, подающегося на вход модели машинного обучения. Полиномиальные модели универсальны, но очень дороги при высоких порядках полинома.
- text: |-
      ## 49. Основные виды преобразования данных для подготовки к машинному обучению

      1. **Преобразование численных атрибутов в категориальные:** иногда бывает целесообразно сгруппировать объекты датасета по значению какого-то признака и заменить его названием группы. В таком случае, мы удаляет часть информации из модели, но это может быть лишняя вариативность. Показательный пример - группы населения по возрасту. Такое нужно делать, только если есть уверенность, что объекты внутри группы одинаково относятся к целевой переменной. Границы групп выбирают вручную, от этого многое зависит.

      2. **Преобразование категориальных данных:** Категориальные признаки часто выражаются строковыми данными и не подходят для использования в машинном обучении, их преобразуют в численные. Самый простой кодировщик - LabelEncoder - просто нумерует все значения категориального признака. Он вводит порядок в значения категорий, которого раньше не было, поэтому можно исказить результаты обучения. Исключение - бинарные признаки, их можно кодировать как 0 и 1. Более продвинутый кодировщик - OneHotEncoder - преобразует один признак во множество. Новые признаки соответствуют значениям исходного и кодируются бинарно. Этот способ более универсален и рекомендуется применять по умолчанию. В принципе, один из получившихся признаков можно удалить, но это не обязательно. Да, из одного признака может получиться тысяча.
- text: |-
      ## 50. Задача выбора признаков в машинном обучении

      Задача выбора признаков - отбор признаков, наиболее полезных для дальнейшего построения модели.

      Почему используются методы отбора признаков?

      - Простые модели (с меньшим количеством признаков) легче интерпретировать.
      - Модели хуже обучаются на датасетах с большим количеством признаков.
      - Уменьшение времени обучения и предсказания.
      - Уменьшение риска переобучения.

      **Четыре группы методов отбора признаков:**

      1. Методы фильтрации (filter methods).
      2. Методы обертывания (wrapper methods).
      3. Методы вложений (embedded methods).
      4. Гибридные методы.

      **1. Методы фильтрации**

      - Методы выбирают наиболее "подходящие" признаки без использования моделей машинного обучения на основе статистических характеристик выборки (корреляция и т.д.)
      - Наименее затратны с точки зрения вычислительных ресурсов.
      - Могут уступать другим методам по качеству отбора признаков, потому что не учитывают зависимости между признаками.
      - Хорошо подходят для начальной фильтрации признаков.

      Простейшие методы фильтрации:

      1) Удаление константных и псевдоконстантных (почти константных) признаков

      - Если признак содержит одинаковые (константные) значения, то он не может внести вклад в построение модели.
      - Если признак содержит почти все одинаковые (константные) значения, то скорее всего он мало полезен при построении модели. (При этом нужно быть осторожным, так как данный признак может быть индикатором одного из классов в случае классификации).
      - Для поиска таких признаков можно использовать функцию unique().
      - Но удобнее использовать дисперсию:
        - У константного признака нулевая дисперсия.
        - У псевдоконстантного списка значение дисперсии очень мало.
      - Возможно использование класса [VarianceThreshold](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html) из библиотеки Sklearn.

      2) Удаление повторяющихся признаков

      3) Методы, основанные на корреляции (поиск групп коррелирующих признаков)

      - Желательно, чтобы признаки хорошо коррелировали с целевым признаком.
      - Важно, чтобы признаки не коррелировали между собой.

      4) Методы, основанные на статистических характеристиках (univariate feature selection)

      Одномерный выбор функций работает путем выбора лучших функций на основе одномерных статистических тестов. Это можно рассматривать как этап предварительной обработки оценщика. Scikit-learn предоставляет процедуры выбора функций как объекты, реализующие transform метод:

      SelectKBest - выбирает К лучших признаков.

      SelectPercentile - выбирает К процентов лучших признаков

      Эти объекты принимают в качестве входных данных функцию оценки, которая возвращает одномерные оценки:

      Для регрессии: f_regression, mutual_info_regression

      Для классификации: chi2, f_classif, mutual_info_classif

      [https://scikit-learn.ru/1-13-feature-selection/?ysclid=lvhy9kgrlk278349951](https://scikit-learn.ru/1-13-feature-selection/?ysclid=lvhy9kgrlk278349951)

      **2. Методы обертывания**

      - Используют модели машинного обучения для отбора признаков.
      - Формируют подмножества признаков.
      - Для каждого подмножества признаков строится отдельная модель машинного обучения.
      - Для конкретной модели машинного обучения (на которой производится оценка) чаще всего генерируют оптимальный набор признаков. (Но этот набор не обобщается на все модели.)
      - Очень затратны с точки зрения вычислительных ресурсов.
      - Могут приводить к переобучению моделей (особенно в случае маленьких выборок).

      Методы обертывания включают ["жадные"](https://ru.wikipedia.org/wiki/%D0%96%D0%B0%D0%B4%D0%BD%D1%8B%D0%B9_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC) алгоритмы трех видов:

      - Прямые алгоритмы (step forward feature selection или sequential forward selection) построены на постепенном добавлении новых признаков в модель.
      - Обратные алгоритмы (step backwards feature selection или sequential backward selection) построены на постепенном удалении признаков из модели.
      - Алгоритмы полного перебора (exhaustive feature selection) проверяют все возможные комбинации признаков.

      Для решения задачи отбора признаков с помощью методов обертывания может быть использована библиотека [MLxtend.](http://rasbt.github.io/mlxtend/)

      1) Прямые алгоритмы

      - На первом шаге для каждого признака $*x_i$* принадлежащего множеству признаков $*X*$
      строятся модели машинного обучения (на основе одного признака). Оценивается качество всех моделей на основе заданной метрики, выбирается лучшая модель, содержащая один признак $x^{1}$.
      - На втором шаге к признаку $x^{1}$ по очереди добавляются оставшиеся признаки $*x_j*$
      принадлежащие множеству признаков $*X*$, и строятся модели машинного обучения (на основе двух признаков). Оценивается качество всех моделей на основе заданной метрики, выбирается лучшая модель из двух признаков.
      - Процедура итеративно повторяется для 3, 4, ... признаков.
      - Критерии остановки могут быть различными:
        - Улучшение метрики качества меньше заданной величины *ε*.
        - Выбрано *N* лучших признаков.

      Для решения задачи используется класс [Sequential Feature Selector](http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/) (с параметром конструктора forward=True) из библиотеки MLxtend.

      2) Обратные алгоритмы

      - На первом шаге каждый признак $*x_i*$, принадлежащий множеству признаков $*X*$
      удаляется из множества признаков, а для оставшихся признаков строятся модели машинного обучения. Оценивается качество всех моделей на основе заданной метрики, выбирается лучшая модель, содержащая все признаки, кроме одного $*X^{−1}*$.
      - На втором шаге из множества $*X^{−1}$*по очереди удаляется по одному из оставшихся признаков $*x_j$* принадлежащих множеству признаков *X*, и строятся модели машинного обучения на основе исходного множества без двух признаков. Оценивается качество всех моделей на основе заданной метрики, выбирается лучшая модель, содержащая все признаки, кроме двух $*X^{−2}*$.
      - Процедура итеративно повторяется с удалением третьего, четвертого ... признаков.
      - Критерии остановки могут быть различными:
        - Улучшение метрики качества меньше заданной величины *ε*.
        - В модели осталось (или из модели было удалено) *N* признаков.

      Для решения задачи используется класс [Sequential Feature Selector](http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/) (с параметром конструктора forward=False) из библиотеки MLxtend.

      Для алгоритмов:

      - sequential forward selection
      - sequential backward selection

      существуют их доработанные варианты

      - sequential forward floating selection
      - sequential backward floating selection

      которые отличаются тем, что при некоторых условиях могут отменять добавление (или удаление) признака, если он ухудшает модель. Данная доработка далеко не всегда улучшает исходный алгоритм.

      3) Алгоритмы полного перебора

      - Осуществляют перебор всех комбинаций из 1, 2, ... N признаков.
      - Для каждой комбинации строится модель и оценивается метрика качества.
      - Выбирается лучшая модель на основе метрики.
      - По сравнению с предыдущими двумя подходами, данный подход наиболее требователен к ресурсам.

      Для решения задачи используется класс [ExhaustiveFeatureSelector](http://rasbt.github.io/mlxtend/user_guide/feature_selection/ExhaustiveFeatureSelector/) из библиотеки MLxtend.

      Параметры min_features и max_features используются для задания диапазона количества перебираемых признаков.

      1. **Методы вложений (embedded methods)**

      - Являются гибридом фильтрации и обертывания.
      - Осуществляют отбор признаков на основе оценки важности признаков в процессе конструирования модели.
      - По сравнению с методами обертывания, менее затратны с точки зрения вычислительных ресурсов.

      Какие модели позволяют оценить важность признаков?

      - Линейные модели. [Линейная регрессия](https://ru.wikipedia.org/wiki/%D0%9B%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F) в задаче регресии и [логистическая регрессия](https://ru.wikipedia.org/wiki/%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F) в задаче классификации.
      - Дерево решений и ансамблевые модели на его основе.

      Класс [SelectFromModel](https://scikit-learn.org/stable/modules/feature_selection.html#select-from-model) может быть использован для выборки наиболее важных признаков из модели.

      1) Использование линейных моделей

      - Логистическая регрессия
      - Линейный классификатор на основе SVM
      - Линейная регрессия

      2) Использование моделей на основе решающего дерева

      - Задача классификации
      - Задача регрессии

      1. **Гибридные методы**

      По утверждениям экспертов, эти методы хорошо работают на практике.

      1) Рекурсивное добавление или удаление признаков:

      - Данный метод имеет названия:
        - Recursive Feature Addition
        - [Recursive Feature Elimination](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)
      - Является разновидностью прямого или обратного алгоритма для методов обертывания.
      - Особенностью является то, что при построении моделей оцениваются важности признаков (как в методе вложений). Соответственно на каждом шаге добавляется наиболее значимый признак или удаляется наименее значимый признак и после этого оценивается качество модели.
      - "Рекурсивное", потому что на каждом шаге переучивается модель и рассматривается новое подмножество признаков.

      2) Определение важности признаков на основе перемешивания данных

      - Данный метод имеет названия:
        - Permutation feature importance
        - Feature selection by random shuffling
      - Идея метода состоит в том, что если для одного признака случайно перемешать все значения и потом обучить модель с "перемешанным" признаком, то чем важнее признак, тем сильнее упадет качество модели.
      - Признаки перемешиваются по очереди, для каждого перемешивания оценивается падение качества модели и на основе этого вычисляется важность признака.
      - Далее на основе важности можно отбирать наиболее значимые признаки как в случае методов вложений.
      - Данный метод реализован с использованием функции [permutation_importance.](https://scikit-learn.org/stable/modules/permutation_importance.html)

      Ссылка на лекцию с кодом: [https://nbviewer.org/github/ugapanyuk/ml_course_2022/blob/main/common/notebooks/features/selection.ipynb](https://nbviewer.org/github/ugapanyuk/ml_course_2022/blob/main/common/notebooks/features/selection.ipynb)
