CMakeLists.txt
LICENSE
MANIFEST.in
README.md
pyproject.toml
requirements-common.txt
requirements-cpu.txt
requirements-cuda.txt
requirements-neuron.txt
requirements-rocm.txt
setup.py
cmake/cpu_extension.cmake
cmake/hipify.py
cmake/utils.cmake
csrc/activation_kernels.cu
csrc/cache.h
csrc/cache_kernels.cu
csrc/cuda_compat.h
csrc/cuda_utils.h
csrc/cuda_utils_kernels.cu
csrc/custom_all_reduce.cu
csrc/custom_all_reduce.cuh
csrc/custom_all_reduce_test.cu
csrc/dispatch_utils.h
csrc/layernorm_kernels.cu
csrc/moe_align_block_size_kernels.cu
csrc/ops.h
csrc/pos_encoding_kernels.cu
csrc/reduction_utils.cuh
csrc/registration.h
csrc/torch_bindings.cpp
csrc/attention/attention_dtypes.h
csrc/attention/attention_generic.cuh
csrc/attention/attention_kernels.cu
csrc/attention/attention_utils.cuh
csrc/attention/dtype_bfloat16.cuh
csrc/attention/dtype_float16.cuh
csrc/attention/dtype_float32.cuh
csrc/attention/dtype_fp8.cuh
csrc/cpu/activation.cpp
csrc/cpu/attention.cpp
csrc/cpu/cache.cpp
csrc/cpu/cpu_types.hpp
csrc/cpu/layernorm.cpp
csrc/cpu/pos_encoding.cpp
csrc/cpu/torch_bindings.cpp
csrc/moe/moe_ops.h
csrc/moe/topk_softmax_kernels.cu
csrc/moe/torch_bindings.cpp
csrc/punica/LICENSE
csrc/punica/punica_ops.cu
csrc/punica/punica_ops.h
csrc/punica/torch_bindings.cpp
csrc/punica/type_convert.h
csrc/punica/bgmv/bgmv_bf16_bf16_bf16.cu
csrc/punica/bgmv/bgmv_bf16_fp32_bf16.cu
csrc/punica/bgmv/bgmv_config.h
csrc/punica/bgmv/bgmv_fp16_fp16_fp16.cu
csrc/punica/bgmv/bgmv_fp16_fp32_fp16.cu
csrc/punica/bgmv/bgmv_fp32_bf16_bf16.cu
csrc/punica/bgmv/bgmv_fp32_fp16_fp16.cu
csrc/punica/bgmv/bgmv_impl.cuh
csrc/punica/bgmv/generator.py
csrc/punica/bgmv/vec_dtypes.cuh
csrc/quantization/aqlm/gemm_kernels.cu
csrc/quantization/awq/dequantize.cuh
csrc/quantization/awq/gemm_kernels.cu
csrc/quantization/compressed_tensors/int8_quant_kernels.cu
csrc/quantization/cutlass_w8a8/broadcast_load_epilogue_c2x.hpp
csrc/quantization/cutlass_w8a8/broadcast_load_epilogue_c3x.hpp
csrc/quantization/cutlass_w8a8/common.hpp
csrc/quantization/cutlass_w8a8/scaled_mm_c2x.cu
csrc/quantization/cutlass_w8a8/scaled_mm_c3x.cu
csrc/quantization/cutlass_w8a8/scaled_mm_entry.cu
csrc/quantization/fp8/common.cu
csrc/quantization/fp8/amd/hip_float8.h
csrc/quantization/fp8/amd/hip_float8_impl.h
csrc/quantization/fp8/amd/quant_utils.cuh
csrc/quantization/fp8/nvidia/quant_utils.cuh
csrc/quantization/gptq/compat.cuh
csrc/quantization/gptq/matrix_view.cuh
csrc/quantization/gptq/q_gemm.cu
csrc/quantization/gptq/qdq_2.cuh
csrc/quantization/gptq/qdq_3.cuh
csrc/quantization/gptq/qdq_4.cuh
csrc/quantization/gptq/qdq_8.cuh
csrc/quantization/gptq/qdq_util.cuh
csrc/quantization/gptq_marlin/gptq_marlin.cu
csrc/quantization/gptq_marlin/gptq_marlin.cuh
csrc/quantization/gptq_marlin/gptq_marlin_dtypes.cuh
csrc/quantization/gptq_marlin/gptq_marlin_repack.cu
csrc/quantization/marlin/dense/LICENSE
csrc/quantization/marlin/dense/marlin_cuda_kernel.cu
csrc/quantization/marlin/sparse/LICENSE
csrc/quantization/marlin/sparse/marlin_24_cuda_kernel.cu
csrc/quantization/marlin/sparse/common/base.h
csrc/quantization/marlin/sparse/common/mem.h
csrc/quantization/marlin/sparse/common/mma.h
csrc/quantization/squeezellm/quant_cuda_kernel.cu
tests/test_cache_block_hashing.py
tests/test_config.py
tests/test_inputs.py
tests/test_logger.py
tests/test_logits_processor.py
tests/test_regression.py
tests/test_sampling_params.py
tests/test_sequence.py
tests/test_sharded_state_loader.py
tests/test_utils.py
tests/core/__init__.py
tests/core/test_block_manager.py
tests/core/test_chunked_prefill_scheduler.py
tests/core/test_scheduler.py
tests/core/utils.py
tests/core/block/__init__.py
tests/core/block/conftest.py
tests/core/block/test_block_manager_v2.py
tests/core/block/test_block_table.py
tests/core/block/test_common.py
tests/core/block/test_cpu_gpu_block_allocator.py
tests/core/block/test_naive_block.py
tests/core/block/test_prefix_caching_block.py
tests/lora/__init__.py
tests/lora/conftest.py
tests/lora/test_baichuan.py
tests/lora/test_chatglm3.py
tests/lora/test_gemma.py
tests/lora/test_layer_variation.py
tests/lora/test_layers.py
tests/lora/test_llama.py
tests/lora/test_lora.py
tests/lora/test_lora_checkpoints.py
tests/lora/test_lora_manager.py
tests/lora/test_mixtral.py
tests/lora/test_punica.py
tests/lora/test_quant_model.py
tests/lora/test_tokenizer_group.py
tests/lora/test_utils.py
tests/lora/test_worker.py
tests/lora/utils.py
tests/spec_decode/__init__.py
tests/spec_decode/test_batch_expansion.py
tests/spec_decode/test_metrics.py
tests/spec_decode/test_multi_step_worker.py
tests/spec_decode/test_ngram_worker.py
tests/spec_decode/test_spec_decode_worker.py
tests/spec_decode/test_utils.py
tests/spec_decode/utils.py
tests/spec_decode/e2e/__init__.py
tests/spec_decode/e2e/conftest.py
tests/spec_decode/e2e/test_compatibility.py
tests/spec_decode/e2e/test_multistep_correctness.py
tests/spec_decode/e2e/test_ngram_correctness.py
tests/tensorizer_loader/__init__.py
tests/tensorizer_loader/test_tensorizer.py
tests/tokenization/__init__.py
tests/tokenization/test_cached_tokenizer.py
tests/tokenization/test_detokenize.py
tests/tokenization/test_tokenizer.py
tests/tokenization/test_tokenizer_group.py
tests/worker/__init__.py
tests/worker/test_model_runner.py
tests/worker/test_swap.py
vllm/__init__.py
vllm/_custom_ops.py
vllm/block.py
vllm/config.py
vllm/envs.py
vllm/inputs.py
vllm/logger.py
vllm/outputs.py
vllm/pooling_params.py
vllm/py.typed
vllm/sampling_params.py
vllm/sequence.py
vllm/utils.py
vllm/version.py
vllm.egg-info/PKG-INFO
vllm.egg-info/SOURCES.txt
vllm.egg-info/dependency_links.txt
vllm.egg-info/requires.txt
vllm.egg-info/top_level.txt
vllm/attention/__init__.py
vllm/attention/layer.py
vllm/attention/selector.py
vllm/attention/backends/__init__.py
vllm/attention/backends/abstract.py
vllm/attention/backends/blocksparse_attn.py
vllm/attention/backends/flash_attn.py
vllm/attention/backends/flashinfer.py
vllm/attention/backends/pallas.py
vllm/attention/backends/rocm_flash_attn.py
vllm/attention/backends/torch_sdpa.py
vllm/attention/backends/xformers.py
vllm/attention/ops/__init__.py
vllm/attention/ops/ipex_attn.py
vllm/attention/ops/paged_attn.py
vllm/attention/ops/prefix_prefill.py
vllm/attention/ops/triton_flash_attention.py
vllm/attention/ops/blocksparse_attention/__init__.py
vllm/attention/ops/blocksparse_attention/blocksparse_attention_kernel.py
vllm/attention/ops/blocksparse_attention/interface.py
vllm/attention/ops/blocksparse_attention/utils.py
vllm/core/__init__.py
vllm/core/block_manager_v1.py
vllm/core/block_manager_v2.py
vllm/core/embedding_model_block_manager.py
vllm/core/evictor_v1.py
vllm/core/evictor_v2.py
vllm/core/interfaces.py
vllm/core/policy.py
vllm/core/scheduler.py
vllm/core/block/__init__.py
vllm/core/block/block_table.py
vllm/core/block/common.py
vllm/core/block/cpu_gpu_block_allocator.py
vllm/core/block/interfaces.py
vllm/core/block/naive_block.py
vllm/core/block/prefix_caching_block.py
vllm/core/block/utils.py
vllm/distributed/__init__.py
vllm/distributed/communication_op.py
vllm/distributed/parallel_state.py
vllm/distributed/utils.py
vllm/distributed/device_communicators/__init__.py
vllm/distributed/device_communicators/custom_all_reduce.py
vllm/distributed/device_communicators/custom_all_reduce_utils.py
vllm/distributed/device_communicators/pynccl.py
vllm/distributed/device_communicators/pynccl_wrapper.py
vllm/engine/__init__.py
vllm/engine/arg_utils.py
vllm/engine/async_llm_engine.py
vllm/engine/llm_engine.py
vllm/engine/metrics.py
vllm/engine/output_processor/__init__.py
vllm/engine/output_processor/interfaces.py
vllm/engine/output_processor/multi_step.py
vllm/engine/output_processor/single_step.py
vllm/engine/output_processor/stop_checker.py
vllm/engine/output_processor/util.py
vllm/entrypoints/__init__.py
vllm/entrypoints/api_server.py
vllm/entrypoints/llm.py
vllm/entrypoints/openai/__init__.py
vllm/entrypoints/openai/api_server.py
vllm/entrypoints/openai/cli_args.py
vllm/entrypoints/openai/protocol.py
vllm/entrypoints/openai/run_batch.py
vllm/entrypoints/openai/serving_chat.py
vllm/entrypoints/openai/serving_completion.py
vllm/entrypoints/openai/serving_embedding.py
vllm/entrypoints/openai/serving_engine.py
vllm/executor/__init__.py
vllm/executor/cpu_executor.py
vllm/executor/distributed_gpu_executor.py
vllm/executor/executor_base.py
vllm/executor/gpu_executor.py
vllm/executor/multiproc_gpu_executor.py
vllm/executor/multiproc_worker_utils.py
vllm/executor/neuron_executor.py
vllm/executor/ray_gpu_executor.py
vllm/executor/ray_utils.py
vllm/executor/tpu_executor.py
vllm/logging/__init__.py
vllm/logging/formatter.py
vllm/lora/__init__.py
vllm/lora/fully_sharded_layers.py
vllm/lora/layers.py
vllm/lora/lora.py
vllm/lora/models.py
vllm/lora/punica.py
vllm/lora/request.py
vllm/lora/utils.py
vllm/lora/worker_manager.py
vllm/model_executor/__init__.py
vllm/model_executor/custom_op.py
vllm/model_executor/pooling_metadata.py
vllm/model_executor/sampling_metadata.py
vllm/model_executor/utils.py
vllm/model_executor/guided_decoding/__init__.py
vllm/model_executor/guided_decoding/lm_format_enforcer_decoding.py
vllm/model_executor/guided_decoding/outlines_decoding.py
vllm/model_executor/guided_decoding/outlines_logits_processors.py
vllm/model_executor/layers/__init__.py
vllm/model_executor/layers/activation.py
vllm/model_executor/layers/layernorm.py
vllm/model_executor/layers/linear.py
vllm/model_executor/layers/logits_processor.py
vllm/model_executor/layers/pooler.py
vllm/model_executor/layers/rejection_sampler.py
vllm/model_executor/layers/rotary_embedding.py
vllm/model_executor/layers/sampler.py
vllm/model_executor/layers/vocab_parallel_embedding.py
vllm/model_executor/layers/fused_moe/__init__.py
vllm/model_executor/layers/fused_moe/fused_moe.py
vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json
vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json
vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json
vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json
vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json
vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json
vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json
vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json
vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json
vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json
vllm/model_executor/layers/ops/__init__.py
vllm/model_executor/layers/ops/rand.py
vllm/model_executor/layers/ops/sample.py
vllm/model_executor/layers/quantization/__init__.py
vllm/model_executor/layers/quantization/aqlm.py
vllm/model_executor/layers/quantization/awq.py
vllm/model_executor/layers/quantization/base_config.py
vllm/model_executor/layers/quantization/bitsandbytes.py
vllm/model_executor/layers/quantization/deepspeedfp.py
vllm/model_executor/layers/quantization/fp8.py
vllm/model_executor/layers/quantization/gptq.py
vllm/model_executor/layers/quantization/gptq_marlin.py
vllm/model_executor/layers/quantization/gptq_marlin_24.py
vllm/model_executor/layers/quantization/marlin.py
vllm/model_executor/layers/quantization/schema.py
vllm/model_executor/layers/quantization/squeezellm.py
vllm/model_executor/layers/quantization/compressed_tensors/__init__.py
vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py
vllm/model_executor/layers/quantization/compressed_tensors/utils.py
vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_unquantized.py
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16.py
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_dynamictoken.py
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_statictensor.py
vllm/model_executor/layers/quantization/utils/__init__.py
vllm/model_executor/layers/quantization/utils/format_24.py
vllm/model_executor/layers/quantization/utils/marlin_24_perms.py
vllm/model_executor/layers/quantization/utils/marlin_perms.py
vllm/model_executor/layers/quantization/utils/marlin_utils.py
vllm/model_executor/layers/quantization/utils/quant_utils.py
vllm/model_executor/model_loader/__init__.py
vllm/model_executor/model_loader/loader.py
vllm/model_executor/model_loader/neuron.py
vllm/model_executor/model_loader/tensorizer.py
vllm/model_executor/model_loader/utils.py
vllm/model_executor/model_loader/weight_utils.py
vllm/model_executor/models/__init__.py
vllm/model_executor/models/arctic.py
vllm/model_executor/models/baichuan.py
vllm/model_executor/models/bloom.py
vllm/model_executor/models/chatglm.py
vllm/model_executor/models/commandr.py
vllm/model_executor/models/dbrx.py
vllm/model_executor/models/decilm.py
vllm/model_executor/models/deepseek.py
vllm/model_executor/models/falcon.py
vllm/model_executor/models/gemma.py
vllm/model_executor/models/gpt2.py
vllm/model_executor/models/gpt_bigcode.py
vllm/model_executor/models/gpt_j.py
vllm/model_executor/models/gpt_neox.py
vllm/model_executor/models/internlm2.py
vllm/model_executor/models/jais.py
vllm/model_executor/models/llama.py
vllm/model_executor/models/llama_embedding.py
vllm/model_executor/models/llava.py
vllm/model_executor/models/llava_next.py
vllm/model_executor/models/minicpm.py
vllm/model_executor/models/mixtral.py
vllm/model_executor/models/mixtral_quant.py
vllm/model_executor/models/mpt.py
vllm/model_executor/models/olmo.py
vllm/model_executor/models/opt.py
vllm/model_executor/models/orion.py
vllm/model_executor/models/phi.py
vllm/model_executor/models/phi3_small.py
vllm/model_executor/models/qwen.py
vllm/model_executor/models/qwen2.py
vllm/model_executor/models/qwen2_moe.py
vllm/model_executor/models/stablelm.py
vllm/model_executor/models/starcoder2.py
vllm/model_executor/models/vlm_base.py
vllm/model_executor/models/xverse.py
vllm/multimodal/__init__.py
vllm/multimodal/base.py
vllm/multimodal/image.py
vllm/multimodal/registry.py
vllm/multimodal/utils.py
vllm/spec_decode/__init__.py
vllm/spec_decode/batch_expansion.py
vllm/spec_decode/interfaces.py
vllm/spec_decode/metrics.py
vllm/spec_decode/multi_step_worker.py
vllm/spec_decode/ngram_worker.py
vllm/spec_decode/proposer_worker_base.py
vllm/spec_decode/spec_decode_worker.py
vllm/spec_decode/top1_proposer.py
vllm/spec_decode/util.py
vllm/transformers_utils/__init__.py
vllm/transformers_utils/config.py
vllm/transformers_utils/detokenizer.py
vllm/transformers_utils/image_processor.py
vllm/transformers_utils/tokenizer.py
vllm/transformers_utils/configs/__init__.py
vllm/transformers_utils/configs/arctic.py
vllm/transformers_utils/configs/chatglm.py
vllm/transformers_utils/configs/dbrx.py
vllm/transformers_utils/configs/falcon.py
vllm/transformers_utils/configs/jais.py
vllm/transformers_utils/configs/mpt.py
vllm/transformers_utils/tokenizer_group/__init__.py
vllm/transformers_utils/tokenizer_group/base_tokenizer_group.py
vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py
vllm/transformers_utils/tokenizer_group/tokenizer_group.py
vllm/transformers_utils/tokenizers/__init__.py
vllm/transformers_utils/tokenizers/baichuan.py
vllm/usage/__init__.py
vllm/usage/usage_lib.py
vllm/worker/__init__.py
vllm/worker/cache_engine.py
vllm/worker/cpu_model_runner.py
vllm/worker/cpu_worker.py
vllm/worker/embedding_model_runner.py
vllm/worker/model_runner.py
vllm/worker/neuron_model_runner.py
vllm/worker/neuron_worker.py
vllm/worker/tpu_model_runner.py
vllm/worker/tpu_worker.py
vllm/worker/worker.py
vllm/worker/worker_base.py