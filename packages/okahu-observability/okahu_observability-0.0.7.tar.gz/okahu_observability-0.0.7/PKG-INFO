Metadata-Version: 2.3
Name: okahu-observability
Version: 0.0.7
Summary: package with okahu opentelemetry
Project-URL: Homepage, https://github.com/okahu/demo-repository
Project-URL: Issues, https://github.com/okahu/demo-repository/issues
Author-email: "Okahu Inc." <okahu-pypi@okahu.ai>
License-File: LICENSE
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Requires-Python: >=3.8
Requires-Dist: opentelemetry-api>=1.21.0
Requires-Dist: opentelemetry-instrumentation
Requires-Dist: opentelemetry-sdk>=1.21.0
Requires-Dist: requests
Requires-Dist: wrapt>=1.14.0
Provides-Extra: dev
Requires-Dist: faiss-cpu==1.7.4; extra == 'dev'
Requires-Dist: instructorembedding==1.0.1; extra == 'dev'
Requires-Dist: langchain-openai==0.0.5; extra == 'dev'
Requires-Dist: llama-index-embeddings-huggingface==0.2.0; extra == 'dev'
Requires-Dist: llama-index==0.10.30; extra == 'dev'
Requires-Dist: numpy==1.26.4; extra == 'dev'
Requires-Dist: pytest==8.0.0; extra == 'dev'
Requires-Dist: sentence-transformers==2.6.1; extra == 'dev'
Requires-Dist: types-requests==2.31.0.20240106; extra == 'dev'
Description-Content-Type: text/markdown

# Okahu callback handler

This package provides okahu telemetry setup.

## Installing the package
```
> python3 -m pip install pipenv

> pipenv install okahu-observability
```

## References

[Managing application dependencies](https://packaging.python.org/en/latest/tutorials/managing-dependencies/)

## Usage
```python
from okahu_apptrace.instrumentor import setup_okahu_telemetry
from langchain.chains import LLMChain
from langchain_openai import OpenAI
from langchain.prompts import PromptTemplate

# Set the OKAHU_API_KEY environment variable, if not set already
os.environ["OKAHU_API_KEY"] = "okh_XXXXXXXX_XXXXXXXXXXXXXXXXXXXXXX"

# Call the setup Okahu telemetry method
app_name = "simple_math_app"
setup_okahu_telemetry(workflow_name=app_name)

llm = OpenAI()
prompt = PromptTemplate.from_template("1 + {number} = ")

chain = LLMChain(llm=llm, prompt=prompt)
chain.invoke({"number":2})

# Request callbacks: Finally, let's use the request `callbacks` to achieve the same result
chain = LLMChain(llm=llm, prompt=prompt)
chain.invoke({"number":2}, {"callbacks":[handler]})
    
```

### Monitoring custom methods with Okahu

```python
from okahu_apptrace.wrapper import WrapperMethod,task_wrapper,atask_wrapper
from opentelemetry.sdk.trace.export import BatchSpanProcessor, ConsoleSpanExporter

# extend the default wrapped methods list as follows
app_name = "simple_math_app"
setup_okahu_telemetry(
        workflow_name=app_name,
        span_processors=[BatchSpanProcessor(ConsoleSpanExporter())],
        wrapper_methods=[
            WrapperMethod(
                package="langchain.schema.runnable",
                object="RunnableParallel",
                method="invoke",
                span_name="langchain.workflow",
                wrapper=task_wrapper),
            WrapperMethod(
                package="langchain.schema.runnable",
                object="RunnableParallel",
                method="ainvoke",
                span_name="langchain.workflow",
                wrapper=atask_wrapper)
        ])

```

