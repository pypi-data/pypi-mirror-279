# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/scraper/ScrapeDomoSupport.ipynb.

# %% auto 0
__all__ = ['get_all_tickets_soup', 'get_ticket__main', 'get_ticket']

# %% ../../nbs/scraper/ScrapeDomoSupport.ipynb 2
import time
import domolibrary_extensions.scraper.routes as desr
from bs4 import BeautifulSoup
from selenium.webdriver.common.keys import Keys

# %% ../../nbs/scraper/ScrapeDomoSupport.ipynb 6
def get_all_tickets_soup(authenticated_driver: desr.webdriver) -> BeautifulSoup:
    url = f"https://domo-support.domo.com/s/"

    authenticated_driver.get(url)

    time.sleep(2)

    # browser element
    page_source = desr.get_pagesource(
        driver=authenticated_driver,
        search_criteria_tuple=(desr.By.CLASS_NAME, "cellContainer"),
        return_soup=False,
        return_entire_page=True,
    )

    # try get all table elements
    # len_table = 0
    # while len_table == 0:
    #     print(f"ðŸ’¤ sleeping {len_table} ðŸ’¤")

    #     len_table = len(page_source.find_all("td"))

    # try scroll

    # len_table = 0
    new_len_table = 0
    prev_len_table = None

    while new_len_table != prev_len_table:
        scroll_bar = desr.wait_and_return(
            driver=authenticated_driver,
            search_criteria_tuple=(desr.By.CLASS_NAME, "uiScroller"),
            return_soup=False,
            # min_sleep_time=15,
        )
        scroll_bar.send_keys(Keys.END)

        time.sleep(2)
        print(f"ðŸ’¤ðŸ“œ sleeping on the scroll {new_len_table} ðŸ’¤ðŸ“œ")

        soup = BeautifulSoup(page_source, parser="lxml")

        prev_len_table = new_len_table
        new_len_table = len(soup.find_all("td"))

    print(f"ðŸš€ done retrieving table {new_len_table} ðŸš€")

    return soup.find("table")

# %% ../../nbs/scraper/ScrapeDomoSupport.ipynb 10
def get_ticket__main(soup):
    # soup = BeautifulSoup(html, 'html.parser')
    data = []

    tables = soup.find_all("div", class_="test-id__record-layout-container")

    res = {}
    for table in tables:
        rows = table.find_all("div", class_="slds-form-element")
        res.update(
            {
                row.find("div", class_="slds-form-element__label")
                .text.strip(): row.find("div", class_="slds-form-element__control")
                .text.strip()
                for row in rows
            }
        )

    return res


def get_ticket(authenticated_driver, url):

    authenticated_driver.get(url)

    description_class = "test-id__field-value"
    soup = desr.get_pagesource(
        driver=authenticated_driver,
        search_criteria_tuple=(desr.By.CLASS_NAME, description_class),
        return_soup=True,
    )

    casecomments_class = "caseCommentsContainer"
    casecomments_soup = desr.get_pagesource(
        driver=authenticated_driver,
        search_criteria_tuple=(desr.By.CLASS_NAME, casecomments_class),
        return_soup=True,
    ).find(class_=casecomments_class)

    casecomments_ls = []
    for li in casecomments_soup.find("ul").find_all("li"):
        comment_hdr = li.find(class_="date").text
        comment_body = li.find(class_="commentBody").text

        casecomments_ls.append({"date": comment_hdr, "body": comment_body})

    return {**get_ticket__main(soup), "case_comments": casecomments_ls}
