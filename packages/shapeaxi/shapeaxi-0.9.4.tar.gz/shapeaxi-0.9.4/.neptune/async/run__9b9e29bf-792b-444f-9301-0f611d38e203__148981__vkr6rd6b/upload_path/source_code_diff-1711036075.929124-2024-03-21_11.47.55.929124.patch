diff --git a/shapeaxi/IcoConcOperator.py b/shapeaxi/IcoConcOperator.py
index 2a29889..a8a7e91 100644
--- a/shapeaxi/IcoConcOperator.py
+++ b/shapeaxi/IcoConcOperator.py
@@ -98,6 +98,7 @@ class IcosahedronConv2d(nn.Module):
 
         return output
 
+
 class IcosahedronConv1d(nn.Module):
     def __init__(self,module,verts,list_edges):
         super().__init__()
diff --git a/shapeaxi/__about__.py b/shapeaxi/__about__.py
index c1c735d..4c655b5 100644
--- a/shapeaxi/__about__.py
+++ b/shapeaxi/__about__.py
@@ -1,6 +1,6 @@
 # SPDX-FileCopyrightText: 2023-present FlorianDAVAUX <91245912+FlorianDAVAUX@users.noreply.github.com>
 #
 # SPDX-License-Identifier: MIT
-__version__ = "0.7.5"
+__version__ = "0.7.6"
 
 
diff --git a/shapeaxi/saxi_dataset.py b/shapeaxi/saxi_dataset.py
index 92ff164..c069e4c 100644
--- a/shapeaxi/saxi_dataset.py
+++ b/shapeaxi/saxi_dataset.py
@@ -374,7 +374,7 @@ class SaxiIcoDataset_fs(Dataset):
             self.data_to_tensor(path_sa).unsqueeze(dim=1),
             self.data_to_tensor(path_thickness).unsqueeze(dim=1),
             self.data_to_tensor(path_curvature).unsqueeze(dim=1),
-            self.data_to_tensor(path_sulc).unsqueeze(dim=1)
+            self.data_to_tensor(path_sulc).unsqueeze(dim=1),
         ]
 
         # Convert sphere and white matter to vtk
@@ -383,6 +383,14 @@ class SaxiIcoDataset_fs(Dataset):
         wm_path = os.path.join(path_to_fs_data, f'{hemisphere_prefix}.white')
         wm_vtk_path = os.path.join(path_to_fs_data, f'{hemisphere_prefix}.white.vtk')
 
+
+        paths = [path_sa, path_thickness, path_curvature, path_sulc, sphere_path, wm_path, sphere_vtk_path, wm_vtk_path]
+
+        for path in paths:
+            if not os.path.exists(path):
+                print(f'File {path} does not exist')
+                return
+
         if not os.path.exists(sphere_vtk_path):
             mris_command = f'mris_convert {sphere_path} {sphere_vtk_path}'
             subprocess.run(mris_command, shell=True)
diff --git a/shapeaxi/saxi_folds.py b/shapeaxi/saxi_folds.py
index 7d55273..0cba011 100644
--- a/shapeaxi/saxi_folds.py
+++ b/shapeaxi/saxi_folds.py
@@ -256,8 +256,10 @@ def main(args, arg_groups):
                 if saxi_train_args[k]:
                     command.append('--' + str(k))
                     command.append(str(saxi_train_args[k]))
-
-            env = {'CUDA_VISIBLE_DEVICES' : '0'}
+            
+            env = os.environ.copy()  # Copy the current environment variables
+            env['NEPTUNE_API_TOKEN'] = os.environ['NEPTUNE_API_TOKEN']  # Add NEPTUNE_API_TOKEN to the environment for the subprocess
+            # env = {'CUDA_VISIBLE_DEVICES' : '0'}
             subprocess.run(command, env=env)
 
         print(bcolors.SUCCESS, "End training for fold {f}".format(f=f), bcolors.ENDC)
@@ -564,7 +566,7 @@ def cml():
 
     # Arguments used for training
     train_group = parser.add_argument_group('Train')
-    train_group.add_argument('--nn', type=str, help='Neural network name : SaxiClassification, SaxiRegression, SaxiSegmentation, SaxiIcoClassification, SaxiIcoClassification_fs', required=True, choices=['SaxiClassification', 'SaxiRegression', 'SaxiSegmentation', 'SaxiIcoClassification', 'SaxiIcoClassification_fs'])
+    train_group.add_argument('--nn', type=str, help='Neural network name : SaxiClassification, SaxiRegression, SaxiSegmentation, SaxiIcoClassification, SaxiIcoClassification_fs', required=True, choices=['SaxiClassification', 'SaxiRegression', 'SaxiSegmentation', 'SaxiIcoClassification', 'SaxiIcoClassification_fs', 'SaxiIcoClassification_fs_test'])
     train_group.add_argument('--model', type=str, help='Model to continue training', default= None)
     train_group.add_argument('--train_sphere_samples', type=int, help='Number of samples for the training sphere', default=10000)
     train_group.add_argument('--surf_column', type=str, help='Surface column name', default="surf")
diff --git a/shapeaxi/saxi_logger.py b/shapeaxi/saxi_logger.py
index a1311c2..1cef341 100644
--- a/shapeaxi/saxi_logger.py
+++ b/shapeaxi/saxi_logger.py
@@ -234,20 +234,44 @@ class SaxiImageLoggerNeptune_Ico_fs(Callback):
             VFR = VFR.to(pl_module.device,non_blocking=True).to(torch.float32)
             FFR = FFR.to(pl_module.device,non_blocking=True)
 
+            print("VL",VL.shape)
+            print("FL",FL.shape)
+            print("VFL",VFL.shape)
+            print("FFL",FFL.shape)
+            print("VR",VR.shape)
+            print("FR",FR.shape)
+            print("VFR",VFR.shape)
+            print("FFR",FFR.shape)
+
+
             with torch.no_grad():
                 # Render the input surface mesh to an image
-                X, PF = pl_module.render(VL[0:1], FL[0:1], VFL[0:1], FFL[0:1], VR[0:1], FR[0:1], VFR[0:1], FFR[0:1])
+                XL, PFL = pl_module.render(VL[0:1], FL[0:1], VFL[0:1], FFL[0:1])
+                print("XL",XL.shape)
+                # XR, PFR = pl_module.render(VR[0:1], FR[0:1], VFR[0:1], FFR[0:1])
 
-                grid_X = torchvision.utils.make_grid(X[0, 0:num_images, 0:3, :, :])#Grab the first image, RGB channels only, X, Y. The time dimension is on dim=1
+                grid_XL = torchvision.utils.make_grid(XL[0, 0:num_images, 0:3, :, :])#Grab the first image, RGB channels only, X, Y. The time dimension is on dim=1
                 fig = plt.figure(figsize=(7, 9))
-                ax = plt.imshow(grid_X.permute(1, 2, 0).cpu().numpy())
+                ax = plt.imshow(grid_XL.permute(1, 2, 0).cpu().numpy())
                 trainer.logger.experiment["images/x"].upload(fig)
                 plt.close()
                 
-                grid_X = torchvision.utils.make_grid(X[0, 0:num_images, 3:, :, :])#Grab the depth map. The time dimension is
+                grid_XL = torchvision.utils.make_grid(XL[0, 0:num_images, 3:, :, :])#Grab the depth map. The time dimension is
                 fig = plt.figure(figsize=(7, 9))
-                ax = plt.imshow(grid_X.permute(1, 2, 0).cpu().numpy())
+                ax = plt.imshow(grid_XL.permute(1, 2, 0).cpu().numpy())
                 trainer.logger.experiment["images/x_depth"].upload(fig)
                 plt.close()
 
+                # grid_XR = torchvision.utils.make_grid(XR[0, 0:num_images, 0:3, :, :])#Grab the first image, RGB channels only, X, Y. The time dimension is on dim=1
+                # fig = plt.figure(figsize=(7, 9))
+                # ax = plt.imshow(grid_XR.permute(1, 2, 0).cpu().numpy())
+                # trainer.logger.experiment["images/x"].upload(fig)
+                # plt.close()
+
+                # grid_XR = torchvision.utils.make_grid(XR[0, 0:num_images, 3:, :, :])#Grab the depth map. The time dimension is
+                # fig = plt.figure(figsize=(7, 9))
+                # ax = plt.imshow(grid_XR.permute(1, 2, 0).cpu().numpy())
+                # trainer.logger.experiment["images/x_depth"].upload(fig)
+                # plt.close()
+
 
diff --git a/shapeaxi/saxi_nets.py b/shapeaxi/saxi_nets.py
index 33d05da..5a43211 100644
--- a/shapeaxi/saxi_nets.py
+++ b/shapeaxi/saxi_nets.py
@@ -26,7 +26,6 @@ from io import BytesIO
 import json
 import os
 
-
 from . import utils
 from .IcoConcOperator import IcosahedronConv1d, IcosahedronConv2d, IcosahedronLinear
 from .saxi_transforms import GaussianNoise, MaxPoolImages, AvgPoolImages, SelfAttention, Identity, TimeDistributed
@@ -852,8 +851,9 @@ class SaxiIcoClassification_fs(pl.LightningModule):
         lights = AmbientLights()
         rasterizer = MeshRasterizer(cameras=self.hparams.cameras,raster_settings=raster_settings)
 
-        self.hparams.phong_renderer = MeshRendererWithFragments(rasterizer=rasterizer,shader=HardPhongShader(cameras=self.hparams.cameras, lights=lights))        
-    
+        self.hparams.phong_renderer = MeshRendererWithFragments(rasterizer=rasterizer,shader=HardPhongShader(cameras=self.hparams.cameras, lights=lights))
+
+
     def to(self, device=None):
         # Move the renderer to the specified device
         self.hparams.phong_renderer = self.hparams.phong_renderer.to(device)
@@ -1023,6 +1023,289 @@ class SaxiIcoClassification_fs(pl.LightningModule):
         return (layer[:3] == 'Ico')
 
 
+###################################################################   DOWN BLOCK TEST  ##################################################################################################################
+
+
+from .down_block import *
+
+class down_block(nn.Module):
+    """
+    downsampling block in spherical unet
+    mean pooling => (conv => BN => ReLU) * 2
+    
+    """
+    def __init__(self, conv_layer, in_ch, out_ch, neigh_orders, pool_neigh_orders, first = False):
+        super(down_block, self).__init__()
+
+        if first:
+            self.block = nn.Sequential(
+                conv_layer(in_ch, out_ch, neigh_orders),
+                nn.BatchNorm1d(out_ch, momentum=0.15, affine=True, track_running_stats=False),
+                nn.LeakyReLU(0.2, inplace=True),
+                conv_layer(out_ch, out_ch, neigh_orders),
+                nn.BatchNorm1d(out_ch, momentum=0.15, affine=True, track_running_stats=False),
+                nn.LeakyReLU(0.2, inplace=True)
+        )
+
+        else:
+            self.block = nn.Sequential(
+                pool_layer(pool_neigh_orders, 'mean'),
+                conv_layer(in_ch, out_ch, neigh_orders),
+                nn.BatchNorm1d(out_ch, momentum=0.15, affine=True, track_running_stats=False),
+                nn.LeakyReLU(0.2, inplace=True),
+                conv_layer(out_ch, out_ch, neigh_orders),
+                nn.BatchNorm1d(out_ch, momentum=0.15, affine=True, track_running_stats=False),
+                nn.LeakyReLU(0.2, inplace=True),
+        )
+
+    def forward(self, x):
+        # batch norm version
+        x = self.block(x)
+        return x
+
+    
+
+class SaxiIcoClassification_fs_test(pl.LightningModule):
+    def __init__(self, **kwargs):
+        super(SaxiIcoClassification_fs_test, self).__init__()
+        self.save_hyperparameters()
+        self.y_pred = []
+        self.y_true = []
+
+        # ico_sphere = utils.CreateIcosahedron(self.hparams.radius, self.hparams.ico_lvl)
+        # ico_sphere_verts, ico_sphere_faces, ico_sphere_edges = utils.PolyDataToTensors(ico_sphere)
+        
+        self.ico_sphere_verts = ico_sphere_verts
+        self.ico_sphere_edges = ico_sphere_edges
+        R=[]
+        T=[]
+        for coords_cam in self.ico_sphere_verts.tolist():
+            camera_position = torch.FloatTensor([coords_cam])
+            R_current = look_at_rotation(camera_position)
+            # check if camera coords vector and up vector for R are collinear
+            if torch.equal(torch.cross(camera_position,torch.tensor([[0.,1.,0.]])),torch.tensor([[0., 0., 0.]])):
+               R_current = look_at_rotation(camera_position, up = torch.tensor([[0.0, 0.0, 1.0]]),)
+            T_current = -torch.bmm(R_current.transpose(1, 2), camera_position[:,:,None])[:, :, 0]   # (1, 3)
+
+            R.append(R_current)
+            T.append(T_current)
+        self.R=torch.cat(R)
+        self.T=torch.cat(T)
+        self.nbr_cam = len(self.R)
+
+        self.drop = nn.Dropout(p=self.hparams.dropout_lvl)
+        self.noise = GaussianNoise(mean=0.0, std=self.hparams.noise_lvl)
+
+        # Left path
+        self.create_network('L', self.hparams.out_size)
+        # Right path
+        self.create_network('R', self.hparams.out_size)
+
+        #Loss
+        self.loss_train = nn.CrossEntropyLoss()
+        self.loss_val = nn.CrossEntropyLoss()
+        self.loss_test = nn.CrossEntropyLoss()
+
+        #Final layer 
+        self.Classification = nn.Linear(2*self.hparams.out_size, 2)
+
+        #Accuracy
+        self.train_accuracy = torchmetrics.Accuracy('multiclass',num_classes=self.hparams.out_classes,average='macro')
+        self.val_accuracy = torchmetrics.Accuracy('multiclass',num_classes=self.hparams.out_classes,average='macro')
+        
+        # Initialize a perspective camera.
+        self.hparams.cameras = FoVPerspectiveCameras()
+
+        # We will also create a Phong renderer. This is simpler and only needs to render one face per pixel.
+        raster_settings = RasterizationSettings(image_size=self.hparams.image_size,blur_radius=0,faces_per_pixel=1,max_faces_per_bin=100000)
+
+        lights = AmbientLights()
+        rasterizer = MeshRasterizer(cameras=self.hparams.cameras,raster_settings=raster_settings)
+
+        self.hparams.phong_renderer = MeshRendererWithFragments(rasterizer=rasterizer,shader=HardPhongShader(cameras=self.hparams.cameras, lights=lights))
+
+
+        neigh_orders_42, neigh_orders_12 = Get_neighs_order()
+        print(len(neigh_orders_42))
+        print(len(neigh_orders_12))
+        conv_layer = onering_conv_layer
+        self.down1 = down_block(conv_layer, 6, 256, neigh_orders_42, None, True)
+
+
+
+    def to(self, device=None):
+        # Move the renderer to the specified device
+        self.hparams.phong_renderer = self.hparams.phong_renderer.to(device)
+        return super().to(device)
+
+    
+    # Create an icosphere
+    def create_network(self, side, out_size):
+
+        if hasattr(monai.networks.nets, self.hparams.base_encoder):
+            template_model = getattr(monai.networks.nets, self.hparams.base_encoder)
+        elif hasattr(torchvision.models, self.hparams.base_encoder):
+            template_model = getattr(torchvision.models, self.hparams.base_encoder)
+        else:
+            raise "{base_encoder} not in monai networks or torchvision".format(base_encoder=self.hparams.base_encoder)
+
+        model_params = eval('dict(%s)' % self.hparams.base_encoder_params.replace(' ',''))
+        
+        self.convnet = template_model(**model_params)
+        setattr(self, f'TimeDistributed{side}', TimeDistributed(self.convnet))
+
+        if self.hparams.layer == 'Att':
+            setattr(self, f'WV{side}', nn.Linear(self.hparams.hidden_dim, out_size))
+            setattr(self, f'Attention{side}', SelfAttention(self.hparams.hidden_dim, out_size))
+
+        elif self.hparams.layer in {'IcoConv2D', 'IcoConv1D', 'IcoLinear'}:
+            if self.hparams.layer == 'IcoConv2D':
+                conv_layer = nn.Conv2d(self.hparams.hidden_dim, out_size, kernel_size=(3, 3), stride=2, padding=0)
+            elif self.hparams.layer == 'IcoConv1D':
+                conv_layer = nn.Conv1d(self.hparams.hidden_dim, out_size, 7)
+            else:
+                conv_layer = nn.Linear(self.hparams.hidden_dim * 7, out_size)
+            icosahedron = IcosahedronConv2d(conv_layer, self.ico_sphere_verts, self.ico_sphere_edges)
+            avgpool = AvgPoolImages(nbr_images=self.nbr_cam)
+            setattr(self, f'IcosahedronConv2d{side}', icosahedron)
+            setattr(self, f'pooling{side}', avgpool)
+
+        else:
+            raise f"{self.hparams.layer} not in IcoConv2D, IcoConv1D, or IcoLinear"
+
+
+    def configure_optimizers(self):
+        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr)
+        return optimizer
+
+
+    def forward(self, x):
+        VL, FL, VFL, FFL, VR, FR, VFR, FFR = x
+        ###To Device
+        VL = VL.to(self.device,non_blocking=True)
+        FL = FL.to(self.device,non_blocking=True)
+        VFL = VFL.to(self.device,non_blocking=True)
+        FFL = FFL.to(self.device,non_blocking=True)
+        VR = VR.to(self.device,non_blocking=True)
+        FR = FR.to(self.device,non_blocking=True)
+        VFR = VFR.to(self.device,non_blocking=True)
+        FFR = FFR.to(self.device,non_blocking=True)
+        ###Resnet18+Ico+Concatenation
+        xL = self.get_features(VL,FL,VFL,FFL,'L')
+        xR = self.get_features(VR,FR,VFR,FFR,'R')
+        print("xL",xL.shape)
+        xL = self.down1(xL)
+        print("xL after",xL.shape)
+        l_left_right = [xL,xR]
+        x = torch.cat(l_left_right,dim=1)
+        # ###Last classification layer
+        x = self.drop(x)
+        x = self.Classification(x)
+
+        return x
+
+
+    def get_features(self,V,F,VF,FF,side):
+        x, PF = self.render(V,F,VF,FF)  
+
+        x = getattr(self, f'TimeDistributed{side}')(x)
+
+        return x
+
+
+    def render(self,V,F,VF,FF):
+        textures = TexturesVertex(verts_features=VF[:, :, :3])
+        meshes = Meshes(
+            verts=V,
+            faces=F,
+            textures=textures
+        )
+        PF = []
+        for i in range(self.nbr_cam):
+            pix_to_face = self.GetView(meshes,i)
+            PF.append(pix_to_face.unsqueeze(dim=1))
+        PF = torch.cat(PF, dim=1)
+
+        l_features = []
+        for index in range(FF.shape[-1]):
+            l_features.append(torch.take(FF[:,index],PF)*(PF >= 0)) # take each feature for each pictures
+        x = torch.cat(l_features,dim=2)
+
+        return x, PF
+
+
+    def training_step(self, train_batch, batch_idx):
+        VL, FL, VFL, FFL, VR, FR, VFR, FFR, Y = train_batch
+        x = self((VL, FL, VFL, FFL, VR, FR, VFR, FFR))
+        loss = self.loss_train(x,Y)
+        self.log('train_loss', loss) 
+        predictions = torch.argmax(x, dim=1, keepdim=True)
+        self.train_accuracy(predictions, Y.reshape(-1, 1))
+        self.log("train_acc", self.train_accuracy, batch_size=self.hparams.batch_size)           
+
+        return loss
+
+
+    def validation_step(self,val_batch,batch_idx):
+        VL, FL, VFL, FFL, VR, FR, VFR, FFR, Y = val_batch
+        x = self((VL, FL, VFL, FFL, VR, FR, VFR, FFR))
+        loss = self.loss_val(x,Y)
+        self.log('val_loss', loss)
+        predictions = torch.argmax(x, dim=1, keepdim=True)
+        val_acc = self.val_accuracy(predictions, Y.reshape(-1, 1))
+        self.log("val_acc", val_acc, batch_size=self.hparams.batch_size)
+
+        return val_acc
+
+
+    def test_step(self,test_batch,batch_idx):
+        VL, FL, VFL, FFL, VR, FR, VFR, FFR, Y = test_batch
+        x = self((VL, FL, VFL, FFL, VR, FR, VFR, FFR))
+        loss = self.loss_test(x,Y)
+        self.log('test_loss', loss, batch_size=self.hparams.batch_size)
+        predictions = torch.argmax(x, dim=1, keepdim=True)
+        output = [predictions,Y]
+
+        return output
+
+
+    def test_epoch_end(self,input_test):
+        y_pred = []
+        y_true = []
+        for ele in input_test:
+            y_pred += ele[0].tolist()
+            y_true += ele[1].tolist()
+        # target_names = ['No ASD','ASD']
+        target_names = ['No QC','QC']
+        self.y_pred = y_pred
+        self.y_true = y_true
+        #Classification report
+        print(self.y_pred)
+        print(self.y_true)
+        print(classification_report(self.y_true, self.y_pred, target_names=target_names))
+
+
+    def GetView(self,meshes,index):
+        phong_renderer = self.hparams.phong_renderer.to(self.device)
+        R = self.R[index][None].to(self.device)
+        T = self.T[index][None].to(self.device)
+        _, fragments = phong_renderer(meshes.clone(),R=R,T=T)
+        pix_to_face = fragments.pix_to_face
+        pix_to_face = pix_to_face.permute(0,3,1,2)
+
+        return pix_to_face
+
+
+    def get_y_for_report_classification(self):
+        #This function could be called only after test step was done
+        return (self.y_pred,self.hparams.y_true)
+    
+
+    def Is_it_Icolayer(self,layer):
+        return (layer[:3] == 'Ico')
+
+
+
 #####################################################################################################################################################################################
 #                                                                                                                                                                                   #
 #                                                                                       Segmentation                                                                                #
diff --git a/shapeaxi/saxi_predict.py b/shapeaxi/saxi_predict.py
index 9c579a9..8064f61 100644
--- a/shapeaxi/saxi_predict.py
+++ b/shapeaxi/saxi_predict.py
@@ -171,7 +171,7 @@ def SaxiRegression_predict(args, mount_point, df, fname, ext, test_loader, model
 def SaxiIcoClassification_predict(args, mount_point, df, fname, ext):
     SAXINETS = getattr(saxi_nets, args.nn)
     model = SAXINETS.load_from_checkpoint(args.model)
-    model.to(torch.device('cuda:0'))
+    model.to(torch.device(args.device))
     model.eval()
     
     list_demographic = ['Gender','MRI_Age','AmygdalaLeft','HippocampusLeft','LatVentsLeft','ICV','Crbm_totTissLeft','Cblm_totTissLeft','AmygdalaRight','HippocampusRight','LatVentsRight','Crbm_totTissRight','Cblm_totTissRight'] #MLR
diff --git a/shapeaxi/saxi_train.py b/shapeaxi/saxi_train.py
index ef705bb..937e59e 100644
--- a/shapeaxi/saxi_train.py
+++ b/shapeaxi/saxi_train.py
@@ -23,6 +23,7 @@ from . import saxi_nets
 from .saxi_nets import MonaiUNet, SaxiIcoClassification
 from .saxi_logger import SaxiImageLoggerTensorboard, SaxiImageLoggerTensorboardSegmentation, SaxiImageLoggerTensorboardIco, SaxiImageLoggerTensorboardIco_fs, SaxiImageLoggerNeptune, SaxiImageLoggerNeptune_Ico_fs
 
+
 def logger_neptune_tensorboard(args):
     image_logger = None
     logger = None
@@ -81,17 +82,16 @@ def SaxiClassification_SaxiRegression_train(args, checkpoint_callback, mount_poi
     trainer.fit(model, datamodule=brain_data, ckpt_path=args.model)
 
 
-def SaxiSegmentation_train(args, checkpoint_callback, mount_point, df_train, df_val, df_test, logger, early_stop_callback):
+def SaxiSegmentation_train(args, checkpoint_callback, mount_point, df_train, df_val, df_test, early_stop_callback):
 
     #Creation of Dataset
     brain_data = SaxiDataModule(df_train, df_val, df_test,mount_point = mount_point,batch_size = args.batch_size,num_workers = args.num_workers,model = args.nn,surf_column = 'surf',surf_property = 'UniversalID',train_transform = UnitSurfTransform(),valid_transform = UnitSurfTransform(),test_transform = UnitSurfTransform())
-    #train_transform = RandomRemoveTeethTransform(surf_property="UniversalID", random_rotation=True),
 
     # model = MonaiUNet(args, out_channels = 34, class_weights=None, image_size=320, train_sphere_samples=args.train_sphere_samples)
 
 
     # CHECK THISSSSS :
-
+    saxi_args = vars(args)
     SAXINETS = getattr(saxi_nets, args.nn)
     model = SAXINETS(**saxi_args)
 
@@ -180,28 +180,49 @@ def SaxiIcoClassification_fs_train(args, checkpoint_callback, mount_point, train
     list_val_and_test_transform.append(CenterTransform())
     list_val_and_test_transform.append(NormalizePointTransform())
     val_and_test_transform = monai.transforms.Compose(list_val_and_test_transform)
+   
+    #Creation of Dataset
+    brain_data = SaxiIcoDataModule_fs(args.batch_size,train,val,test,train_transform=train_transform,val_and_test_transform=val_and_test_transform,num_workers=args.num_workers,name_class=args.class_column,freesurfer_path=args.fs_path)
+    df_train = pd.read_csv(train)
+    unique_classes = np.sort(np.unique(df_train[args.class_column]))
+    nb_classes = np.array(class_weight.compute_class_weight(class_weight='balanced', classes=unique_classes, y=df_train[args.class_column]))    
 
-    # df_train = pd.read_csv("/work/floda/source/qc_filtered.csv")
-    # brain_data = SaxiIcoDataset_fs(df_train,transform=train_transform,name_class = args.class_column,freesurfer_path=args.fs_path)
+    print('Number of classes:',len(nb_classes))
 
-    # for i in range(len(brain_data)):
-    #     try:
-    #         sample = brain_data[i]
-    #         print(i)
-    #     except Exception as e:
-    #         print(f"Path or CSV input line: {brain_data.df.iloc[i]}")
-    
-    # df_train = "/work/floda/source/qc_filtered.csv"
-    # brain_data = SaxiIcoDataModule_fs(args.batch_size,df_train,val,test,train_transform=train_transform,val_and_test_transform=val_and_test_transform,num_workers=args.num_workers,name_class=args.class_column,freesurfer_path=args.fs_path)
+    saxi_args = vars(args)
+    saxi_args['out_classes'] = len(nb_classes)
+    saxi_args['out_size'] = 256
 
-    # for i, batch in enumerate(brain_data.train_dataloader()):
-    #     try:
-    #         print(f"Processing batch {i+2}")
-    #     except RuntimeError as e:
-    #         print(f"RuntimeError encountered at batch {i+1}: {e}")
-    #         break
+    #Creation of our model
+    SAXINETS = getattr(saxi_nets, args.nn)
+    model = SAXINETS(**saxi_args)
 
-    
+    callbacks = [early_stop_callback, checkpoint_callback]
+    logger, image_logger = logger_neptune_tensorboard(args)
+
+    if image_logger:
+        callbacks.append(image_logger)
+
+    # trainer = Trainer(log_every_n_steps=10,reload_dataloaders_every_n_epochs=True,logger=logger,max_epochs=args.epochs,callbacks=callbacks,accelerator="gpu")
+    trainer = Trainer(log_every_n_steps=args.log_every_n_steps,logger=logger,max_epochs=args.epochs,callbacks=callbacks,accelerator="gpu", devices=torch.cuda.device_count())
+    trainer.fit(model,datamodule=brain_data)
+
+
+def SaxiIcoClassification_fs_test_train(args, checkpoint_callback, mount_point, train, val, test, early_stop_callback):
+    #Transformation
+    list_train_transform = [] 
+    list_train_transform.append(CenterTransform())
+    list_train_transform.append(NormalizePointTransform())
+    list_train_transform.append(RandomRotationTransform())        
+    list_train_transform.append(GaussianNoisePointTransform(args.mean,args.std)) #Do not use this transformation if your object is not a sphere
+    list_train_transform.append(NormalizePointTransform()) #Do not use this transformation if your object is not a sphere
+    train_transform = monai.transforms.Compose(list_train_transform)
+
+    list_val_and_test_transform = []    
+    list_val_and_test_transform.append(CenterTransform())
+    list_val_and_test_transform.append(NormalizePointTransform())
+    val_and_test_transform = monai.transforms.Compose(list_val_and_test_transform)
+   
     #Creation of Dataset
     brain_data = SaxiIcoDataModule_fs(args.batch_size,train,val,test,train_transform=train_transform,val_and_test_transform=val_and_test_transform,num_workers=args.num_workers,name_class=args.class_column,freesurfer_path=args.fs_path)
     df_train = pd.read_csv(train)
@@ -224,7 +245,6 @@ def SaxiIcoClassification_fs_train(args, checkpoint_callback, mount_point, train
     if image_logger:
         callbacks.append(image_logger)
 
-    # trainer = Trainer(log_every_n_steps=10,reload_dataloaders_every_n_epochs=True,logger=logger,max_epochs=args.epochs,callbacks=callbacks,accelerator="gpu")
     trainer = Trainer(log_every_n_steps=args.log_every_n_steps,logger=logger,max_epochs=args.epochs,callbacks=callbacks,accelerator="gpu", devices=torch.cuda.device_count())
     trainer.fit(model,datamodule=brain_data)
 
@@ -265,6 +285,9 @@ def main(args):
     elif args.nn == "SaxiIcoClassification_fs":
         SaxiIcoClassification_fs_train(args, checkpoint_callback, mount_point, path_train, path_val, path_test, early_stop_callback)
 
+    elif args.nn == "SaxiIcoClassification_fs_test":
+        SaxiIcoClassification_fs_test_train(args, checkpoint_callback, mount_point, path_train, path_val, path_test, early_stop_callback)
+
     else:
         raise ValueError ("Unknown neural network name: {}, choose between SaxiClassification, SaxiRegression, SaxiSegmentation, SaxiIcoClassification".format(args.nn))
 
@@ -293,7 +316,7 @@ def get_argparse():
 
     ##Hyperparameters
     hyper_group = parser.add_argument_group('Hyperparameters')
-    hyper_group.add_argument('--nn', type=str, help='Neural network name : SaxiClassification, SaxiRegression, SaxiSegmentation, SaxiIcoClassification, SaxiIcoClassification_fs', required=True, choices=["SaxiClassification", "SaxiRegression", "SaxiSegmentation", "SaxiIcoClassification", "SaxiIcoClassification_fs"])
+    hyper_group.add_argument('--nn', type=str, help='Neural network name : SaxiClassification, SaxiRegression, SaxiSegmentation, SaxiIcoClassification, SaxiIcoClassification_fs', required=True, choices=["SaxiClassification", "SaxiRegression", "SaxiSegmentation", "SaxiIcoClassification", "SaxiIcoClassification_fs", "SaxiIcoClassification_fs_test"])
     hyper_group.add_argument('--base_encoder', type=str, help='Base encoder for the feature extraction', default='resnet18')
     hyper_group.add_argument('--base_encoder_params', type=str, help='Base encoder parameters that are passed to build the feature extraction', default='pretrained=False,spatial_dims=2,n_input_channels=4,num_classes=512')
     hyper_group.add_argument('--hidden_dim', type=int, help='Hidden dimension for features output. Should match with output of base_encoder. Default value is 512', default=512)
