{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:31:09.439873Z",
     "start_time": "2024-06-07T21:31:09.429700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# import os\n",
    "#\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "# os.environ[\"PAREA_API_KEY\"] = \"...\"\n",
    "\n",
    "load_dotenv(Path(\"../.env.test\"), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfb3ed902652dfd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:31:10.781718Z",
     "start_time": "2024-06-07T21:31:10.777108Z"
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f32dc5445e19c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:31:12.061947Z",
     "start_time": "2024-06-07T21:31:11.086702Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from parea import Parea, trace\n",
    "\n",
    "parea = Parea()\n",
    "openai = OpenAI()\n",
    "\n",
    "parea.wrap_openai_client(openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75125e8ad065532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:31:12.065961Z",
     "start_time": "2024-06-07T21:31:12.063008Z"
    }
   },
   "outputs": [],
   "source": [
    "from parea.schemas import Log, EvaluationResult\n",
    "\n",
    "\n",
    "def score_answer(log: Log) -> EvaluationResult:\n",
    "    if log.target:\n",
    "        output = log.output.split(\"#### \")[-1]\n",
    "        target = log.target.split(\"#### \")[-1]\n",
    "        return EvaluationResult(\"correctness\", int(output == target))\n",
    "\n",
    "\n",
    "@trace(eval_funcs=[score_answer])\n",
    "def langchain_chain(inputs):\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "    messages = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert math solver. Your answer must be just the number with no separators, and nothing else. Follow the format of the examples.\",\n",
    "        ),\n",
    "        (\"user\", \"{question}\")\n",
    "    ]\n",
    "\n",
    "    chain = (\n",
    "        ChatPromptTemplate.from_messages(messages)\n",
    "        | ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    answer = chain.invoke(inputs)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f66675f324975a5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:31:36.821496Z",
     "start_time": "2024-06-07T21:31:29.714705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name set to: leary-plug, since a name was not provided.\n",
      "Fetching test collection: gsm8k-testset\n",
      "Fetched 5 test cases from collection: gsm8k-testset \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.63it/s]\n",
      "0it [00:04, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment wibbly-wobbly Run leary-plug stats:\n",
      "{\n",
      "  \"latency\": \"0.73\",\n",
      "  \"input_tokens\": \"0.00\",\n",
      "  \"output_tokens\": \"0.00\",\n",
      "  \"total_tokens\": \"0.00\",\n",
      "  \"cost\": \"0.00000\",\n",
      "  \"correctness\": \"0.40\"\n",
      "}\n",
      "\n",
      "\n",
      "View experiment & traces at: https://app.parea.ai/experiments/wibbly-wobbly/38aa90aa-c266-448a-abad-c659db606ba8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment_kwargs = dict(\n",
    "    data=\"gsm8k-testset\",\n",
    "    n_workers=2,\n",
    ")\n",
    "\n",
    "parea.experiment(\n",
    "    name=\"wibbly-wobbly\",\n",
    "    func=langchain_chain,\n",
    "    **experiment_kwargs\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b35fb30eb084d55e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:34:19.182984Z",
     "start_time": "2024-06-07T21:34:19.178197Z"
    }
   },
   "outputs": [],
   "source": [
    "from zenbase.types import LMRequest, deflm\n",
    "\n",
    "# Step 1: Add the deflm decorator\n",
    "# Step 2: Incorporate few-shot demonstrations\n",
    "\n",
    "@deflm # Step 1\n",
    "@trace(eval_funcs=[score_answer])\n",
    "def zen_chain(request: LMRequest):\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "    messages = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert math solver. Your answer must be just the number with no separators, and nothing else. Follow the format of the examples.\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Step 2\n",
    "    for demo in request.zenbase.task_demos:\n",
    "        messages += [\n",
    "            (\"user\", demo.inputs[\"question\"]),\n",
    "            (\"assistant\", demo.outputs[\"target\"]),\n",
    "        ]\n",
    "\n",
    "    messages.append((\"user\", \"{question}\"))\n",
    "\n",
    "    chain = (\n",
    "        ChatPromptTemplate.from_messages(messages)\n",
    "        | ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    answer = chain.invoke(request.inputs)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e935c1126e7e18be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:32:11.262370Z",
     "start_time": "2024-06-07T21:31:51.730471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name set to: still-tule, since a name was not provided.\n",
      "Fetching test collection: gsm8k-testset\n",
      "Fetched 5 test cases from collection: gsm8k-testset \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.07s/it]\n",
      "0it [00:04, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment zenbase-fully-configurable-bandwidth-monitored-strategy Run still-tule stats:\n",
      "{\n",
      "  \"latency\": \"1.77\",\n",
      "  \"input_tokens\": \"0.00\",\n",
      "  \"output_tokens\": \"0.00\",\n",
      "  \"total_tokens\": \"0.00\",\n",
      "  \"cost\": \"0.00000\",\n",
      "  \"correctness\": \"0.60\"\n",
      "}\n",
      "\n",
      "\n",
      "View experiment & traces at: https://app.parea.ai/experiments/zenbase-fully-configurable-bandwidth-monitored-strategy/123e90c5-8ba5-41dc-81af-c20178ce9461\n",
      "\n",
      "Run name set to: tubby-fils, since a name was not provided.\n",
      "Fetching test collection: gsm8k-testset\n",
      "Fetched 5 test cases from collection: gsm8k-testset \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.31it/s]\n",
      "0it [00:04, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment zenbase-profit-focused-disintermediate-challenge Run tubby-fils stats:\n",
      "{\n",
      "  \"latency\": \"1.25\",\n",
      "  \"input_tokens\": \"0.00\",\n",
      "  \"output_tokens\": \"0.00\",\n",
      "  \"total_tokens\": \"0.00\",\n",
      "  \"cost\": \"0.00000\",\n",
      "  \"correctness\": \"0.60\"\n",
      "}\n",
      "\n",
      "\n",
      "View experiment & traces at: https://app.parea.ai/experiments/zenbase-profit-focused-disintermediate-challenge/fa550de9-3bcd-43bf-808a-92e997a3e845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from zenbase.optim.metric.labeled_few_shot import LabeledFewShot\n",
    "from zenbase.helpers.parea import ZenParea\n",
    "\n",
    "demoset = ZenParea.collection_demos(parea.get_collection(\"gsm8k-demoset\"))\n",
    "optimizer = LabeledFewShot(demoset=demoset, shots=3)\n",
    "\n",
    "best_fn, candidate_results = optimizer.perform(\n",
    "    zen_chain,\n",
    "    evaluator=ZenParea.metric_evaluator(**experiment_kwargs),\n",
    "    samples=2,\n",
    "    rounds=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d03caab067b16ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:32:37.833282Z",
     "start_time": "2024-06-07T21:32:37.303381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = best_fn({\"question\": \"What is 2+2?\"})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84203be06a032a5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:33:27.644968Z",
     "start_time": "2024-06-07T21:33:25.609472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython autoawait is `on`, and set to use `asyncio`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The total percentage of shares assigned is 30% + 40% = 70%.\\nThis means that 100% - 70% = 30% of shares are unassigned.\\nAs there are 10M shares in total, the number of unassigned shares is 30% of 10M, which is 0.3 * 10M = 3M.\\n#### 3000000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can even run your function asynchronously in a coroutine\n",
    "%autoawait\n",
    "\n",
    "await best_fn.coroutine({\n",
    "    \"question\": \"I have 30% of company and Mamad has 40% of company and there are 10M shares, how many shares are unassigned?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "273ba2abfd65d89d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:34:24.204620Z",
     "start_time": "2024-06-07T21:34:23.594362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also save the zenbase params for re-use\n",
    "import pickle\n",
    "\n",
    "pickled_zenbase = pickle.dumps(best_fn.zenbase)\n",
    "zen_chain.zenbase = pickle.loads(pickled_zenbase)\n",
    "\n",
    "zen_chain({\"question\": \"What is 2 + 2?\"}) # uses the best few-shot demos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
