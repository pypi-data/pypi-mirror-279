# This file was auto-generated by Fern from our API Definition.

import datetime as dt
import typing

from ...core.datetime_utils import serialize_datetime
from ...core.pydantic_utilities import pydantic_v1
from .lora_tune_checkpoint import LoraTuneCheckpoint
from .lora_tune_file import LoraTuneFile


class LoraTune(pydantic_v1.BaseModel):
    """
    A LoRA Tune.
    """

    base_checkpoint: LoraTuneCheckpoint = pydantic_v1.Field()
    """
    The base checkpoint used for this LoRA Tune.
    """

    files: typing.List[LoraTuneFile] = pydantic_v1.Field()
    """
    The files used for this LoRA Tune.
    """

    resize_images: typing.Optional[bool] = None
    seed: typing.Optional[int] = None
    steps: int = pydantic_v1.Field()
    """
    The number of steps used for this LoRA Tune.
    """

    trigger_words: typing.List[str] = pydantic_v1.Field()
    """
    The trigger words used for this tune. As of now, only one trigger word is supported. `List` is used for future-proofing.
    """

    def json(self, **kwargs: typing.Any) -> str:
        kwargs_with_defaults: typing.Any = {"by_alias": True, "exclude_unset": True, **kwargs}
        return super().json(**kwargs_with_defaults)

    def dict(self, **kwargs: typing.Any) -> typing.Dict[str, typing.Any]:
        kwargs_with_defaults: typing.Any = {"by_alias": True, "exclude_unset": True, **kwargs}
        return super().dict(**kwargs_with_defaults)

    class Config:
        frozen = True
        smart_union = True
        extra = pydantic_v1.Extra.allow
        json_encoders = {dt.datetime: serialize_datetime}
